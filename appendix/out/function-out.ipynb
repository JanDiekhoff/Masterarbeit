{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e93e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T10:46:04.452554Z",
     "iopub.status.busy": "2024-10-28T10:46:04.452413Z",
     "iopub.status.idle": "2024-10-28T10:46:08.103438Z",
     "shell.execute_reply": "2024-10-28T10:46:08.102497Z"
    },
    "papermill": {
     "duration": 3.655406,
     "end_time": "2024-10-28T10:46:08.105626",
     "exception": false,
     "start_time": "2024-10-28T10:46:04.450220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 11:46:06.185024: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-28 11:46:06.302549: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 11:46:06.737160: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-28 11:46:06.737221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-28 11:46:06.737227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "from transformers import set_seed\n",
    "from transformers import AutoTokenizer\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer\n",
    "import os\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModelForCausalLM\n",
    "import torch\n",
    "from datasets import DatasetDict, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b309c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T10:46:08.111866Z",
     "iopub.status.busy": "2024-10-28T10:46:08.111552Z",
     "iopub.status.idle": "2024-10-28T10:46:08.116691Z",
     "shell.execute_reply": "2024-10-28T10:46:08.115924Z"
    },
    "papermill": {
     "duration": 0.010439,
     "end_time": "2024-10-28T10:46:08.118894",
     "exception": false,
     "start_time": "2024-10-28T10:46:08.108455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)\n",
    "model_name = \"TinyLlama/TinyLlama_v1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e404755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T10:46:08.124461Z",
     "iopub.status.busy": "2024-10-28T10:46:08.124321Z",
     "iopub.status.idle": "2024-10-28T10:46:08.129564Z",
     "shell.execute_reply": "2024-10-28T10:46:08.128939Z"
    },
    "papermill": {
     "duration": 0.010072,
     "end_time": "2024-10-28T10:46:08.131343",
     "exception": false,
     "start_time": "2024-10-28T10:46:08.121271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(base_config, lora_config, bnb_config, data, tokenizer, collator):\n",
    "    global model_name\n",
    "\n",
    "    if bnb_config:\n",
    "        print(\"QLORA\")\n",
    "        bnb = BitsAndBytesConfig(\n",
    "            load_in_4bit=bnb_config[\"load_in_4bit\"],\n",
    "            bnb_4bit_use_double_quant=bnb_config[\"bnb_4bit_use_double_quant\"],\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=bnb_config[\"bnb_4bit_compute_dtype\"]\n",
    "        )\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "                    model_name,\n",
    "                    device_map=\"auto\",\n",
    "                    revision=\"main\",\n",
    "                    quantization_config = bnb\n",
    "                )\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                device_map=\"auto\",\n",
    "                revision=\"main\"\n",
    "            )\n",
    "    \n",
    "    if lora_config:\n",
    "        print(\"LORA\")\n",
    "        lora = LoraConfig(\n",
    "            r = lora_config[\"r\"],\n",
    "            lora_alpha = lora_config[\"lora_alpha\"],\n",
    "            init_lora_weights = True,\n",
    "            lora_dropout = lora_config[\"lora_dropout\"],\n",
    "            bias = 'none',\n",
    "            task_type=\"CAUSAL_LM\"\n",
    "        )\n",
    "        \n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "        model = get_peft_model(model,lora)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=\".\",\n",
    "        fp16=base_config[\"fp16\"],\n",
    "        weight_decay=base_config[\"weight_decay\"],\n",
    "        learning_rate=base_config[\"learning_rate\"],\n",
    "        label_names=['input_ids'],\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=8,\n",
    "        no_cuda=False,\n",
    "        optim=\"paged_adamw_8bit\"\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=data,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=collator\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    save_path = \"tmp_trainer_smol\"\n",
    "    trainer.save_model(save_path)\n",
    "    model.save_pretrained(save_path+\"_peft\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540fca8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T10:46:08.137207Z",
     "iopub.status.busy": "2024-10-28T10:46:08.136825Z",
     "iopub.status.idle": "2024-10-28T10:46:14.093069Z",
     "shell.execute_reply": "2024-10-28T10:46:14.092351Z"
    },
    "papermill": {
     "duration": 5.960312,
     "end_time": "2024-10-28T10:46:14.094042",
     "exception": false,
     "start_time": "2024-10-28T10:46:08.133730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size after filtering: 34080\n",
      "Sampled size (1%): 3408\n",
      "  language                                               head  \\\n",
      "0   Python  # Python\\n# ADD ME\\n\\ntest_build_epg_title(sel...   \n",
      "1   Python  # Python\\n# :param sceneName: (Optional) 场景名字，...   \n",
      "2   Python  # Python\\n# Save frames in animation \\n\\nsave(...   \n",
      "3   Python  # Python\\n# Sets the coordinate_y of this UIPr...   \n",
      "4   Python  # Python\\n# Command to value (in percent)\\n\\np...   \n",
      "\n",
      "                                                body  \\\n",
      "0  item_helper = ItemHelper(constants=Constants()...   \n",
      "1       self.sceneName = sceneName\\nself.rate = rate   \n",
      "2  global counter\\nfilename = f'frame{counter:04d...   \n",
      "3                  self._coordinate_y = coordinate_y   \n",
      "4  assert 0 <= value <= 100, value\\nsend_command(...   \n",
      "\n",
      "                                    file_id  split  __index_level_0__  \n",
      "0  1d09b47b21a7b9333e73343761e428640501363f      0            4567132  \n",
      "1  d4d1d9b094838079345f9c23e1f12390cca425d0      0             594316  \n",
      "2  66b426d0e883148ae597a3f951bb7c9161419fe3      0            3252946  \n",
      "3  16289589ecb61b49c0edddb400748d58d958111c      0            3461083  \n",
      "4  7f353f9732fbcbceb49698c829bf99091784d1c6      0             553015  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f63ae0efcc7443f946f4c3d55294145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5ef59d7af74735a0014c72fbe4ac26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "def reformat_func(example):\n",
    "    example[\"full\"] = \"# <func>\\n\" + example[\"head\"] + example[\"body\"] + \"\\n</func>\"\n",
    "    return example\n",
    "\n",
    "def tokenize_func(example):\n",
    "    return tokenizer(example[\"full\"], return_tensors=\"np\",padding=\"max_length\",max_length=1000)\n",
    "\n",
    "data = Dataset.from_parquet(\"../data/chunks/chunk_1.parquet\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "filtered_df = df[df[\"language\"] == \"Python\"]\n",
    "\n",
    "sampled_df = filtered_df.sample(frac=.1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "data = Dataset.from_pandas(sampled_df)\n",
    "\n",
    "print(f\"Original size after filtering: {len(filtered_df)}\")\n",
    "print(f\"Sampled size (1%): {len(sampled_df)}\")\n",
    "print(sampled_df.head())\n",
    "\n",
    "\n",
    "data = data.map(reformat_func)\n",
    "tokenized_ds = data.map(tokenize_func, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac084858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T10:46:14.097957Z",
     "iopub.status.busy": "2024-10-28T10:46:14.097814Z",
     "iopub.status.idle": "2024-10-28T12:12:23.869907Z",
     "shell.execute_reply": "2024-10-28T12:12:23.869340Z"
    },
    "papermill": {
     "duration": 5169.776576,
     "end_time": "2024-10-28T12:12:23.872496",
     "exception": false,
     "start_time": "2024-10-28T10:46:14.095920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QLORA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diekhoff/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LORA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-28 11:46:21,167] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diekhoff/.local/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias=None):\n",
      "/home/diekhoff/.local/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diekhoff/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diekhoff/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53/53 1:20:28, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diekhoff/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/diekhoff/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"from typing import List\\n# <func>\\n# Python\\n# Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n#>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n# False\\n# >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n# True\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for number in numbers:\\n        if number < threshold:\\n            return False\\n        else:\\n            return True\\n\\nhas_close_elements(numbers: List[float], threshold: float) -> bool:\\n    return has_close_elements(numbers, threshold)\\n\\n</func>\\n\\n\\nA: I'm not sure if this is the best way to do it, but I'm trying to find the closest number to another number.\\nI'm using the following function:\\ndef closest_number(numbers: List[float], threshold: float):\\n    closest_number = 0\\n    for number in numbers:\\n        if number < threshold:\\n            closest_number = number\\n    return closest_number\\n\\nI'm trying to find the closest number to another number.\\nI'm using the following function:\\ndef closest_number(numbers: List[float], threshold: float):\\n    closest_number = 0\\n    for number in numbers:\\n        if number < threshold:\\n            closest_number = number\\n    return closest_number\\n\\nI'm trying to find the closest number to another number.\\nI'm using the following function:\\ndef closest_number(numbers: List[float], threshold: float):\\n    closest_number = 0\\n    for number in numbers:\\n        if number < threshold:\\n            closest_number = number\\n    return closest_number\\n\\nI'm trying to find the closest number to another number.\\nI'm using the following function:\\ndef closest_number(numbers: List[float], threshold: float):\\n    closest_number = 0\\n    for number in numbers:\\n        if number < threshold:\\n            closest_number = number\\n    return closest_number\\n\\nI'm trying to find the closest number to another number.\\nI'm using the following function:\\ndef closest_number(numbers: List[float], threshold: float):\\n    closest_number = 0\\n    for number in numbers:\\n        if number < threshold:\\n            closest_number = number\\n    return closest_number\\n\\nI'm trying to find the closest number to another number.\\nI'm using the following function:\\ndef closest_number(numbers: List[float], threshold: float):\\n    closest_number = 0\\n    for number in\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diekhoff/.local/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'from typing import List\\n# <func>\\n# Python\\n# Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n#>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n# False\\n# >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n# True\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for number in numbers:\\n        if number < threshold:\\n            return False\\n    return True\\n\\n# <func>\\n# Python\\n# Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n#>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n# False\\n# >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n# True\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for number in numbers:\\n        if number < threshold:\\n            return False\\n    return True\\n\\n# <func>\\n# Python\\n# Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n#>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n# False\\n# >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n# True\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for number in numbers:\\n        if number < threshold:\\n            return False\\n    return True\\n\\n# <func>\\n# Python\\n# Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n#>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n# False\\n# >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n# True\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for number in numbers:\\n        if number < threshold:\\n            return False\\n    return True\\n\\n# <func>\\n# Python\\n# Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n#>>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'from typing import List\\n# <func>\\n# Python\\n# Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n#>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n# False\\n# >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n# True\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\"\\n    Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    True\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3'}]\n"
     ]
    }
   ],
   "source": [
    "model = train_model({\"weight_decay\":0.1,\"learning_rate\":1e-4,\"fp16\":False},\n",
    "            {\"r\":4096,\"lora_alpha\":4096,\"lora_dropout\":0.1},\n",
    "            {\"load_in_4bit\":True,\"bnb_4bit_use_double_quant\":True,\"bnb_4bit_compute_dtype\":\"bfloat16\"},\n",
    "            #False,\n",
    "            tokenized_ds,tokenizer,collator)\n",
    "\n",
    "prompt = \"\"\"from typing import List\\n# <func>\\n# Python\\n# Check if in given list of numbers, are any two numbers closer to each other than given threshold.\\n#>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n# False\\n# >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n# True\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\"\"\"\n",
    "\n",
    "gen = pipeline(model=model, tokenizer=tokenizer, task=\"text-generation\", device_map=\"auto\",max_new_tokens=512)\n",
    "print(gen(prompt))\n",
    "\n",
    "\n",
    "gen = pipeline(model=model.merge_and_unload(), tokenizer=tokenizer, task=\"text-generation\", device_map=\"auto\",max_new_tokens=512)\n",
    "print(gen(prompt))\n",
    "\n",
    "\n",
    "gen = pipeline(model=AutoModelForCausalLM.from_pretrained(model_name), tokenizer=tokenizer, task=\"text-generation\", device_map=\"auto\",max_new_tokens=512)\n",
    "print(gen(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5182.103831,
   "end_time": "2024-10-28T12:12:25.693101",
   "environment_variables": {},
   "exception": null,
   "input_path": "finetune-MVP-function.ipynb",
   "output_path": "mvp-out-smol.ipynb",
   "parameters": {},
   "start_time": "2024-10-28T10:46:03.589270",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0224ae17fb4e4d48a66345e017e94c33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "02692d21878e4a95957687872573c603": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2156d12f6dc54b92809769260d64a952": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22de794116fb4d9aa53c567ad5cc90d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2f63ae0efcc7443f946f4c3d55294145": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ec0841341ccb40668ee1895f5d8d54cb",
        "IPY_MODEL_f6887889423942d59a1b958e6d461240",
        "IPY_MODEL_3789c4c3edb94a6aa5e83d65d369d59d"
       ],
       "layout": "IPY_MODEL_3538d8995a1e43838234a8757c919a2a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3538d8995a1e43838234a8757c919a2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "366d6752691940c5a5ce3016460084a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3789c4c3edb94a6aa5e83d65d369d59d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_42bfde905c1440508bc6c50d3fa55100",
       "placeholder": "​",
       "style": "IPY_MODEL_366d6752691940c5a5ce3016460084a3",
       "tabbable": null,
       "tooltip": null,
       "value": " 3408/3408 [00:00&lt;00:00, 23448.59 examples/s]"
      }
     },
     "3b4313afc6a645a195f7d5c301a86c8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42bfde905c1440508bc6c50d3fa55100": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "497efba254f343bc8b37b238536b14fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ad7597ae117646899020a7b49f94e126",
       "placeholder": "​",
       "style": "IPY_MODEL_0224ae17fb4e4d48a66345e017e94c33",
       "tabbable": null,
       "tooltip": null,
       "value": " 3408/3408 [00:00&lt;00:00, 5037.93 examples/s]"
      }
     },
     "5749854ac6fb4a82be1eb34af2e2c8b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3b4313afc6a645a195f7d5c301a86c8c",
       "max": 3408,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b4df77dd9dc544159874e157024c9a95",
       "tabbable": null,
       "tooltip": null,
       "value": 3408
      }
     },
     "5bdcd98bda524bcc9aeb8a47cb422781": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5e5ef59d7af74735a0014c72fbe4ac26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_67e94914efbc4bdd80c7fe831ddfc2ae",
        "IPY_MODEL_5749854ac6fb4a82be1eb34af2e2c8b7",
        "IPY_MODEL_497efba254f343bc8b37b238536b14fa"
       ],
       "layout": "IPY_MODEL_ccd546a330e6461ca4c0f60b12a802e7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "67e94914efbc4bdd80c7fe831ddfc2ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c1ea64b67c745b2b6a735ea8d0b57c4",
       "placeholder": "​",
       "style": "IPY_MODEL_02692d21878e4a95957687872573c603",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "8c1ea64b67c745b2b6a735ea8d0b57c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad7597ae117646899020a7b49f94e126": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4df77dd9dc544159874e157024c9a95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ccd546a330e6461ca4c0f60b12a802e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2beea3269734aefa4c7335efc80bc0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec0841341ccb40668ee1895f5d8d54cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2156d12f6dc54b92809769260d64a952",
       "placeholder": "​",
       "style": "IPY_MODEL_5bdcd98bda524bcc9aeb8a47cb422781",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "f6887889423942d59a1b958e6d461240": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e2beea3269734aefa4c7335efc80bc0e",
       "max": 3408,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_22de794116fb4d9aa53c567ad5cc90d3",
       "tabbable": null,
       "tooltip": null,
       "value": 3408
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
