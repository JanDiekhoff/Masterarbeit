{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {\n",
    "    \"llama.v1.0\":\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    \"llama.v1.1\":\"TinyLlama/TinyLlama_v1.1\",\n",
    "    \"llama.math\":\"TinyLlama/TinyLlama_v1.1_math_code\",\n",
    "    \"v1.0\":\"JanDkff/TinyFuncCoder-v1.0\",\n",
    "    \"v1.1\":\"JanDkff/TinyFuncCoder-v1.1\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#evaluate_finetuned = False\n",
    "\n",
    "reformatted_prompt = False\n",
    "reformatted_path = \"R\" if reformatted_prompt else \"\"\n",
    "\n",
    "\n",
    "eval_types=[\"humaneval\",\"mbpp\",\"mbppplus\",\"multiple-sh\",\"multiple-cpp\",\"multiple-cs\",\"multiple-js\",\"multiple-java\",\"multiple-php\",\"multiple-ts\"] #,\"humanevalsynthesize-python\",\"humanevalsynthesize-cpp\",\"humanevalsynthesize-js\",\"humanevalsynthesize-java\",\"ds1000-all-completion\"]\n",
    "\n",
    "#names = [\"v1.0\",\"v1.1\"] if evaluate_finetuned else [\"llama.v1.0\",\"llama.v1.1\",\"llama.math\"]\n",
    "\n",
    "names = [\"llama.v1.0\"]\n",
    "\n",
    "eval_types = [\"ds1000-all-completion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE DS-1000\n",
    "from transformers import AutoModelForCausalLM, pipeline, AutoTokenizer\n",
    "from peft import PeftModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "data = load_dataset(\"xlangai/DS-1000\",split=\"test\")\n",
    "\n",
    "for name in names:\n",
    "    if name.find(\"llama\") >= 0:\n",
    "        model = AutoModelForCausalLM.from_pretrained(name_map[name])\n",
    "        tokenizer = AutoTokenizer.from_pretrained(name_map[name])\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(name_map[f\"llama.{name}\"])\n",
    "        peft = PeftModelForCausalLM.from_pretrained(model=model,model_id=name_map[name])\n",
    "        tokenizer = AutoTokenizer.from_pretrained(name_map[f\"llama.{name}\"])\n",
    "        model = peft.merge_and_unload()\n",
    "    generator = pipeline(task=\"text-generation\",model=model,tokenizer=tokenizer, max_new_tokens=512,device=\"cuda\")\n",
    "    \n",
    "    new_data = []\n",
    "    i = 1\n",
    "    for problem in data:\n",
    "        #print(problem)\n",
    "        print(f'{name}: {i}/1000')\n",
    "        problem[\"output\"] = generator(problem[\"prompt\"],temperature=0.2,top_p=0.95,top_k=0,num_return_sequences=1,do_sample=True)[0][\"generated_text\"]\n",
    "        new_data.append(problem)\n",
    "        i += 1\n",
    "    \n",
    "    with open(f'save/{name}/_ds1000-all-completion.jsonl', 'w') as file:\n",
    "        for entry in new_data:\n",
    "            json_line = json.dumps(entry)\n",
    "            file.write(json_line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE OTHERS\n",
    "\n",
    "for eval_type in eval_types:\n",
    "    for name in names:\n",
    "        if name.find(\"llama\") >= 0:\n",
    "            command = f'accelerate launch main.py --model={name_map[name]} --tasks={eval_type} --save_generations --save_generations_path=save/{name}/{reformatted_path} --n_samples=1 --allow_code_execution --trust_remote_code --prompt=continue --temperature=0.2 --generation_only'\n",
    "            !{command}\n",
    "        else:\n",
    "            command = f'accelerate launch main.py --model={name_map[\"llama.\"+name]} --tasks={eval_type} --save_generations --save_generations_path=save/{name}/{reformatted_path} --peft_model={name_map[name]} --eos=\"</func>\" --n_samples=1 --trust_remote_code --prompt=continue --temperature=0.2 --precision=fp16 --generation_only'\n",
    "            !{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE OTHERS\n",
    "\n",
    "for eval_type in eval_types:\n",
    "    \n",
    "    for name in names:\n",
    "        path = f\"save/{name}/{reformatted_path}_{eval_type}.json\"\n",
    "        \n",
    "        cmd_head = \"\"\n",
    "        if eval_type.find(\"synthesize\") < 0 or eval_type.find(\"ds1000\") < 0:\n",
    "            cmd_head = f\"docker run -v $(pwd)/{path}:/app/{path}:ro -it  evaluation-harness-multiple\"\n",
    "            path = f\"/app/{path}\"\n",
    "        else:\n",
    "            cmd_head = \"python3 main.py\"\n",
    "                \n",
    "        if name.find(\"llama\") >= 0:\n",
    "            command = f'{cmd_head} --model={name_map[name]} --tasks={eval_type} --load_generations_path={path} --n_samples=1 --allow_code_execution --trust_remote_code --temperature=0.2 --prompt=continue'\n",
    "            \n",
    "            !{command}\n",
    "            \n",
    "            if eval_type==\"humaneval\": # or eval_type==\"mbpp\":\n",
    "                command2 = f'{cmd_head} --model={name_map[name]} --tasks={eval_type+\"plus\"} --load_generations_path={path} --n_samples=1 --allow_code_execution --trust_remote_code --temperature=0.2'\n",
    "                \n",
    "                !{command2}\n",
    "        else:               \n",
    "                \n",
    "            command = f'{cmd_head} --model={name_map[\"llama.\"+name]} --tasks={eval_type} --load_generations_path={path} --n_samples=1 --allow_code_execution --trust_remote_code --temperature=0.2 --peft_model={name_map[name]} --eos=\"</func>\" --precision=fp16 --prompt=continue'\n",
    "            \n",
    "            !{command}\n",
    "            \n",
    "            if eval_type==\"humaneval\": # or eval_type==\"mbpp\":\n",
    "                command2 = f'{cmd_head} --model={name_map[name]} --tasks={eval_type+\"plus\"} --load_generations_path={path} --n_samples=1 --allow_code_execution --trust_remote_code --temperature=0.2 --peft_model={name_map[name]} --eos=\"</func>\" --precision=fp16 --prompt=continue'\n",
    "                \n",
    "                !{command2}\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
