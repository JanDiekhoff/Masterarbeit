{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1cec2c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T09:27:04.377076Z",
     "iopub.status.busy": "2024-08-15T09:27:04.376773Z",
     "iopub.status.idle": "2024-08-15T09:27:04.384623Z",
     "shell.execute_reply": "2024-08-15T09:27:04.384025Z"
    },
    "papermill": {
     "duration": 0.012068,
     "end_time": "2024-08-15T09:27:04.386264",
     "exception": false,
     "start_time": "2024-08-15T09:27:04.374196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "formats = {\n",
    "    \"Python\":\"\",\n",
    "    \"JavaScript\":\"// {language}\\n{docstring}\\n{name}{params}\",\n",
    "    \"TypeScript\":\"// {language}\\n{docstring}\\n{name}{params}\",\n",
    "    \"Java\":\"// {language}\\n{docstring}\\n{name}{params}\",\n",
    "    \"C\":\"// {language}\\n{docstring}\\n{name}{params}\",\n",
    "    \"C++\":\"// {language}\\n{docstring}\\n{name}{params}\",\n",
    "    \"C#\":\"// {language}\\n{docstring}\\n{name}{params}\",\n",
    "    \"Ruby\":\"# {language}\\n{docstring}\\n{name}{params}\\n\",\n",
    "    \"Shell\":\"# {language}\\n{docstring}\\n{name}{params}\",\n",
    "    \"PHP\":\"// {language}\\n{docstring}\\n{name}{params}\",\n",
    "}\n",
    "\n",
    "def reconstruct_python_func(example):\n",
    "    func = f\"# {example['language']}\\n\"\n",
    "    \n",
    "    lines = example['docstring'].split(\"\\n\")\n",
    "    for line in lines:\n",
    "        func += \"# \" + line + \"\\n\"\n",
    "    \n",
    "    func += example['name']\n",
    "    \n",
    "    args = example['params']\n",
    "    if args[0] == '[':\n",
    "        func += \"(\"\n",
    "        args = [arg.strip()[1:-1] for arg in args[1:-1].split(\",\")]\n",
    "        for arg in args:\n",
    "            func += arg + \", \"\n",
    "        func = func[:-2] + \"):\\n\"\n",
    "    else:\n",
    "        func += args + \":\\n\"\n",
    "    \n",
    "    func_with_body = func + \"\\n\".join(example['body'].split(\"\\n\")[1:])\n",
    "    \n",
    "    return func_with_body\n",
    "\n",
    "\n",
    "def reconstruct_func(example):\n",
    "    if example[\"language\"] == \"Python\":\n",
    "        return reconstruct_python_func(example)\n",
    "    else:\n",
    "        func = formats[example['language']].format(\n",
    "            language=example['language'],\n",
    "            docstring=example['docstring'],\n",
    "            name=example['name'],\n",
    "            params=example['params']\n",
    "            )\n",
    "        return func+example['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7488d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T09:27:04.389133Z",
     "iopub.status.busy": "2024-08-15T09:27:04.388698Z",
     "iopub.status.idle": "2024-08-15T09:27:05.887379Z",
     "shell.execute_reply": "2024-08-15T09:27:05.886441Z"
    },
    "papermill": {
     "duration": 1.501625,
     "end_time": "2024-08-15T09:27:05.888849",
     "exception": false,
     "start_time": "2024-08-15T09:27:04.387224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "model_name = \"TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "def init_tokenizer(model_name):\n",
    "    return AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "tokenizer = init_tokenizer(model_name)\n",
    "\n",
    "tokenizer.bos_token = \"<func>\"\n",
    "tokenizer.eos_token = \"</func>\"\n",
    "tokenizer.pad_token = \"</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc89d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T09:27:08.510475Z",
     "iopub.status.busy": "2024-08-15T09:27:08.510218Z",
     "iopub.status.idle": "2024-08-15T09:27:08.514214Z",
     "shell.execute_reply": "2024-08-15T09:27:08.513569Z"
    },
    "papermill": {
     "duration": 0.006866,
     "end_time": "2024-08-15T09:27:08.515254",
     "exception": false,
     "start_time": "2024-08-15T09:27:08.508388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reformat_prompt(prompt, gen_type):\n",
    "    func_name = \"\"\n",
    "    definition = \"\"\n",
    "    docstring = \"\"\n",
    "    \n",
    "    if gen_type == \"mbpp\":\n",
    "        func_name = prompt[\"canonical_solution\"]\n",
    "        definition = \"def\" + func_name.split(\"def\")[1].split(':\\n')[0] + \":\\n\"\n",
    "        docstring = prompt[\"prompt\"]\n",
    "    else:\n",
    "        prompt = prompt[\"prompt\"].split(\"def\")[1].split(':\\n')\n",
    "        docstring = prompt[1]\n",
    "        definition = \"def\" + prompt[0] + \":\\n\"\n",
    "    \n",
    "    docstring = docstring.replace('\"\"\"',\"\").replace(\"'''\",\"\")\n",
    "    new_prompt = tokenizer.bos_token + \"\\n# Python\\n\"\n",
    "    for line in docstring.split(\"\\n\"):\n",
    "        if line.strip():\n",
    "            new_prompt += f\"# {line}\\n\"\n",
    "    new_prompt += definition\n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b5e4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_prompt_tokens(prompt, gen_type):\n",
    "    func_name = \"\"\n",
    "    definition = \"\"\n",
    "    docstring = \"\"\n",
    "    \n",
    "    if gen_type == \"mbpp\":\n",
    "        func_name = prompt[\"canonical_solution\"]\n",
    "        definition = \"def\" + func_name.split(\"def\")[1].split(':\\n')[0] + \":\\n\"\n",
    "        docstring = prompt[\"prompt\"]\n",
    "    else:\n",
    "        prompt = prompt[\"prompt\"].split(\"def\")[1].split(':\\n')\n",
    "        docstring = prompt[1]\n",
    "        definition = \"def\" + prompt[0] + \":\\n\"\n",
    "    \n",
    "    docstring = docstring.replace('\"\"\"',\"\").replace(\"'''\",\"\")\n",
    "    new_prompt = tokenizer.bos_token + \"\\n# <|language|> Python\\ <|/language|>\\n# <|docstring|>\\n\"\n",
    "    for line in docstring.split(\"\\n\"):\n",
    "        if line.strip():\n",
    "            new_prompt += f\"# {line}\\n\"\n",
    "    new_prompt += \"# <|/docstring|>\\n# <|head|>\\n\"\n",
    "    new_prompt += definition\n",
    "    new_prompt += \"# <|/head|>\\n# <|body|>\\n\"\n",
    "    print(new_prompt)\n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2d237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T09:27:08.518033Z",
     "iopub.status.busy": "2024-08-15T09:27:08.517739Z",
     "iopub.status.idle": "2024-08-15T09:27:08.521048Z",
     "shell.execute_reply": "2024-08-15T09:27:08.520446Z"
    },
    "papermill": {
     "duration": 0.005907,
     "end_time": "2024-08-15T09:27:08.522013",
     "exception": false,
     "start_time": "2024-08-15T09:27:08.516106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_one_completion(id,prompt,code_generator, gen_type):\n",
    "    print(id)\n",
    "    prompt = reformat_prompt(prompt, gen_type)\n",
    "    #prompt = prompt[\"prompt\"]\n",
    "    \n",
    "    generated_code = code_generator(\n",
    "    prompt,\n",
    "    max_new_tokens=512,\n",
    "    truncation=True\n",
    "    )[0][\"generated_text\"]\n",
    "    generated_code = \"# \" + generated_code\n",
    "    if generated_code.find(tokenizer.eos_token) >= 0:\n",
    "        generated_code = generated_code.split(tokenizer.eos_token)[0]\n",
    "    return generated_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de7d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T09:27:08.525058Z",
     "iopub.status.busy": "2024-08-15T09:27:08.524542Z",
     "iopub.status.idle": "2024-08-15T10:44:55.251763Z",
     "shell.execute_reply": "2024-08-15T10:44:55.250855Z"
    },
    "papermill": {
     "duration": 4666.731355,
     "end_time": "2024-08-15T10:44:55.254257",
     "exception": false,
     "start_time": "2024-08-15T09:27:08.522902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanEval/0\n",
      "HumanEval/1\n",
      "HumanEval/2\n",
      "HumanEval/3\n",
      "HumanEval/4\n",
      "HumanEval/5\n",
      "HumanEval/6\n",
      "HumanEval/7\n",
      "HumanEval/8\n",
      "HumanEval/9\n",
      "HumanEval/10\n",
      "HumanEval/11\n",
      "HumanEval/12\n",
      "HumanEval/13\n",
      "HumanEval/14\n",
      "HumanEval/15\n",
      "HumanEval/16\n",
      "HumanEval/17\n",
      "HumanEval/18\n",
      "HumanEval/19\n",
      "HumanEval/20\n",
      "HumanEval/21\n",
      "HumanEval/22\n",
      "HumanEval/23\n",
      "HumanEval/24\n",
      "HumanEval/25\n",
      "HumanEval/26\n",
      "HumanEval/27\n",
      "HumanEval/28\n",
      "HumanEval/29\n",
      "HumanEval/30\n",
      "HumanEval/31\n",
      "HumanEval/32\n",
      "HumanEval/33\n",
      "HumanEval/34\n",
      "HumanEval/35\n",
      "HumanEval/36\n",
      "HumanEval/37\n",
      "HumanEval/38\n",
      "HumanEval/39\n",
      "HumanEval/40\n",
      "HumanEval/41\n",
      "HumanEval/42\n",
      "HumanEval/43\n",
      "HumanEval/44\n",
      "HumanEval/45\n",
      "HumanEval/46\n",
      "HumanEval/47\n",
      "HumanEval/48\n",
      "HumanEval/49\n",
      "HumanEval/50\n",
      "HumanEval/51\n",
      "HumanEval/52\n",
      "HumanEval/53\n",
      "HumanEval/54\n",
      "HumanEval/55\n",
      "HumanEval/56\n",
      "HumanEval/57\n",
      "HumanEval/58\n",
      "HumanEval/59\n",
      "HumanEval/60\n",
      "HumanEval/61\n",
      "HumanEval/62\n",
      "HumanEval/63\n",
      "HumanEval/64\n",
      "HumanEval/65\n",
      "HumanEval/66\n",
      "HumanEval/67\n",
      "HumanEval/68\n",
      "HumanEval/69\n",
      "HumanEval/70\n",
      "HumanEval/71\n",
      "HumanEval/72\n",
      "HumanEval/73\n",
      "HumanEval/74\n",
      "HumanEval/75\n",
      "HumanEval/76\n",
      "HumanEval/77\n",
      "HumanEval/78\n",
      "HumanEval/79\n",
      "HumanEval/80\n",
      "HumanEval/81\n",
      "HumanEval/82\n",
      "HumanEval/83\n",
      "HumanEval/84\n",
      "HumanEval/85\n",
      "HumanEval/86\n",
      "HumanEval/87\n",
      "HumanEval/88\n",
      "HumanEval/89\n",
      "HumanEval/90\n",
      "HumanEval/91\n",
      "HumanEval/92\n",
      "HumanEval/93\n",
      "HumanEval/94\n",
      "HumanEval/95\n",
      "HumanEval/96\n",
      "HumanEval/97\n",
      "HumanEval/98\n",
      "HumanEval/99\n",
      "HumanEval/100\n",
      "HumanEval/101\n",
      "HumanEval/102\n",
      "HumanEval/103\n",
      "HumanEval/104\n",
      "HumanEval/105\n",
      "HumanEval/106\n",
      "HumanEval/107\n",
      "HumanEval/108\n",
      "HumanEval/109\n",
      "HumanEval/110\n",
      "HumanEval/111\n",
      "HumanEval/112\n",
      "HumanEval/113\n",
      "HumanEval/114\n",
      "HumanEval/115\n",
      "HumanEval/116\n",
      "HumanEval/117\n",
      "HumanEval/118\n",
      "HumanEval/119\n",
      "HumanEval/120\n",
      "HumanEval/121\n",
      "HumanEval/122\n",
      "HumanEval/123\n",
      "HumanEval/124\n",
      "HumanEval/125\n",
      "HumanEval/126\n",
      "HumanEval/127\n",
      "HumanEval/128\n",
      "HumanEval/129\n",
      "HumanEval/130\n",
      "HumanEval/131\n",
      "HumanEval/132\n",
      "HumanEval/133\n",
      "HumanEval/134\n",
      "HumanEval/135\n",
      "HumanEval/136\n",
      "HumanEval/137\n",
      "HumanEval/138\n",
      "HumanEval/139\n",
      "HumanEval/140\n",
      "HumanEval/141\n",
      "HumanEval/142\n",
      "HumanEval/143\n",
      "HumanEval/144\n",
      "HumanEval/145\n",
      "HumanEval/146\n",
      "HumanEval/147\n",
      "HumanEval/148\n",
      "HumanEval/149\n",
      "HumanEval/150\n",
      "HumanEval/151\n",
      "HumanEval/152\n",
      "HumanEval/153\n",
      "HumanEval/154\n",
      "HumanEval/155\n",
      "HumanEval/156\n",
      "HumanEval/157\n",
      "HumanEval/158\n",
      "HumanEval/159\n",
      "HumanEval/160\n",
      "HumanEval/161\n",
      "HumanEval/162\n",
      "HumanEval/163\n",
      "HumanEval/0\n",
      "HumanEval/1\n",
      "HumanEval/2\n",
      "HumanEval/3\n",
      "HumanEval/4\n",
      "HumanEval/5\n",
      "HumanEval/6\n",
      "HumanEval/7\n",
      "HumanEval/8\n",
      "HumanEval/9\n",
      "HumanEval/10\n",
      "HumanEval/11\n",
      "HumanEval/12\n",
      "HumanEval/13\n",
      "HumanEval/14\n",
      "HumanEval/15\n",
      "HumanEval/16\n",
      "HumanEval/17\n",
      "HumanEval/18\n",
      "HumanEval/19\n",
      "HumanEval/20\n",
      "HumanEval/21\n",
      "HumanEval/22\n",
      "HumanEval/23\n",
      "HumanEval/24\n",
      "HumanEval/25\n",
      "HumanEval/26\n",
      "HumanEval/27\n",
      "HumanEval/28\n",
      "HumanEval/29\n",
      "HumanEval/30\n",
      "HumanEval/31\n",
      "HumanEval/32\n",
      "HumanEval/33\n",
      "HumanEval/34\n",
      "HumanEval/35\n",
      "HumanEval/36\n",
      "HumanEval/37\n",
      "HumanEval/38\n",
      "HumanEval/39\n",
      "HumanEval/40\n",
      "HumanEval/41\n",
      "HumanEval/42\n",
      "HumanEval/43\n",
      "HumanEval/44\n",
      "HumanEval/45\n",
      "HumanEval/46\n",
      "HumanEval/47\n",
      "HumanEval/48\n",
      "HumanEval/49\n",
      "HumanEval/50\n",
      "HumanEval/51\n",
      "HumanEval/52\n",
      "HumanEval/53\n",
      "HumanEval/54\n",
      "HumanEval/55\n",
      "HumanEval/56\n",
      "HumanEval/57\n",
      "HumanEval/58\n",
      "HumanEval/59\n",
      "HumanEval/60\n",
      "HumanEval/61\n",
      "HumanEval/62\n",
      "HumanEval/63\n",
      "HumanEval/64\n",
      "HumanEval/65\n",
      "HumanEval/66\n",
      "HumanEval/67\n",
      "HumanEval/68\n",
      "HumanEval/69\n",
      "HumanEval/70\n",
      "HumanEval/71\n",
      "HumanEval/72\n",
      "HumanEval/73\n",
      "HumanEval/74\n",
      "HumanEval/75\n",
      "HumanEval/76\n",
      "HumanEval/77\n",
      "HumanEval/78\n",
      "HumanEval/79\n",
      "HumanEval/80\n",
      "HumanEval/81\n",
      "HumanEval/82\n",
      "HumanEval/83\n",
      "HumanEval/84\n",
      "HumanEval/85\n",
      "HumanEval/86\n",
      "HumanEval/87\n",
      "HumanEval/88\n",
      "HumanEval/89\n",
      "HumanEval/90\n",
      "HumanEval/91\n",
      "HumanEval/92\n",
      "HumanEval/93\n",
      "HumanEval/94\n",
      "HumanEval/95\n",
      "HumanEval/96\n",
      "HumanEval/97\n",
      "HumanEval/98\n",
      "HumanEval/99\n",
      "HumanEval/100\n",
      "HumanEval/101\n",
      "HumanEval/102\n",
      "HumanEval/103\n",
      "HumanEval/104\n",
      "HumanEval/105\n",
      "HumanEval/106\n",
      "HumanEval/107\n",
      "HumanEval/108\n",
      "HumanEval/109\n",
      "HumanEval/110\n",
      "HumanEval/111\n",
      "HumanEval/112\n",
      "HumanEval/113\n",
      "HumanEval/114\n",
      "HumanEval/115\n",
      "HumanEval/116\n",
      "HumanEval/117\n",
      "HumanEval/118\n",
      "HumanEval/119\n",
      "HumanEval/120\n",
      "HumanEval/121\n",
      "HumanEval/122\n",
      "HumanEval/123\n",
      "HumanEval/124\n",
      "HumanEval/125\n",
      "HumanEval/126\n",
      "HumanEval/127\n",
      "HumanEval/128\n",
      "HumanEval/129\n",
      "HumanEval/130\n",
      "HumanEval/131\n",
      "HumanEval/132\n",
      "HumanEval/133\n",
      "HumanEval/134\n",
      "HumanEval/135\n",
      "HumanEval/136\n",
      "HumanEval/137\n",
      "HumanEval/138\n",
      "HumanEval/139\n",
      "HumanEval/140\n",
      "HumanEval/141\n",
      "HumanEval/142\n",
      "HumanEval/143\n",
      "HumanEval/144\n",
      "HumanEval/145\n",
      "HumanEval/146\n",
      "HumanEval/147\n",
      "HumanEval/148\n",
      "HumanEval/149\n",
      "HumanEval/150\n",
      "HumanEval/151\n",
      "HumanEval/152\n",
      "HumanEval/153\n",
      "HumanEval/154\n",
      "HumanEval/155\n",
      "HumanEval/156\n",
      "HumanEval/157\n",
      "HumanEval/158\n",
      "HumanEval/159\n",
      "HumanEval/160\n",
      "HumanEval/161\n",
      "HumanEval/162\n",
      "HumanEval/163\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import pipeline,AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from evalplus.data import get_human_eval_plus, get_mbpp_plus, write_jsonl\n",
    "\n",
    "gen_type = \"human-eval\"\n",
    "\n",
    "problems = []\n",
    "match gen_type:\n",
    "    case \"human-eval\":\n",
    "        problems = get_human_eval_plus()\n",
    "    case \"mbpp\":\n",
    "        problems = get_mbpp_plus()\n",
    "\n",
    "\n",
    "num_samples_per_task = 1\n",
    "\n",
    "def run_gen(path):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    p_model = PeftModel.from_pretrained(model,path)\n",
    "    model = p_model.merge_and_unload()\n",
    "    \n",
    "    code_generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, device=\"cuda\")\n",
    "    samples = []\n",
    "    for task_id, problem in problems.items():\n",
    "        tasksplit = task_id.split(\"/\")\n",
    "        #if tasksplit[0] == \"Mbpp\" and int(tasksplit[1]) < 601: continue\n",
    "        for _ in range(num_samples_per_task):\n",
    "            samples.append(dict(\n",
    "                task_id=task_id,\n",
    "                completion=generate_one_completion(task_id,problem,code_generator,gen_type)\n",
    "                ))\n",
    "    return samples\n",
    "\n",
    "for num in [2,6]:\n",
    "    path = f\"results/tagged/checkpoint-{num}\"\n",
    "    samples = run_gen(path)\n",
    "    write_jsonl(f\"{gen_type}/results/tagged/{model_name}-{num}.jsonl\", samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4672.738674,
   "end_time": "2024-08-15T10:44:56.076186",
   "environment_variables": {},
   "exception": null,
   "input_path": "test-model.ipynb",
   "output_path": "test-model-out.ipynb",
   "parameters": {},
   "start_time": "2024-08-15T09:27:03.337512",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
