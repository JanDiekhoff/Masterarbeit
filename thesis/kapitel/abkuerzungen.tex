\newacronym{adam}{Adam}{adaptive moment estimation}
\newacronym{ai}{AI}{artificial intelligence}
\newacronym{ast}{AST}{abstract syntax tree}
\newacronym{cot}{CoT}{chain of thought}
\newacronym{dora}{DoRA}{weight-decomposed low-rank adaptation}
\newacronym{fnn}{FNN}{feedfoward neural network}
\newacronym{gpt}{GPT}{generative pre-trained transformer}
\newacronym{gpu}{GPU}{graphical processing unit}
\newacronym{icl}{ICL}{in-context learning}
\newacronym{llm}{LLM}{large language model}
\newacronym{lm}{LM}{language model}
\newacronym{lora}{LoRA}{low-rank adaptation}
\newacronym{mbpp}{MBPP}{Mostly Basic Programming Problems}
\newacronym{ml}{ML}{machine learning}
\newacronym{nlg}{NLG}{natural language generation}
\newacronym{nlp}{NLP}{natural language processing}
\newacronym{nlu}{NLU}{natural language understanding}
\newacronym{peft}{PEFT}{parameter-efficient fine-tuning}
\newacronym{qlora}{QLoRA}{quantized low-rank adaptation}
\newacronym{qdora}{QDoRA}{quantized weight-decomposed low-rank adaptation}
\newacronym{regex}{regex}{regular expression}
\newacronym{rnn}{RNN}{recurrent neural network}
\newacronym{relu}{ReLU}{rectified linear unit}
\newacronym{wsl}{WSL}{Windows subsystem for Linux}

%\begin{acronym}[NLP]
%    \acrodef{nlp}[NLP]{Natural Language Processing}
%\end{acronym}
