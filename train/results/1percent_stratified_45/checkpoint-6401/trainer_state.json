{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999218933062564,
  "eval_steps": 1000,
  "global_step": 6401,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0039053346871826917,
      "grad_norm": 1.4763494729995728,
      "learning_rate": 9.9609436025621e-05,
      "loss": 2.1277,
      "step": 25
    },
    {
      "epoch": 0.007810669374365383,
      "grad_norm": 1.3312056064605713,
      "learning_rate": 9.921887205124199e-05,
      "loss": 1.7552,
      "step": 50
    },
    {
      "epoch": 0.011716004061548074,
      "grad_norm": 0.929668664932251,
      "learning_rate": 9.8828308076863e-05,
      "loss": 1.5897,
      "step": 75
    },
    {
      "epoch": 0.015621338748730767,
      "grad_norm": 1.1300644874572754,
      "learning_rate": 9.843774410248398e-05,
      "loss": 1.5823,
      "step": 100
    },
    {
      "epoch": 0.01952667343591346,
      "grad_norm": 1.462064504623413,
      "learning_rate": 9.804718012810498e-05,
      "loss": 1.5221,
      "step": 125
    },
    {
      "epoch": 0.02343200812309615,
      "grad_norm": 0.8335881233215332,
      "learning_rate": 9.765661615372598e-05,
      "loss": 1.5314,
      "step": 150
    },
    {
      "epoch": 0.02733734281027884,
      "grad_norm": 2.0097782611846924,
      "learning_rate": 9.726605217934698e-05,
      "loss": 1.4972,
      "step": 175
    },
    {
      "epoch": 0.031242677497461534,
      "grad_norm": 1.4685038328170776,
      "learning_rate": 9.687548820496799e-05,
      "loss": 1.5007,
      "step": 200
    },
    {
      "epoch": 0.03514801218464422,
      "grad_norm": 1.5708566904067993,
      "learning_rate": 9.648492423058899e-05,
      "loss": 1.4135,
      "step": 225
    },
    {
      "epoch": 0.03905334687182692,
      "grad_norm": 1.1746795177459717,
      "learning_rate": 9.609436025620997e-05,
      "loss": 1.4763,
      "step": 250
    },
    {
      "epoch": 0.04295868155900961,
      "grad_norm": 1.1374479532241821,
      "learning_rate": 9.570379628183097e-05,
      "loss": 1.3983,
      "step": 275
    },
    {
      "epoch": 0.0468640162461923,
      "grad_norm": 1.27229642868042,
      "learning_rate": 9.531323230745196e-05,
      "loss": 1.4648,
      "step": 300
    },
    {
      "epoch": 0.05076935093337499,
      "grad_norm": 1.2441561222076416,
      "learning_rate": 9.492266833307296e-05,
      "loss": 1.4747,
      "step": 325
    },
    {
      "epoch": 0.05467468562055768,
      "grad_norm": 0.9706517457962036,
      "learning_rate": 9.453210435869396e-05,
      "loss": 1.4448,
      "step": 350
    },
    {
      "epoch": 0.05858002030774037,
      "grad_norm": 0.8361151814460754,
      "learning_rate": 9.414154038431495e-05,
      "loss": 1.4307,
      "step": 375
    },
    {
      "epoch": 0.06248535499492307,
      "grad_norm": 0.8806796669960022,
      "learning_rate": 9.375097640993595e-05,
      "loss": 1.4313,
      "step": 400
    },
    {
      "epoch": 0.06639068968210575,
      "grad_norm": 0.7703037261962891,
      "learning_rate": 9.336041243555694e-05,
      "loss": 1.434,
      "step": 425
    },
    {
      "epoch": 0.07029602436928845,
      "grad_norm": 0.8223084211349487,
      "learning_rate": 9.296984846117794e-05,
      "loss": 1.4264,
      "step": 450
    },
    {
      "epoch": 0.07420135905647114,
      "grad_norm": 1.0480761528015137,
      "learning_rate": 9.257928448679894e-05,
      "loss": 1.3693,
      "step": 475
    },
    {
      "epoch": 0.07810669374365384,
      "grad_norm": 0.863487958908081,
      "learning_rate": 9.218872051241993e-05,
      "loss": 1.4248,
      "step": 500
    },
    {
      "epoch": 0.08201202843083652,
      "grad_norm": 0.7272910475730896,
      "learning_rate": 9.179815653804093e-05,
      "loss": 1.4546,
      "step": 525
    },
    {
      "epoch": 0.08591736311801922,
      "grad_norm": 1.2515255212783813,
      "learning_rate": 9.140759256366193e-05,
      "loss": 1.4344,
      "step": 550
    },
    {
      "epoch": 0.08982269780520191,
      "grad_norm": 0.8335232734680176,
      "learning_rate": 9.101702858928293e-05,
      "loss": 1.3875,
      "step": 575
    },
    {
      "epoch": 0.0937280324923846,
      "grad_norm": 0.9101013541221619,
      "learning_rate": 9.062646461490393e-05,
      "loss": 1.4254,
      "step": 600
    },
    {
      "epoch": 0.09763336717956729,
      "grad_norm": 1.2119026184082031,
      "learning_rate": 9.023590064052492e-05,
      "loss": 1.4591,
      "step": 625
    },
    {
      "epoch": 0.10153870186674999,
      "grad_norm": 2.799138069152832,
      "learning_rate": 8.984533666614592e-05,
      "loss": 1.4894,
      "step": 650
    },
    {
      "epoch": 0.10544403655393267,
      "grad_norm": 0.9789898991584778,
      "learning_rate": 8.945477269176692e-05,
      "loss": 1.4018,
      "step": 675
    },
    {
      "epoch": 0.10934937124111536,
      "grad_norm": 1.011104702949524,
      "learning_rate": 8.906420871738791e-05,
      "loss": 1.438,
      "step": 700
    },
    {
      "epoch": 0.11325470592829806,
      "grad_norm": 1.0065643787384033,
      "learning_rate": 8.867364474300891e-05,
      "loss": 1.4527,
      "step": 725
    },
    {
      "epoch": 0.11716004061548074,
      "grad_norm": 0.782344400882721,
      "learning_rate": 8.828308076862991e-05,
      "loss": 1.4718,
      "step": 750
    },
    {
      "epoch": 0.12106537530266344,
      "grad_norm": 0.6812836527824402,
      "learning_rate": 8.78925167942509e-05,
      "loss": 1.4089,
      "step": 775
    },
    {
      "epoch": 0.12497070998984613,
      "grad_norm": 0.9686892628669739,
      "learning_rate": 8.75019528198719e-05,
      "loss": 1.4211,
      "step": 800
    },
    {
      "epoch": 0.12887604467702882,
      "grad_norm": 0.9966545104980469,
      "learning_rate": 8.711138884549289e-05,
      "loss": 1.4205,
      "step": 825
    },
    {
      "epoch": 0.1327813793642115,
      "grad_norm": 1.032671570777893,
      "learning_rate": 8.672082487111389e-05,
      "loss": 1.418,
      "step": 850
    },
    {
      "epoch": 0.1366867140513942,
      "grad_norm": 0.9866138100624084,
      "learning_rate": 8.633026089673489e-05,
      "loss": 1.3789,
      "step": 875
    },
    {
      "epoch": 0.1405920487385769,
      "grad_norm": 1.1085788011550903,
      "learning_rate": 8.593969692235589e-05,
      "loss": 1.4584,
      "step": 900
    },
    {
      "epoch": 0.1444973834257596,
      "grad_norm": 1.0397107601165771,
      "learning_rate": 8.554913294797689e-05,
      "loss": 1.4112,
      "step": 925
    },
    {
      "epoch": 0.14840271811294228,
      "grad_norm": 0.7966607809066772,
      "learning_rate": 8.515856897359788e-05,
      "loss": 1.3845,
      "step": 950
    },
    {
      "epoch": 0.15230805280012497,
      "grad_norm": 0.8755033016204834,
      "learning_rate": 8.476800499921888e-05,
      "loss": 1.457,
      "step": 975
    },
    {
      "epoch": 0.15621338748730768,
      "grad_norm": 0.9106577038764954,
      "learning_rate": 8.437744102483988e-05,
      "loss": 1.3876,
      "step": 1000
    },
    {
      "epoch": 0.15621338748730768,
      "eval_loss": 1.4112004041671753,
      "eval_runtime": 1621.1548,
      "eval_samples_per_second": 6.318,
      "eval_steps_per_second": 6.318,
      "step": 1000
    },
    {
      "epoch": 0.16011872217449036,
      "grad_norm": 0.9092069268226624,
      "learning_rate": 8.398687705046087e-05,
      "loss": 1.4679,
      "step": 1025
    },
    {
      "epoch": 0.16402405686167304,
      "grad_norm": 1.6133460998535156,
      "learning_rate": 8.359631307608187e-05,
      "loss": 1.4102,
      "step": 1050
    },
    {
      "epoch": 0.16792939154885575,
      "grad_norm": 0.8722118139266968,
      "learning_rate": 8.320574910170287e-05,
      "loss": 1.4054,
      "step": 1075
    },
    {
      "epoch": 0.17183472623603843,
      "grad_norm": 0.8725088834762573,
      "learning_rate": 8.281518512732386e-05,
      "loss": 1.4209,
      "step": 1100
    },
    {
      "epoch": 0.17574006092322111,
      "grad_norm": 1.065869688987732,
      "learning_rate": 8.242462115294486e-05,
      "loss": 1.362,
      "step": 1125
    },
    {
      "epoch": 0.17964539561040382,
      "grad_norm": 0.6902753710746765,
      "learning_rate": 8.203405717856584e-05,
      "loss": 1.4295,
      "step": 1150
    },
    {
      "epoch": 0.1835507302975865,
      "grad_norm": 0.722829282283783,
      "learning_rate": 8.164349320418685e-05,
      "loss": 1.3557,
      "step": 1175
    },
    {
      "epoch": 0.1874560649847692,
      "grad_norm": 1.6030093431472778,
      "learning_rate": 8.125292922980785e-05,
      "loss": 1.4076,
      "step": 1200
    },
    {
      "epoch": 0.1913613996719519,
      "grad_norm": 0.6739567518234253,
      "learning_rate": 8.086236525542883e-05,
      "loss": 1.3668,
      "step": 1225
    },
    {
      "epoch": 0.19526673435913458,
      "grad_norm": 1.3481837511062622,
      "learning_rate": 8.047180128104984e-05,
      "loss": 1.3986,
      "step": 1250
    },
    {
      "epoch": 0.19917206904631726,
      "grad_norm": 0.8955158591270447,
      "learning_rate": 8.008123730667084e-05,
      "loss": 1.3749,
      "step": 1275
    },
    {
      "epoch": 0.20307740373349997,
      "grad_norm": 1.315308690071106,
      "learning_rate": 7.969067333229184e-05,
      "loss": 1.4145,
      "step": 1300
    },
    {
      "epoch": 0.20698273842068265,
      "grad_norm": 0.9556869268417358,
      "learning_rate": 7.930010935791284e-05,
      "loss": 1.4249,
      "step": 1325
    },
    {
      "epoch": 0.21088807310786534,
      "grad_norm": 0.7596988081932068,
      "learning_rate": 7.890954538353383e-05,
      "loss": 1.3593,
      "step": 1350
    },
    {
      "epoch": 0.21479340779504805,
      "grad_norm": 0.8614522218704224,
      "learning_rate": 7.851898140915483e-05,
      "loss": 1.3839,
      "step": 1375
    },
    {
      "epoch": 0.21869874248223073,
      "grad_norm": 0.9098691940307617,
      "learning_rate": 7.812841743477583e-05,
      "loss": 1.399,
      "step": 1400
    },
    {
      "epoch": 0.2226040771694134,
      "grad_norm": 0.8798898458480835,
      "learning_rate": 7.773785346039681e-05,
      "loss": 1.4213,
      "step": 1425
    },
    {
      "epoch": 0.22650941185659612,
      "grad_norm": 0.7275555729866028,
      "learning_rate": 7.734728948601782e-05,
      "loss": 1.4179,
      "step": 1450
    },
    {
      "epoch": 0.2304147465437788,
      "grad_norm": 0.9096347689628601,
      "learning_rate": 7.69567255116388e-05,
      "loss": 1.3814,
      "step": 1475
    },
    {
      "epoch": 0.23432008123096149,
      "grad_norm": 0.8505092859268188,
      "learning_rate": 7.65661615372598e-05,
      "loss": 1.3813,
      "step": 1500
    },
    {
      "epoch": 0.2382254159181442,
      "grad_norm": 0.7015337944030762,
      "learning_rate": 7.61755975628808e-05,
      "loss": 1.4225,
      "step": 1525
    },
    {
      "epoch": 0.24213075060532688,
      "grad_norm": 1.143351674079895,
      "learning_rate": 7.578503358850179e-05,
      "loss": 1.3685,
      "step": 1550
    },
    {
      "epoch": 0.24603608529250956,
      "grad_norm": 1.5683960914611816,
      "learning_rate": 7.539446961412279e-05,
      "loss": 1.3962,
      "step": 1575
    },
    {
      "epoch": 0.24994141997969227,
      "grad_norm": 1.544646978378296,
      "learning_rate": 7.50039056397438e-05,
      "loss": 1.374,
      "step": 1600
    },
    {
      "epoch": 0.25384675466687495,
      "grad_norm": 1.0173366069793701,
      "learning_rate": 7.46133416653648e-05,
      "loss": 1.3695,
      "step": 1625
    },
    {
      "epoch": 0.25775208935405763,
      "grad_norm": 1.0145901441574097,
      "learning_rate": 7.42227776909858e-05,
      "loss": 1.4294,
      "step": 1650
    },
    {
      "epoch": 0.2616574240412403,
      "grad_norm": 0.7746893167495728,
      "learning_rate": 7.383221371660678e-05,
      "loss": 1.4144,
      "step": 1675
    },
    {
      "epoch": 0.265562758728423,
      "grad_norm": 0.7983056306838989,
      "learning_rate": 7.344164974222778e-05,
      "loss": 1.4359,
      "step": 1700
    },
    {
      "epoch": 0.26946809341560574,
      "grad_norm": 0.9755007028579712,
      "learning_rate": 7.305108576784879e-05,
      "loss": 1.408,
      "step": 1725
    },
    {
      "epoch": 0.2733734281027884,
      "grad_norm": 0.9977045059204102,
      "learning_rate": 7.266052179346977e-05,
      "loss": 1.3715,
      "step": 1750
    },
    {
      "epoch": 0.2772787627899711,
      "grad_norm": 0.8164525628089905,
      "learning_rate": 7.226995781909077e-05,
      "loss": 1.4223,
      "step": 1775
    },
    {
      "epoch": 0.2811840974771538,
      "grad_norm": 0.6733083724975586,
      "learning_rate": 7.187939384471176e-05,
      "loss": 1.3726,
      "step": 1800
    },
    {
      "epoch": 0.28508943216433646,
      "grad_norm": 0.6322495937347412,
      "learning_rate": 7.148882987033276e-05,
      "loss": 1.3798,
      "step": 1825
    },
    {
      "epoch": 0.2889947668515192,
      "grad_norm": 0.6121037602424622,
      "learning_rate": 7.109826589595376e-05,
      "loss": 1.3761,
      "step": 1850
    },
    {
      "epoch": 0.2929001015387019,
      "grad_norm": 0.931926429271698,
      "learning_rate": 7.070770192157475e-05,
      "loss": 1.424,
      "step": 1875
    },
    {
      "epoch": 0.29680543622588457,
      "grad_norm": 0.7890235185623169,
      "learning_rate": 7.031713794719575e-05,
      "loss": 1.3885,
      "step": 1900
    },
    {
      "epoch": 0.30071077091306725,
      "grad_norm": 0.8960729837417603,
      "learning_rate": 6.992657397281675e-05,
      "loss": 1.3861,
      "step": 1925
    },
    {
      "epoch": 0.30461610560024993,
      "grad_norm": 0.9343369007110596,
      "learning_rate": 6.953600999843774e-05,
      "loss": 1.4726,
      "step": 1950
    },
    {
      "epoch": 0.3085214402874326,
      "grad_norm": 0.8326055407524109,
      "learning_rate": 6.914544602405874e-05,
      "loss": 1.4097,
      "step": 1975
    },
    {
      "epoch": 0.31242677497461535,
      "grad_norm": 0.7789708971977234,
      "learning_rate": 6.875488204967974e-05,
      "loss": 1.429,
      "step": 2000
    },
    {
      "epoch": 0.31242677497461535,
      "eval_loss": 1.3924791812896729,
      "eval_runtime": 1646.754,
      "eval_samples_per_second": 6.22,
      "eval_steps_per_second": 6.22,
      "step": 2000
    },
    {
      "epoch": 0.31633210966179803,
      "grad_norm": 0.9438354969024658,
      "learning_rate": 6.836431807530074e-05,
      "loss": 1.4196,
      "step": 2025
    },
    {
      "epoch": 0.3202374443489807,
      "grad_norm": 1.021217942237854,
      "learning_rate": 6.797375410092174e-05,
      "loss": 1.3891,
      "step": 2050
    },
    {
      "epoch": 0.3241427790361634,
      "grad_norm": 0.6499137282371521,
      "learning_rate": 6.759881268551789e-05,
      "loss": 1.4024,
      "step": 2075
    },
    {
      "epoch": 0.3280481137233461,
      "grad_norm": 0.6098520755767822,
      "learning_rate": 6.72082487111389e-05,
      "loss": 1.3855,
      "step": 2100
    },
    {
      "epoch": 0.33195344841052876,
      "grad_norm": 0.8999474048614502,
      "learning_rate": 6.68176847367599e-05,
      "loss": 1.3933,
      "step": 2125
    },
    {
      "epoch": 0.3358587830977115,
      "grad_norm": 1.0524059534072876,
      "learning_rate": 6.642712076238088e-05,
      "loss": 1.4384,
      "step": 2150
    },
    {
      "epoch": 0.3397641177848942,
      "grad_norm": 0.6331286430358887,
      "learning_rate": 6.603655678800188e-05,
      "loss": 1.405,
      "step": 2175
    },
    {
      "epoch": 0.34366945247207686,
      "grad_norm": 0.8113471269607544,
      "learning_rate": 6.564599281362287e-05,
      "loss": 1.3802,
      "step": 2200
    },
    {
      "epoch": 0.34757478715925955,
      "grad_norm": 1.1798409223556519,
      "learning_rate": 6.525542883924387e-05,
      "loss": 1.4319,
      "step": 2225
    },
    {
      "epoch": 0.35148012184644223,
      "grad_norm": 0.6473181843757629,
      "learning_rate": 6.486486486486487e-05,
      "loss": 1.4324,
      "step": 2250
    },
    {
      "epoch": 0.3553854565336249,
      "grad_norm": 0.6822458505630493,
      "learning_rate": 6.447430089048586e-05,
      "loss": 1.4275,
      "step": 2275
    },
    {
      "epoch": 0.35929079122080765,
      "grad_norm": 0.9384357333183289,
      "learning_rate": 6.408373691610686e-05,
      "loss": 1.3236,
      "step": 2300
    },
    {
      "epoch": 0.36319612590799033,
      "grad_norm": 1.223878264427185,
      "learning_rate": 6.369317294172786e-05,
      "loss": 1.4209,
      "step": 2325
    },
    {
      "epoch": 0.367101460595173,
      "grad_norm": 1.0539546012878418,
      "learning_rate": 6.330260896734885e-05,
      "loss": 1.4177,
      "step": 2350
    },
    {
      "epoch": 0.3710067952823557,
      "grad_norm": 1.5849878787994385,
      "learning_rate": 6.291204499296985e-05,
      "loss": 1.3948,
      "step": 2375
    },
    {
      "epoch": 0.3749121299695384,
      "grad_norm": 0.65977543592453,
      "learning_rate": 6.252148101859084e-05,
      "loss": 1.3443,
      "step": 2400
    },
    {
      "epoch": 0.37881746465672106,
      "grad_norm": 0.6692675352096558,
      "learning_rate": 6.213091704421184e-05,
      "loss": 1.4296,
      "step": 2425
    },
    {
      "epoch": 0.3827227993439038,
      "grad_norm": 0.7789745330810547,
      "learning_rate": 6.174035306983284e-05,
      "loss": 1.3537,
      "step": 2450
    },
    {
      "epoch": 0.3866281340310865,
      "grad_norm": 0.7101157903671265,
      "learning_rate": 6.134978909545384e-05,
      "loss": 1.3509,
      "step": 2475
    },
    {
      "epoch": 0.39053346871826916,
      "grad_norm": 1.02878999710083,
      "learning_rate": 6.0959225121074834e-05,
      "loss": 1.3793,
      "step": 2500
    },
    {
      "epoch": 0.39443880340545184,
      "grad_norm": 0.671149492263794,
      "learning_rate": 6.056866114669583e-05,
      "loss": 1.4525,
      "step": 2525
    },
    {
      "epoch": 0.3983441380926345,
      "grad_norm": 0.8248345851898193,
      "learning_rate": 6.0193719731291985e-05,
      "loss": 1.4034,
      "step": 2550
    },
    {
      "epoch": 0.4022494727798172,
      "grad_norm": 0.9510210752487183,
      "learning_rate": 5.9803155756912986e-05,
      "loss": 1.3414,
      "step": 2575
    },
    {
      "epoch": 0.40615480746699995,
      "grad_norm": 0.5867644548416138,
      "learning_rate": 5.941259178253398e-05,
      "loss": 1.3767,
      "step": 2600
    },
    {
      "epoch": 0.4100601421541826,
      "grad_norm": 0.9295007586479187,
      "learning_rate": 5.902202780815498e-05,
      "loss": 1.4109,
      "step": 2625
    },
    {
      "epoch": 0.4139654768413653,
      "grad_norm": 0.9668832421302795,
      "learning_rate": 5.863146383377598e-05,
      "loss": 1.4209,
      "step": 2650
    },
    {
      "epoch": 0.417870811528548,
      "grad_norm": 0.9404669404029846,
      "learning_rate": 5.824089985939697e-05,
      "loss": 1.4133,
      "step": 2675
    },
    {
      "epoch": 0.4217761462157307,
      "grad_norm": 0.7666005492210388,
      "learning_rate": 5.785033588501797e-05,
      "loss": 1.4055,
      "step": 2700
    },
    {
      "epoch": 0.42568148090291336,
      "grad_norm": 1.1044992208480835,
      "learning_rate": 5.745977191063897e-05,
      "loss": 1.3343,
      "step": 2725
    },
    {
      "epoch": 0.4295868155900961,
      "grad_norm": 0.7680078148841858,
      "learning_rate": 5.706920793625996e-05,
      "loss": 1.3626,
      "step": 2750
    },
    {
      "epoch": 0.4334921502772788,
      "grad_norm": 0.9791789054870605,
      "learning_rate": 5.667864396188096e-05,
      "loss": 1.4015,
      "step": 2775
    },
    {
      "epoch": 0.43739748496446146,
      "grad_norm": 0.7576345801353455,
      "learning_rate": 5.6288079987501954e-05,
      "loss": 1.409,
      "step": 2800
    },
    {
      "epoch": 0.44130281965164414,
      "grad_norm": 0.8978610038757324,
      "learning_rate": 5.5897516013122955e-05,
      "loss": 1.3763,
      "step": 2825
    },
    {
      "epoch": 0.4452081543388268,
      "grad_norm": 1.0526325702667236,
      "learning_rate": 5.5506952038743955e-05,
      "loss": 1.3658,
      "step": 2850
    },
    {
      "epoch": 0.4491134890260095,
      "grad_norm": 0.6741896867752075,
      "learning_rate": 5.511638806436494e-05,
      "loss": 1.396,
      "step": 2875
    },
    {
      "epoch": 0.45301882371319224,
      "grad_norm": 0.8018696308135986,
      "learning_rate": 5.4725824089985944e-05,
      "loss": 1.3707,
      "step": 2900
    },
    {
      "epoch": 0.4569241584003749,
      "grad_norm": 0.6517796516418457,
      "learning_rate": 5.433526011560693e-05,
      "loss": 1.3636,
      "step": 2925
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 0.6891139149665833,
      "learning_rate": 5.394469614122793e-05,
      "loss": 1.4186,
      "step": 2950
    },
    {
      "epoch": 0.4647348277747403,
      "grad_norm": 1.1286011934280396,
      "learning_rate": 5.355413216684893e-05,
      "loss": 1.35,
      "step": 2975
    },
    {
      "epoch": 0.46864016246192297,
      "grad_norm": 0.7032376527786255,
      "learning_rate": 5.316356819246993e-05,
      "loss": 1.4404,
      "step": 3000
    },
    {
      "epoch": 0.46864016246192297,
      "eval_loss": 1.3823872804641724,
      "eval_runtime": 1655.6979,
      "eval_samples_per_second": 6.186,
      "eval_steps_per_second": 6.186,
      "step": 3000
    },
    {
      "epoch": 0.47254549714910565,
      "grad_norm": 0.7714300751686096,
      "learning_rate": 5.277300421809093e-05,
      "loss": 1.3916,
      "step": 3025
    },
    {
      "epoch": 0.4764508318362884,
      "grad_norm": 1.5552830696105957,
      "learning_rate": 5.238244024371193e-05,
      "loss": 1.3618,
      "step": 3050
    },
    {
      "epoch": 0.4803561665234711,
      "grad_norm": 0.6488907337188721,
      "learning_rate": 5.1991876269332917e-05,
      "loss": 1.4084,
      "step": 3075
    },
    {
      "epoch": 0.48426150121065376,
      "grad_norm": 0.8546695709228516,
      "learning_rate": 5.160131229495392e-05,
      "loss": 1.4334,
      "step": 3100
    },
    {
      "epoch": 0.48816683589783644,
      "grad_norm": 1.0892606973648071,
      "learning_rate": 5.121074832057491e-05,
      "loss": 1.383,
      "step": 3125
    },
    {
      "epoch": 0.4920721705850191,
      "grad_norm": 0.9896228909492493,
      "learning_rate": 5.082018434619591e-05,
      "loss": 1.4417,
      "step": 3150
    },
    {
      "epoch": 0.4959775052722018,
      "grad_norm": 0.7663734555244446,
      "learning_rate": 5.0429620371816914e-05,
      "loss": 1.3472,
      "step": 3175
    },
    {
      "epoch": 0.49988283995938454,
      "grad_norm": 0.6798304915428162,
      "learning_rate": 5.00390563974379e-05,
      "loss": 1.4118,
      "step": 3200
    },
    {
      "epoch": 0.5037881746465672,
      "grad_norm": 0.7987580299377441,
      "learning_rate": 4.96484924230589e-05,
      "loss": 1.3594,
      "step": 3225
    },
    {
      "epoch": 0.5076935093337499,
      "grad_norm": 0.7924529910087585,
      "learning_rate": 4.9257928448679896e-05,
      "loss": 1.3412,
      "step": 3250
    },
    {
      "epoch": 0.5115988440209326,
      "grad_norm": 0.9347301125526428,
      "learning_rate": 4.886736447430089e-05,
      "loss": 1.3469,
      "step": 3275
    },
    {
      "epoch": 0.5155041787081153,
      "grad_norm": 1.0230127573013306,
      "learning_rate": 4.8476800499921884e-05,
      "loss": 1.3787,
      "step": 3300
    },
    {
      "epoch": 0.519409513395298,
      "grad_norm": 0.7808129787445068,
      "learning_rate": 4.8086236525542885e-05,
      "loss": 1.3463,
      "step": 3325
    },
    {
      "epoch": 0.5233148480824806,
      "grad_norm": 1.3984512090682983,
      "learning_rate": 4.7695672551163886e-05,
      "loss": 1.3868,
      "step": 3350
    },
    {
      "epoch": 0.5272201827696633,
      "grad_norm": 0.841855525970459,
      "learning_rate": 4.730510857678488e-05,
      "loss": 1.4084,
      "step": 3375
    },
    {
      "epoch": 0.531125517456846,
      "grad_norm": 1.046021819114685,
      "learning_rate": 4.6914544602405875e-05,
      "loss": 1.3842,
      "step": 3400
    },
    {
      "epoch": 0.5350308521440288,
      "grad_norm": 0.8401737809181213,
      "learning_rate": 4.6523980628026876e-05,
      "loss": 1.3786,
      "step": 3425
    },
    {
      "epoch": 0.5389361868312115,
      "grad_norm": 1.1475027799606323,
      "learning_rate": 4.613341665364787e-05,
      "loss": 1.3938,
      "step": 3450
    },
    {
      "epoch": 0.5428415215183942,
      "grad_norm": 1.114848017692566,
      "learning_rate": 4.5742852679268864e-05,
      "loss": 1.4275,
      "step": 3475
    },
    {
      "epoch": 0.5467468562055768,
      "grad_norm": 0.6435806751251221,
      "learning_rate": 4.5352288704889865e-05,
      "loss": 1.3699,
      "step": 3500
    },
    {
      "epoch": 0.5506521908927595,
      "grad_norm": 0.7356697916984558,
      "learning_rate": 4.4961724730510866e-05,
      "loss": 1.3656,
      "step": 3525
    },
    {
      "epoch": 0.5545575255799422,
      "grad_norm": 1.09589684009552,
      "learning_rate": 4.457116075613186e-05,
      "loss": 1.3602,
      "step": 3550
    },
    {
      "epoch": 0.5584628602671249,
      "grad_norm": 0.7905699610710144,
      "learning_rate": 4.4180596781752854e-05,
      "loss": 1.3715,
      "step": 3575
    },
    {
      "epoch": 0.5623681949543076,
      "grad_norm": 0.8297883868217468,
      "learning_rate": 4.379003280737385e-05,
      "loss": 1.4185,
      "step": 3600
    },
    {
      "epoch": 0.5662735296414902,
      "grad_norm": 0.9162718057632446,
      "learning_rate": 4.339946883299484e-05,
      "loss": 1.3602,
      "step": 3625
    },
    {
      "epoch": 0.5701788643286729,
      "grad_norm": 0.763048529624939,
      "learning_rate": 4.3008904858615843e-05,
      "loss": 1.3617,
      "step": 3650
    },
    {
      "epoch": 0.5740841990158556,
      "grad_norm": 0.595098614692688,
      "learning_rate": 4.261834088423684e-05,
      "loss": 1.3569,
      "step": 3675
    },
    {
      "epoch": 0.5779895337030384,
      "grad_norm": 0.5940783023834229,
      "learning_rate": 4.222777690985784e-05,
      "loss": 1.3656,
      "step": 3700
    },
    {
      "epoch": 0.5818948683902211,
      "grad_norm": 0.8302678465843201,
      "learning_rate": 4.183721293547883e-05,
      "loss": 1.3493,
      "step": 3725
    },
    {
      "epoch": 0.5858002030774038,
      "grad_norm": 0.9037550091743469,
      "learning_rate": 4.1446648961099834e-05,
      "loss": 1.3808,
      "step": 3750
    },
    {
      "epoch": 0.5897055377645865,
      "grad_norm": 0.8929495215415955,
      "learning_rate": 4.105608498672083e-05,
      "loss": 1.3658,
      "step": 3775
    },
    {
      "epoch": 0.5936108724517691,
      "grad_norm": 0.5761247277259827,
      "learning_rate": 4.066552101234182e-05,
      "loss": 1.4193,
      "step": 3800
    },
    {
      "epoch": 0.5975162071389518,
      "grad_norm": 0.8047066926956177,
      "learning_rate": 4.0274957037962816e-05,
      "loss": 1.356,
      "step": 3825
    },
    {
      "epoch": 0.6014215418261345,
      "grad_norm": 0.965038537979126,
      "learning_rate": 3.988439306358382e-05,
      "loss": 1.3336,
      "step": 3850
    },
    {
      "epoch": 0.6053268765133172,
      "grad_norm": 0.6776233911514282,
      "learning_rate": 3.949382908920482e-05,
      "loss": 1.3803,
      "step": 3875
    },
    {
      "epoch": 0.6092322112004999,
      "grad_norm": 0.8392130732536316,
      "learning_rate": 3.910326511482581e-05,
      "loss": 1.3896,
      "step": 3900
    },
    {
      "epoch": 0.6131375458876825,
      "grad_norm": 0.702089786529541,
      "learning_rate": 3.8712701140446806e-05,
      "loss": 1.3843,
      "step": 3925
    },
    {
      "epoch": 0.6170428805748652,
      "grad_norm": 0.7156714200973511,
      "learning_rate": 3.832213716606781e-05,
      "loss": 1.3734,
      "step": 3950
    },
    {
      "epoch": 0.6209482152620479,
      "grad_norm": 0.5943379402160645,
      "learning_rate": 3.79315731916888e-05,
      "loss": 1.3594,
      "step": 3975
    },
    {
      "epoch": 0.6248535499492307,
      "grad_norm": 0.9692847728729248,
      "learning_rate": 3.7541009217309796e-05,
      "loss": 1.4571,
      "step": 4000
    },
    {
      "epoch": 0.6248535499492307,
      "eval_loss": 1.37699294090271,
      "eval_runtime": 1621.0572,
      "eval_samples_per_second": 6.318,
      "eval_steps_per_second": 6.318,
      "step": 4000
    },
    {
      "epoch": 0.6287588846364134,
      "grad_norm": 0.8428181409835815,
      "learning_rate": 3.715044524293079e-05,
      "loss": 1.3997,
      "step": 4025
    },
    {
      "epoch": 0.6326642193235961,
      "grad_norm": 0.8015975952148438,
      "learning_rate": 3.675988126855179e-05,
      "loss": 1.4116,
      "step": 4050
    },
    {
      "epoch": 0.6365695540107787,
      "grad_norm": 0.6364414691925049,
      "learning_rate": 3.636931729417279e-05,
      "loss": 1.3681,
      "step": 4075
    },
    {
      "epoch": 0.6404748886979614,
      "grad_norm": 0.9702988862991333,
      "learning_rate": 3.5978753319793786e-05,
      "loss": 1.4011,
      "step": 4100
    },
    {
      "epoch": 0.6443802233851441,
      "grad_norm": 0.9088470935821533,
      "learning_rate": 3.558818934541478e-05,
      "loss": 1.3868,
      "step": 4125
    },
    {
      "epoch": 0.6482855580723268,
      "grad_norm": 0.780589759349823,
      "learning_rate": 3.5197625371035774e-05,
      "loss": 1.3596,
      "step": 4150
    },
    {
      "epoch": 0.6521908927595095,
      "grad_norm": 0.9329619407653809,
      "learning_rate": 3.4807061396656775e-05,
      "loss": 1.405,
      "step": 4175
    },
    {
      "epoch": 0.6560962274466922,
      "grad_norm": 0.7571757435798645,
      "learning_rate": 3.441649742227777e-05,
      "loss": 1.385,
      "step": 4200
    },
    {
      "epoch": 0.6600015621338748,
      "grad_norm": 0.8670351505279541,
      "learning_rate": 3.4025933447898763e-05,
      "loss": 1.3449,
      "step": 4225
    },
    {
      "epoch": 0.6639068968210575,
      "grad_norm": 0.6838398575782776,
      "learning_rate": 3.3635369473519764e-05,
      "loss": 1.3988,
      "step": 4250
    },
    {
      "epoch": 0.6678122315082402,
      "grad_norm": 0.7810453772544861,
      "learning_rate": 3.3244805499140765e-05,
      "loss": 1.4527,
      "step": 4275
    },
    {
      "epoch": 0.671717566195423,
      "grad_norm": 0.7850847244262695,
      "learning_rate": 3.285424152476176e-05,
      "loss": 1.389,
      "step": 4300
    },
    {
      "epoch": 0.6756229008826057,
      "grad_norm": 0.6359183192253113,
      "learning_rate": 3.2463677550382754e-05,
      "loss": 1.3587,
      "step": 4325
    },
    {
      "epoch": 0.6795282355697884,
      "grad_norm": 0.7685272097587585,
      "learning_rate": 3.207311357600375e-05,
      "loss": 1.3419,
      "step": 4350
    },
    {
      "epoch": 0.683433570256971,
      "grad_norm": 0.8491644859313965,
      "learning_rate": 3.168254960162475e-05,
      "loss": 1.4732,
      "step": 4375
    },
    {
      "epoch": 0.6873389049441537,
      "grad_norm": 1.118013620376587,
      "learning_rate": 3.129198562724574e-05,
      "loss": 1.3735,
      "step": 4400
    },
    {
      "epoch": 0.6912442396313364,
      "grad_norm": 0.5600271821022034,
      "learning_rate": 3.0901421652866744e-05,
      "loss": 1.393,
      "step": 4425
    },
    {
      "epoch": 0.6951495743185191,
      "grad_norm": 0.8386671543121338,
      "learning_rate": 3.0510857678487738e-05,
      "loss": 1.3443,
      "step": 4450
    },
    {
      "epoch": 0.6990549090057018,
      "grad_norm": 0.7589930891990662,
      "learning_rate": 3.0120293704108732e-05,
      "loss": 1.3366,
      "step": 4475
    },
    {
      "epoch": 0.7029602436928845,
      "grad_norm": 1.7524293661117554,
      "learning_rate": 2.9729729729729733e-05,
      "loss": 1.3529,
      "step": 4500
    },
    {
      "epoch": 0.7068655783800671,
      "grad_norm": 0.6670259833335876,
      "learning_rate": 2.9339165755350727e-05,
      "loss": 1.3531,
      "step": 4525
    },
    {
      "epoch": 0.7107709130672498,
      "grad_norm": 0.8065944910049438,
      "learning_rate": 2.8948601780971725e-05,
      "loss": 1.3688,
      "step": 4550
    },
    {
      "epoch": 0.7146762477544325,
      "grad_norm": 0.8798961043357849,
      "learning_rate": 2.855803780659272e-05,
      "loss": 1.3577,
      "step": 4575
    },
    {
      "epoch": 0.7185815824416153,
      "grad_norm": 0.8544321060180664,
      "learning_rate": 2.816747383221372e-05,
      "loss": 1.3834,
      "step": 4600
    },
    {
      "epoch": 0.722486917128798,
      "grad_norm": 0.872218668460846,
      "learning_rate": 2.7776909857834714e-05,
      "loss": 1.3638,
      "step": 4625
    },
    {
      "epoch": 0.7263922518159807,
      "grad_norm": 1.2091219425201416,
      "learning_rate": 2.7386345883455712e-05,
      "loss": 1.3656,
      "step": 4650
    },
    {
      "epoch": 0.7302975865031633,
      "grad_norm": 0.7943214774131775,
      "learning_rate": 2.6995781909076706e-05,
      "loss": 1.3066,
      "step": 4675
    },
    {
      "epoch": 0.734202921190346,
      "grad_norm": 1.0366089344024658,
      "learning_rate": 2.6605217934697707e-05,
      "loss": 1.3046,
      "step": 4700
    },
    {
      "epoch": 0.7381082558775287,
      "grad_norm": 0.8225303292274475,
      "learning_rate": 2.62146539603187e-05,
      "loss": 1.3876,
      "step": 4725
    },
    {
      "epoch": 0.7420135905647114,
      "grad_norm": 0.8514026999473572,
      "learning_rate": 2.58240899859397e-05,
      "loss": 1.3628,
      "step": 4750
    },
    {
      "epoch": 0.7459189252518941,
      "grad_norm": 0.9289026856422424,
      "learning_rate": 2.5433526011560693e-05,
      "loss": 1.38,
      "step": 4775
    },
    {
      "epoch": 0.7498242599390768,
      "grad_norm": 0.7579982280731201,
      "learning_rate": 2.5042962037181694e-05,
      "loss": 1.4104,
      "step": 4800
    },
    {
      "epoch": 0.7537295946262594,
      "grad_norm": 0.5789150595664978,
      "learning_rate": 2.465239806280269e-05,
      "loss": 1.3314,
      "step": 4825
    },
    {
      "epoch": 0.7576349293134421,
      "grad_norm": 0.6666375398635864,
      "learning_rate": 2.4261834088423685e-05,
      "loss": 1.3488,
      "step": 4850
    },
    {
      "epoch": 0.7615402640006248,
      "grad_norm": 0.6650744080543518,
      "learning_rate": 2.387127011404468e-05,
      "loss": 1.3737,
      "step": 4875
    },
    {
      "epoch": 0.7654455986878076,
      "grad_norm": 0.7812045216560364,
      "learning_rate": 2.3480706139665677e-05,
      "loss": 1.356,
      "step": 4900
    },
    {
      "epoch": 0.7693509333749903,
      "grad_norm": 0.949373185634613,
      "learning_rate": 2.3090142165286675e-05,
      "loss": 1.361,
      "step": 4925
    },
    {
      "epoch": 0.773256268062173,
      "grad_norm": 0.7577349543571472,
      "learning_rate": 2.2699578190907672e-05,
      "loss": 1.4134,
      "step": 4950
    },
    {
      "epoch": 0.7771616027493556,
      "grad_norm": 0.9616401195526123,
      "learning_rate": 2.2309014216528666e-05,
      "loss": 1.3945,
      "step": 4975
    },
    {
      "epoch": 0.7810669374365383,
      "grad_norm": 0.8237420320510864,
      "learning_rate": 2.1918450242149667e-05,
      "loss": 1.3847,
      "step": 5000
    },
    {
      "epoch": 0.7810669374365383,
      "eval_loss": 1.3735631704330444,
      "eval_runtime": 1621.0574,
      "eval_samples_per_second": 6.318,
      "eval_steps_per_second": 6.318,
      "step": 5000
    },
    {
      "epoch": 0.784972272123721,
      "grad_norm": 1.1050138473510742,
      "learning_rate": 2.152788626777066e-05,
      "loss": 1.3841,
      "step": 5025
    },
    {
      "epoch": 0.7888776068109037,
      "grad_norm": 0.8159286975860596,
      "learning_rate": 2.113732229339166e-05,
      "loss": 1.3396,
      "step": 5050
    },
    {
      "epoch": 0.7927829414980864,
      "grad_norm": 0.7311978936195374,
      "learning_rate": 2.0746758319012653e-05,
      "loss": 1.3374,
      "step": 5075
    },
    {
      "epoch": 0.796688276185269,
      "grad_norm": 0.978733479976654,
      "learning_rate": 2.0356194344633654e-05,
      "loss": 1.3674,
      "step": 5100
    },
    {
      "epoch": 0.8005936108724517,
      "grad_norm": 0.5921557545661926,
      "learning_rate": 1.996563037025465e-05,
      "loss": 1.4016,
      "step": 5125
    },
    {
      "epoch": 0.8044989455596344,
      "grad_norm": 1.3846529722213745,
      "learning_rate": 1.9575066395875646e-05,
      "loss": 1.3819,
      "step": 5150
    },
    {
      "epoch": 0.8084042802468171,
      "grad_norm": 1.153941035270691,
      "learning_rate": 1.9184502421496643e-05,
      "loss": 1.4036,
      "step": 5175
    },
    {
      "epoch": 0.8123096149339999,
      "grad_norm": 1.222078561782837,
      "learning_rate": 1.879393844711764e-05,
      "loss": 1.3933,
      "step": 5200
    },
    {
      "epoch": 0.8162149496211826,
      "grad_norm": 0.8932201862335205,
      "learning_rate": 1.8403374472738635e-05,
      "loss": 1.3517,
      "step": 5225
    },
    {
      "epoch": 0.8201202843083653,
      "grad_norm": 0.9220097661018372,
      "learning_rate": 1.8012810498359633e-05,
      "loss": 1.3473,
      "step": 5250
    },
    {
      "epoch": 0.8240256189955479,
      "grad_norm": 1.2295385599136353,
      "learning_rate": 1.762224652398063e-05,
      "loss": 1.3581,
      "step": 5275
    },
    {
      "epoch": 0.8279309536827306,
      "grad_norm": 0.8870292901992798,
      "learning_rate": 1.7231682549601624e-05,
      "loss": 1.3861,
      "step": 5300
    },
    {
      "epoch": 0.8318362883699133,
      "grad_norm": 0.7477444410324097,
      "learning_rate": 1.6841118575222622e-05,
      "loss": 1.3557,
      "step": 5325
    },
    {
      "epoch": 0.835741623057096,
      "grad_norm": 0.7183886170387268,
      "learning_rate": 1.645055460084362e-05,
      "loss": 1.3604,
      "step": 5350
    },
    {
      "epoch": 0.8396469577442787,
      "grad_norm": 0.683977484703064,
      "learning_rate": 1.6059990626464617e-05,
      "loss": 1.3467,
      "step": 5375
    },
    {
      "epoch": 0.8435522924314613,
      "grad_norm": 0.9652218222618103,
      "learning_rate": 1.566942665208561e-05,
      "loss": 1.3665,
      "step": 5400
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.8133140206336975,
      "learning_rate": 1.527886267770661e-05,
      "loss": 1.4019,
      "step": 5425
    },
    {
      "epoch": 0.8513629618058267,
      "grad_norm": 0.7465248703956604,
      "learning_rate": 1.4888298703327605e-05,
      "loss": 1.3975,
      "step": 5450
    },
    {
      "epoch": 0.8552682964930095,
      "grad_norm": 0.7612723708152771,
      "learning_rate": 1.4497734728948604e-05,
      "loss": 1.3875,
      "step": 5475
    },
    {
      "epoch": 0.8591736311801922,
      "grad_norm": 0.6542579531669617,
      "learning_rate": 1.4107170754569598e-05,
      "loss": 1.4542,
      "step": 5500
    },
    {
      "epoch": 0.8630789658673749,
      "grad_norm": 0.8822392821311951,
      "learning_rate": 1.3716606780190597e-05,
      "loss": 1.3549,
      "step": 5525
    },
    {
      "epoch": 0.8669843005545576,
      "grad_norm": 1.7219934463500977,
      "learning_rate": 1.3326042805811592e-05,
      "loss": 1.4008,
      "step": 5550
    },
    {
      "epoch": 0.8708896352417402,
      "grad_norm": 1.0451680421829224,
      "learning_rate": 1.293547883143259e-05,
      "loss": 1.3966,
      "step": 5575
    },
    {
      "epoch": 0.8747949699289229,
      "grad_norm": 1.0544906854629517,
      "learning_rate": 1.2544914857053585e-05,
      "loss": 1.4031,
      "step": 5600
    },
    {
      "epoch": 0.8787003046161056,
      "grad_norm": 0.9319952130317688,
      "learning_rate": 1.2154350882674583e-05,
      "loss": 1.3581,
      "step": 5625
    },
    {
      "epoch": 0.8826056393032883,
      "grad_norm": 1.2545573711395264,
      "learning_rate": 1.176378690829558e-05,
      "loss": 1.3003,
      "step": 5650
    },
    {
      "epoch": 0.886510973990471,
      "grad_norm": 1.2120589017868042,
      "learning_rate": 1.1373222933916576e-05,
      "loss": 1.337,
      "step": 5675
    },
    {
      "epoch": 0.8904163086776536,
      "grad_norm": 0.9295231103897095,
      "learning_rate": 1.0982658959537573e-05,
      "loss": 1.3971,
      "step": 5700
    },
    {
      "epoch": 0.8943216433648363,
      "grad_norm": 0.65184086561203,
      "learning_rate": 1.059209498515857e-05,
      "loss": 1.3704,
      "step": 5725
    },
    {
      "epoch": 0.898226978052019,
      "grad_norm": 0.813244640827179,
      "learning_rate": 1.0201531010779567e-05,
      "loss": 1.3954,
      "step": 5750
    },
    {
      "epoch": 0.9021323127392018,
      "grad_norm": 0.8441548943519592,
      "learning_rate": 9.810967036400563e-06,
      "loss": 1.3477,
      "step": 5775
    },
    {
      "epoch": 0.9060376474263845,
      "grad_norm": 0.706526517868042,
      "learning_rate": 9.42040306202156e-06,
      "loss": 1.3069,
      "step": 5800
    },
    {
      "epoch": 0.9099429821135672,
      "grad_norm": 0.7202579379081726,
      "learning_rate": 9.029839087642556e-06,
      "loss": 1.3417,
      "step": 5825
    },
    {
      "epoch": 0.9138483168007498,
      "grad_norm": 0.6262293457984924,
      "learning_rate": 8.639275113263554e-06,
      "loss": 1.3183,
      "step": 5850
    },
    {
      "epoch": 0.9177536514879325,
      "grad_norm": 0.9493404626846313,
      "learning_rate": 8.24871113888455e-06,
      "loss": 1.3953,
      "step": 5875
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 0.7150434851646423,
      "learning_rate": 7.858147164505545e-06,
      "loss": 1.3847,
      "step": 5900
    },
    {
      "epoch": 0.9255643208622979,
      "grad_norm": 0.8635838031768799,
      "learning_rate": 7.467583190126542e-06,
      "loss": 1.3711,
      "step": 5925
    },
    {
      "epoch": 0.9294696555494806,
      "grad_norm": 1.3370689153671265,
      "learning_rate": 7.077019215747539e-06,
      "loss": 1.3402,
      "step": 5950
    },
    {
      "epoch": 0.9333749902366633,
      "grad_norm": 0.6966661810874939,
      "learning_rate": 6.686455241368536e-06,
      "loss": 1.3872,
      "step": 5975
    },
    {
      "epoch": 0.9372803249238459,
      "grad_norm": 0.64863121509552,
      "learning_rate": 6.295891266989533e-06,
      "loss": 1.3743,
      "step": 6000
    },
    {
      "epoch": 0.9372803249238459,
      "eval_loss": 1.3711369037628174,
      "eval_runtime": 1725.8218,
      "eval_samples_per_second": 5.935,
      "eval_steps_per_second": 5.935,
      "step": 6000
    },
    {
      "epoch": 0.9411856596110286,
      "grad_norm": 0.9568379521369934,
      "learning_rate": 5.90532729261053e-06,
      "loss": 1.3658,
      "step": 6025
    },
    {
      "epoch": 0.9450909942982113,
      "grad_norm": 0.8447178602218628,
      "learning_rate": 5.5147633182315265e-06,
      "loss": 1.3264,
      "step": 6050
    },
    {
      "epoch": 0.9489963289853941,
      "grad_norm": 0.9099807739257812,
      "learning_rate": 5.124199343852523e-06,
      "loss": 1.3657,
      "step": 6075
    },
    {
      "epoch": 0.9529016636725768,
      "grad_norm": 0.8223264217376709,
      "learning_rate": 4.73363536947352e-06,
      "loss": 1.4248,
      "step": 6100
    },
    {
      "epoch": 0.9568069983597595,
      "grad_norm": 0.9021925926208496,
      "learning_rate": 4.343071395094517e-06,
      "loss": 1.3272,
      "step": 6125
    },
    {
      "epoch": 0.9607123330469421,
      "grad_norm": 0.7923884987831116,
      "learning_rate": 3.952507420715513e-06,
      "loss": 1.3705,
      "step": 6150
    },
    {
      "epoch": 0.9646176677341248,
      "grad_norm": 0.645503580570221,
      "learning_rate": 3.5619434463365105e-06,
      "loss": 1.3802,
      "step": 6175
    },
    {
      "epoch": 0.9685230024213075,
      "grad_norm": 0.8544132709503174,
      "learning_rate": 3.1713794719575072e-06,
      "loss": 1.3336,
      "step": 6200
    },
    {
      "epoch": 0.9724283371084902,
      "grad_norm": 0.837233304977417,
      "learning_rate": 2.7808154975785035e-06,
      "loss": 1.4072,
      "step": 6225
    },
    {
      "epoch": 0.9763336717956729,
      "grad_norm": 0.5651229023933411,
      "learning_rate": 2.3902515231995002e-06,
      "loss": 1.3578,
      "step": 6250
    },
    {
      "epoch": 0.9802390064828556,
      "grad_norm": 0.8151102662086487,
      "learning_rate": 1.999687548820497e-06,
      "loss": 1.3222,
      "step": 6275
    },
    {
      "epoch": 0.9841443411700382,
      "grad_norm": 1.1222201585769653,
      "learning_rate": 1.6091235744414936e-06,
      "loss": 1.4296,
      "step": 6300
    },
    {
      "epoch": 0.9880496758572209,
      "grad_norm": 0.8156527280807495,
      "learning_rate": 1.2185596000624903e-06,
      "loss": 1.3859,
      "step": 6325
    },
    {
      "epoch": 0.9919550105444036,
      "grad_norm": 0.6538434028625488,
      "learning_rate": 8.279956256834869e-07,
      "loss": 1.3325,
      "step": 6350
    },
    {
      "epoch": 0.9958603452315864,
      "grad_norm": 1.018000602722168,
      "learning_rate": 4.3743165130448375e-07,
      "loss": 1.3876,
      "step": 6375
    },
    {
      "epoch": 0.9997656799187691,
      "grad_norm": 0.8237853050231934,
      "learning_rate": 4.6867676925480397e-08,
      "loss": 1.3813,
      "step": 6400
    }
  ],
  "logging_steps": 25,
  "max_steps": 6401,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.57349482689495e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
