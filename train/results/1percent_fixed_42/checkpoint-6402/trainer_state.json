{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 1000,
  "global_step": 6402,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0039050296782255547,
      "grad_norm": 0.9788556098937988,
      "learning_rate": 9.960949703217745e-05,
      "loss": 2.0441,
      "step": 25
    },
    {
      "epoch": 0.007810059356451109,
      "grad_norm": 1.4186716079711914,
      "learning_rate": 9.92189940643549e-05,
      "loss": 1.6476,
      "step": 50
    },
    {
      "epoch": 0.011715089034676664,
      "grad_norm": 1.530958652496338,
      "learning_rate": 9.882849109653233e-05,
      "loss": 1.6357,
      "step": 75
    },
    {
      "epoch": 0.015620118712902219,
      "grad_norm": 1.1300246715545654,
      "learning_rate": 9.843798812870978e-05,
      "loss": 1.5908,
      "step": 100
    },
    {
      "epoch": 0.01952514839112777,
      "grad_norm": 1.1624640226364136,
      "learning_rate": 9.804748516088723e-05,
      "loss": 1.5148,
      "step": 125
    },
    {
      "epoch": 0.023430178069353328,
      "grad_norm": 1.275742530822754,
      "learning_rate": 9.765698219306467e-05,
      "loss": 1.5328,
      "step": 150
    },
    {
      "epoch": 0.02733520774757888,
      "grad_norm": 0.8366349935531616,
      "learning_rate": 9.726647922524212e-05,
      "loss": 1.533,
      "step": 175
    },
    {
      "epoch": 0.031240237425804437,
      "grad_norm": 1.1947709321975708,
      "learning_rate": 9.687597625741956e-05,
      "loss": 1.4323,
      "step": 200
    },
    {
      "epoch": 0.035145267104029994,
      "grad_norm": 0.9227701425552368,
      "learning_rate": 9.6485473289597e-05,
      "loss": 1.4247,
      "step": 225
    },
    {
      "epoch": 0.03905029678225554,
      "grad_norm": 1.4063547849655151,
      "learning_rate": 9.609497032177445e-05,
      "loss": 1.4529,
      "step": 250
    },
    {
      "epoch": 0.0429553264604811,
      "grad_norm": 1.2065435647964478,
      "learning_rate": 9.57044673539519e-05,
      "loss": 1.441,
      "step": 275
    },
    {
      "epoch": 0.046860356138706656,
      "grad_norm": 0.971281111240387,
      "learning_rate": 9.531396438612934e-05,
      "loss": 1.4531,
      "step": 300
    },
    {
      "epoch": 0.050765385816932206,
      "grad_norm": 0.9510043859481812,
      "learning_rate": 9.492346141830677e-05,
      "loss": 1.5193,
      "step": 325
    },
    {
      "epoch": 0.05467041549515776,
      "grad_norm": 1.0490731000900269,
      "learning_rate": 9.453295845048423e-05,
      "loss": 1.4733,
      "step": 350
    },
    {
      "epoch": 0.05857544517338332,
      "grad_norm": 1.1532464027404785,
      "learning_rate": 9.414245548266167e-05,
      "loss": 1.427,
      "step": 375
    },
    {
      "epoch": 0.062480474851608875,
      "grad_norm": 0.6971469521522522,
      "learning_rate": 9.375195251483912e-05,
      "loss": 1.4548,
      "step": 400
    },
    {
      "epoch": 0.06638550452983442,
      "grad_norm": 0.9145767092704773,
      "learning_rate": 9.336144954701657e-05,
      "loss": 1.4817,
      "step": 425
    },
    {
      "epoch": 0.07029053420805999,
      "grad_norm": 0.8630960583686829,
      "learning_rate": 9.2970946579194e-05,
      "loss": 1.4269,
      "step": 450
    },
    {
      "epoch": 0.07419556388628554,
      "grad_norm": 1.035193681716919,
      "learning_rate": 9.258044361137144e-05,
      "loss": 1.4544,
      "step": 475
    },
    {
      "epoch": 0.07810059356451109,
      "grad_norm": 1.4784947633743286,
      "learning_rate": 9.21899406435489e-05,
      "loss": 1.4585,
      "step": 500
    },
    {
      "epoch": 0.08200562324273665,
      "grad_norm": 0.8094277381896973,
      "learning_rate": 9.179943767572634e-05,
      "loss": 1.446,
      "step": 525
    },
    {
      "epoch": 0.0859106529209622,
      "grad_norm": 1.0660157203674316,
      "learning_rate": 9.140893470790379e-05,
      "loss": 1.4338,
      "step": 550
    },
    {
      "epoch": 0.08981568259918775,
      "grad_norm": 1.007818341255188,
      "learning_rate": 9.101843174008123e-05,
      "loss": 1.4244,
      "step": 575
    },
    {
      "epoch": 0.09372071227741331,
      "grad_norm": 0.8388475179672241,
      "learning_rate": 9.062792877225867e-05,
      "loss": 1.4219,
      "step": 600
    },
    {
      "epoch": 0.09762574195563886,
      "grad_norm": 0.9769904017448425,
      "learning_rate": 9.023742580443611e-05,
      "loss": 1.4356,
      "step": 625
    },
    {
      "epoch": 0.10153077163386441,
      "grad_norm": 1.0306223630905151,
      "learning_rate": 8.984692283661357e-05,
      "loss": 1.4269,
      "step": 650
    },
    {
      "epoch": 0.10543580131208997,
      "grad_norm": 0.9314174652099609,
      "learning_rate": 8.945641986879101e-05,
      "loss": 1.4484,
      "step": 675
    },
    {
      "epoch": 0.10934083099031552,
      "grad_norm": 1.0374778509140015,
      "learning_rate": 8.906591690096846e-05,
      "loss": 1.4284,
      "step": 700
    },
    {
      "epoch": 0.11324586066854109,
      "grad_norm": 0.9628512263298035,
      "learning_rate": 8.86754139331459e-05,
      "loss": 1.4641,
      "step": 725
    },
    {
      "epoch": 0.11715089034676664,
      "grad_norm": 0.7893606424331665,
      "learning_rate": 8.828491096532334e-05,
      "loss": 1.4292,
      "step": 750
    },
    {
      "epoch": 0.12105592002499219,
      "grad_norm": 0.8745779395103455,
      "learning_rate": 8.789440799750078e-05,
      "loss": 1.445,
      "step": 775
    },
    {
      "epoch": 0.12496094970321775,
      "grad_norm": 0.6995758414268494,
      "learning_rate": 8.750390502967824e-05,
      "loss": 1.4392,
      "step": 800
    },
    {
      "epoch": 0.12886597938144329,
      "grad_norm": 0.9901021718978882,
      "learning_rate": 8.711340206185567e-05,
      "loss": 1.4432,
      "step": 825
    },
    {
      "epoch": 0.13277100905966885,
      "grad_norm": 0.7265489101409912,
      "learning_rate": 8.672289909403311e-05,
      "loss": 1.4313,
      "step": 850
    },
    {
      "epoch": 0.1366760387378944,
      "grad_norm": 0.737176775932312,
      "learning_rate": 8.633239612621057e-05,
      "loss": 1.4521,
      "step": 875
    },
    {
      "epoch": 0.14058106841611998,
      "grad_norm": 0.9069027900695801,
      "learning_rate": 8.594189315838801e-05,
      "loss": 1.3692,
      "step": 900
    },
    {
      "epoch": 0.1444860980943455,
      "grad_norm": 0.8256837129592896,
      "learning_rate": 8.555139019056545e-05,
      "loss": 1.3786,
      "step": 925
    },
    {
      "epoch": 0.14839112777257107,
      "grad_norm": 0.9153324365615845,
      "learning_rate": 8.51608872227429e-05,
      "loss": 1.3139,
      "step": 950
    },
    {
      "epoch": 0.15229615745079664,
      "grad_norm": 1.0537070035934448,
      "learning_rate": 8.477038425492034e-05,
      "loss": 1.4855,
      "step": 975
    },
    {
      "epoch": 0.15620118712902217,
      "grad_norm": 0.9281678795814514,
      "learning_rate": 8.437988128709778e-05,
      "loss": 1.3694,
      "step": 1000
    },
    {
      "epoch": 0.15620118712902217,
      "eval_loss": 1.4100061655044556,
      "eval_runtime": 1622.8745,
      "eval_samples_per_second": 6.312,
      "eval_steps_per_second": 6.312,
      "step": 1000
    },
    {
      "epoch": 0.16010621680724774,
      "grad_norm": 0.8348686099052429,
      "learning_rate": 8.398937831927524e-05,
      "loss": 1.4679,
      "step": 1025
    },
    {
      "epoch": 0.1640112464854733,
      "grad_norm": 0.857980489730835,
      "learning_rate": 8.359887535145268e-05,
      "loss": 1.4241,
      "step": 1050
    },
    {
      "epoch": 0.16791627616369884,
      "grad_norm": 1.0315102338790894,
      "learning_rate": 8.320837238363012e-05,
      "loss": 1.4206,
      "step": 1075
    },
    {
      "epoch": 0.1718213058419244,
      "grad_norm": 0.8269699811935425,
      "learning_rate": 8.281786941580757e-05,
      "loss": 1.4232,
      "step": 1100
    },
    {
      "epoch": 0.17572633552014996,
      "grad_norm": 0.7871904373168945,
      "learning_rate": 8.242736644798501e-05,
      "loss": 1.4577,
      "step": 1125
    },
    {
      "epoch": 0.1796313651983755,
      "grad_norm": 0.9099403619766235,
      "learning_rate": 8.203686348016245e-05,
      "loss": 1.4107,
      "step": 1150
    },
    {
      "epoch": 0.18353639487660106,
      "grad_norm": 0.9328250288963318,
      "learning_rate": 8.16463605123399e-05,
      "loss": 1.4,
      "step": 1175
    },
    {
      "epoch": 0.18744142455482662,
      "grad_norm": 0.8486063480377197,
      "learning_rate": 8.125585754451735e-05,
      "loss": 1.452,
      "step": 1200
    },
    {
      "epoch": 0.19134645423305216,
      "grad_norm": 1.0273486375808716,
      "learning_rate": 8.086535457669478e-05,
      "loss": 1.466,
      "step": 1225
    },
    {
      "epoch": 0.19525148391127772,
      "grad_norm": 0.7445910573005676,
      "learning_rate": 8.047485160887222e-05,
      "loss": 1.4502,
      "step": 1250
    },
    {
      "epoch": 0.1991565135895033,
      "grad_norm": 1.0248730182647705,
      "learning_rate": 8.008434864104968e-05,
      "loss": 1.422,
      "step": 1275
    },
    {
      "epoch": 0.20306154326772882,
      "grad_norm": 0.9922653436660767,
      "learning_rate": 7.969384567322712e-05,
      "loss": 1.3643,
      "step": 1300
    },
    {
      "epoch": 0.20696657294595439,
      "grad_norm": 0.7457150816917419,
      "learning_rate": 7.930334270540456e-05,
      "loss": 1.4058,
      "step": 1325
    },
    {
      "epoch": 0.21087160262417995,
      "grad_norm": 0.7834466099739075,
      "learning_rate": 7.891283973758201e-05,
      "loss": 1.4087,
      "step": 1350
    },
    {
      "epoch": 0.21477663230240548,
      "grad_norm": 0.7649375200271606,
      "learning_rate": 7.852233676975945e-05,
      "loss": 1.4305,
      "step": 1375
    },
    {
      "epoch": 0.21868166198063105,
      "grad_norm": 1.2048529386520386,
      "learning_rate": 7.813183380193689e-05,
      "loss": 1.3963,
      "step": 1400
    },
    {
      "epoch": 0.2225866916588566,
      "grad_norm": 0.9572616815567017,
      "learning_rate": 7.774133083411435e-05,
      "loss": 1.3733,
      "step": 1425
    },
    {
      "epoch": 0.22649172133708217,
      "grad_norm": 0.8934391736984253,
      "learning_rate": 7.735082786629179e-05,
      "loss": 1.4179,
      "step": 1450
    },
    {
      "epoch": 0.2303967510153077,
      "grad_norm": 0.9330870509147644,
      "learning_rate": 7.696032489846922e-05,
      "loss": 1.3873,
      "step": 1475
    },
    {
      "epoch": 0.23430178069353327,
      "grad_norm": 0.8023552894592285,
      "learning_rate": 7.656982193064668e-05,
      "loss": 1.382,
      "step": 1500
    },
    {
      "epoch": 0.23820681037175884,
      "grad_norm": 1.0145927667617798,
      "learning_rate": 7.617931896282412e-05,
      "loss": 1.4593,
      "step": 1525
    },
    {
      "epoch": 0.24211184004998437,
      "grad_norm": 1.0062764883041382,
      "learning_rate": 7.578881599500156e-05,
      "loss": 1.4308,
      "step": 1550
    },
    {
      "epoch": 0.24601686972820994,
      "grad_norm": 0.8741281628608704,
      "learning_rate": 7.539831302717902e-05,
      "loss": 1.4212,
      "step": 1575
    },
    {
      "epoch": 0.2499218994064355,
      "grad_norm": 0.9855102300643921,
      "learning_rate": 7.500781005935645e-05,
      "loss": 1.4128,
      "step": 1600
    },
    {
      "epoch": 0.25382692908466103,
      "grad_norm": 0.8172687292098999,
      "learning_rate": 7.461730709153389e-05,
      "loss": 1.4174,
      "step": 1625
    },
    {
      "epoch": 0.25773195876288657,
      "grad_norm": 1.1485220193862915,
      "learning_rate": 7.422680412371135e-05,
      "loss": 1.4511,
      "step": 1650
    },
    {
      "epoch": 0.26163698844111216,
      "grad_norm": 1.2781294584274292,
      "learning_rate": 7.383630115588879e-05,
      "loss": 1.4094,
      "step": 1675
    },
    {
      "epoch": 0.2655420181193377,
      "grad_norm": 0.8155423998832703,
      "learning_rate": 7.344579818806623e-05,
      "loss": 1.3896,
      "step": 1700
    },
    {
      "epoch": 0.2694470477975633,
      "grad_norm": 1.19487464427948,
      "learning_rate": 7.305529522024368e-05,
      "loss": 1.3922,
      "step": 1725
    },
    {
      "epoch": 0.2733520774757888,
      "grad_norm": 0.8717193007469177,
      "learning_rate": 7.266479225242112e-05,
      "loss": 1.3826,
      "step": 1750
    },
    {
      "epoch": 0.27725710715401436,
      "grad_norm": 0.815072238445282,
      "learning_rate": 7.227428928459856e-05,
      "loss": 1.3427,
      "step": 1775
    },
    {
      "epoch": 0.28116213683223995,
      "grad_norm": 0.7282699346542358,
      "learning_rate": 7.188378631677602e-05,
      "loss": 1.4233,
      "step": 1800
    },
    {
      "epoch": 0.2850671665104655,
      "grad_norm": 0.8836639523506165,
      "learning_rate": 7.149328334895346e-05,
      "loss": 1.4416,
      "step": 1825
    },
    {
      "epoch": 0.288972196188691,
      "grad_norm": 1.1085466146469116,
      "learning_rate": 7.110278038113089e-05,
      "loss": 1.297,
      "step": 1850
    },
    {
      "epoch": 0.2928772258669166,
      "grad_norm": 0.8943423628807068,
      "learning_rate": 7.071227741330835e-05,
      "loss": 1.3439,
      "step": 1875
    },
    {
      "epoch": 0.29678225554514215,
      "grad_norm": 0.7290465831756592,
      "learning_rate": 7.032177444548579e-05,
      "loss": 1.3455,
      "step": 1900
    },
    {
      "epoch": 0.3006872852233677,
      "grad_norm": 1.0493628978729248,
      "learning_rate": 6.993127147766323e-05,
      "loss": 1.3515,
      "step": 1925
    },
    {
      "epoch": 0.3045923149015933,
      "grad_norm": 0.9758964776992798,
      "learning_rate": 6.954076850984069e-05,
      "loss": 1.3877,
      "step": 1950
    },
    {
      "epoch": 0.3084973445798188,
      "grad_norm": 0.8183075189590454,
      "learning_rate": 6.915026554201812e-05,
      "loss": 1.4081,
      "step": 1975
    },
    {
      "epoch": 0.31240237425804435,
      "grad_norm": 1.2012001276016235,
      "learning_rate": 6.875976257419556e-05,
      "loss": 1.3826,
      "step": 2000
    },
    {
      "epoch": 0.31240237425804435,
      "eval_loss": 1.3891282081604004,
      "eval_runtime": 1622.8317,
      "eval_samples_per_second": 6.312,
      "eval_steps_per_second": 6.312,
      "step": 2000
    },
    {
      "epoch": 0.31630740393626994,
      "grad_norm": 0.778975248336792,
      "learning_rate": 6.836925960637302e-05,
      "loss": 1.3761,
      "step": 2025
    },
    {
      "epoch": 0.3202124336144955,
      "grad_norm": 0.747718095779419,
      "learning_rate": 6.797875663855046e-05,
      "loss": 1.4318,
      "step": 2050
    },
    {
      "epoch": 0.324117463292721,
      "grad_norm": 0.9056251049041748,
      "learning_rate": 6.75882536707279e-05,
      "loss": 1.3882,
      "step": 2075
    },
    {
      "epoch": 0.3280224929709466,
      "grad_norm": 0.9129356741905212,
      "learning_rate": 6.719775070290534e-05,
      "loss": 1.4031,
      "step": 2100
    },
    {
      "epoch": 0.33192752264917214,
      "grad_norm": 0.667236328125,
      "learning_rate": 6.680724773508279e-05,
      "loss": 1.3969,
      "step": 2125
    },
    {
      "epoch": 0.33583255232739767,
      "grad_norm": 0.9704068303108215,
      "learning_rate": 6.641674476726023e-05,
      "loss": 1.3397,
      "step": 2150
    },
    {
      "epoch": 0.33973758200562326,
      "grad_norm": 1.06690514087677,
      "learning_rate": 6.602624179943769e-05,
      "loss": 1.4212,
      "step": 2175
    },
    {
      "epoch": 0.3436426116838488,
      "grad_norm": 0.8432579040527344,
      "learning_rate": 6.563573883161513e-05,
      "loss": 1.4374,
      "step": 2200
    },
    {
      "epoch": 0.34754764136207433,
      "grad_norm": 1.0442194938659668,
      "learning_rate": 6.524523586379257e-05,
      "loss": 1.373,
      "step": 2225
    },
    {
      "epoch": 0.3514526710402999,
      "grad_norm": 0.9351023435592651,
      "learning_rate": 6.487035301468292e-05,
      "loss": 1.4182,
      "step": 2250
    },
    {
      "epoch": 0.35535770071852546,
      "grad_norm": 0.9344373941421509,
      "learning_rate": 6.447985004686035e-05,
      "loss": 1.3841,
      "step": 2275
    },
    {
      "epoch": 0.359262730396751,
      "grad_norm": 0.9935104846954346,
      "learning_rate": 6.408934707903781e-05,
      "loss": 1.4326,
      "step": 2300
    },
    {
      "epoch": 0.3631677600749766,
      "grad_norm": 0.7968645095825195,
      "learning_rate": 6.369884411121525e-05,
      "loss": 1.3949,
      "step": 2325
    },
    {
      "epoch": 0.3670727897532021,
      "grad_norm": 0.7839841842651367,
      "learning_rate": 6.33083411433927e-05,
      "loss": 1.3706,
      "step": 2350
    },
    {
      "epoch": 0.37097781943142766,
      "grad_norm": 0.8733723759651184,
      "learning_rate": 6.291783817557014e-05,
      "loss": 1.4319,
      "step": 2375
    },
    {
      "epoch": 0.37488284910965325,
      "grad_norm": 1.784317970275879,
      "learning_rate": 6.252733520774758e-05,
      "loss": 1.3913,
      "step": 2400
    },
    {
      "epoch": 0.3787878787878788,
      "grad_norm": 1.04975163936615,
      "learning_rate": 6.213683223992502e-05,
      "loss": 1.4579,
      "step": 2425
    },
    {
      "epoch": 0.3826929084661043,
      "grad_norm": 1.2106798887252808,
      "learning_rate": 6.174632927210246e-05,
      "loss": 1.4207,
      "step": 2450
    },
    {
      "epoch": 0.3865979381443299,
      "grad_norm": 0.9787081480026245,
      "learning_rate": 6.135582630427992e-05,
      "loss": 1.3287,
      "step": 2475
    },
    {
      "epoch": 0.39050296782255545,
      "grad_norm": 0.755710244178772,
      "learning_rate": 6.096532333645736e-05,
      "loss": 1.4122,
      "step": 2500
    },
    {
      "epoch": 0.394407997500781,
      "grad_norm": 0.8430375456809998,
      "learning_rate": 6.05748203686348e-05,
      "loss": 1.4425,
      "step": 2525
    },
    {
      "epoch": 0.3983130271790066,
      "grad_norm": 0.8444249033927917,
      "learning_rate": 6.018431740081225e-05,
      "loss": 1.3714,
      "step": 2550
    },
    {
      "epoch": 0.4022180568572321,
      "grad_norm": 0.9024614095687866,
      "learning_rate": 5.979381443298969e-05,
      "loss": 1.3792,
      "step": 2575
    },
    {
      "epoch": 0.40612308653545764,
      "grad_norm": 0.9260613322257996,
      "learning_rate": 5.9403311465167135e-05,
      "loss": 1.3415,
      "step": 2600
    },
    {
      "epoch": 0.41002811621368324,
      "grad_norm": 0.7240073084831238,
      "learning_rate": 5.9012808497344584e-05,
      "loss": 1.3284,
      "step": 2625
    },
    {
      "epoch": 0.41393314589190877,
      "grad_norm": 0.7593271732330322,
      "learning_rate": 5.862230552952203e-05,
      "loss": 1.42,
      "step": 2650
    },
    {
      "epoch": 0.4178381755701343,
      "grad_norm": 0.9628000855445862,
      "learning_rate": 5.823180256169947e-05,
      "loss": 1.3598,
      "step": 2675
    },
    {
      "epoch": 0.4217432052483599,
      "grad_norm": 0.6669929623603821,
      "learning_rate": 5.784129959387692e-05,
      "loss": 1.3691,
      "step": 2700
    },
    {
      "epoch": 0.42564823492658543,
      "grad_norm": 0.8762942552566528,
      "learning_rate": 5.745079662605436e-05,
      "loss": 1.4063,
      "step": 2725
    },
    {
      "epoch": 0.42955326460481097,
      "grad_norm": 0.772219717502594,
      "learning_rate": 5.70602936582318e-05,
      "loss": 1.4078,
      "step": 2750
    },
    {
      "epoch": 0.43345829428303656,
      "grad_norm": 1.0171741247177124,
      "learning_rate": 5.6669790690409254e-05,
      "loss": 1.38,
      "step": 2775
    },
    {
      "epoch": 0.4373633239612621,
      "grad_norm": 0.765740156173706,
      "learning_rate": 5.627928772258669e-05,
      "loss": 1.4231,
      "step": 2800
    },
    {
      "epoch": 0.4412683536394877,
      "grad_norm": 0.8746947050094604,
      "learning_rate": 5.588878475476413e-05,
      "loss": 1.371,
      "step": 2825
    },
    {
      "epoch": 0.4451733833177132,
      "grad_norm": 0.7496356964111328,
      "learning_rate": 5.549828178694159e-05,
      "loss": 1.3442,
      "step": 2850
    },
    {
      "epoch": 0.44907841299593876,
      "grad_norm": 0.7783387899398804,
      "learning_rate": 5.5107778819119025e-05,
      "loss": 1.4312,
      "step": 2875
    },
    {
      "epoch": 0.45298344267416435,
      "grad_norm": 0.889725387096405,
      "learning_rate": 5.471727585129647e-05,
      "loss": 1.399,
      "step": 2900
    },
    {
      "epoch": 0.4568884723523899,
      "grad_norm": 1.023020625114441,
      "learning_rate": 5.432677288347392e-05,
      "loss": 1.3657,
      "step": 2925
    },
    {
      "epoch": 0.4607935020306154,
      "grad_norm": 0.9599210023880005,
      "learning_rate": 5.393626991565136e-05,
      "loss": 1.4014,
      "step": 2950
    },
    {
      "epoch": 0.464698531708841,
      "grad_norm": 1.1952301263809204,
      "learning_rate": 5.35457669478288e-05,
      "loss": 1.3319,
      "step": 2975
    },
    {
      "epoch": 0.46860356138706655,
      "grad_norm": 0.8350117802619934,
      "learning_rate": 5.315526398000625e-05,
      "loss": 1.3746,
      "step": 3000
    },
    {
      "epoch": 0.46860356138706655,
      "eval_loss": 1.379629135131836,
      "eval_runtime": 1622.5807,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 3000
    },
    {
      "epoch": 0.4725085910652921,
      "grad_norm": 0.7739664316177368,
      "learning_rate": 5.2764761012183695e-05,
      "loss": 1.4085,
      "step": 3025
    },
    {
      "epoch": 0.4764136207435177,
      "grad_norm": 0.781043529510498,
      "learning_rate": 5.237425804436114e-05,
      "loss": 1.3533,
      "step": 3050
    },
    {
      "epoch": 0.4803186504217432,
      "grad_norm": 0.6492843627929688,
      "learning_rate": 5.198375507653859e-05,
      "loss": 1.4445,
      "step": 3075
    },
    {
      "epoch": 0.48422368009996875,
      "grad_norm": 0.7984755635261536,
      "learning_rate": 5.159325210871603e-05,
      "loss": 1.3689,
      "step": 3100
    },
    {
      "epoch": 0.48812870977819434,
      "grad_norm": 0.7521188855171204,
      "learning_rate": 5.1202749140893466e-05,
      "loss": 1.4317,
      "step": 3125
    },
    {
      "epoch": 0.49203373945641987,
      "grad_norm": 0.7364665865898132,
      "learning_rate": 5.081224617307092e-05,
      "loss": 1.3606,
      "step": 3150
    },
    {
      "epoch": 0.4959387691346454,
      "grad_norm": 0.987529993057251,
      "learning_rate": 5.0421743205248365e-05,
      "loss": 1.3917,
      "step": 3175
    },
    {
      "epoch": 0.499843798812871,
      "grad_norm": 0.8404374718666077,
      "learning_rate": 5.00312402374258e-05,
      "loss": 1.3419,
      "step": 3200
    },
    {
      "epoch": 0.5037488284910965,
      "grad_norm": 1.2168902158737183,
      "learning_rate": 4.964073726960325e-05,
      "loss": 1.4761,
      "step": 3225
    },
    {
      "epoch": 0.5076538581693221,
      "grad_norm": 1.087868332862854,
      "learning_rate": 4.925023430178069e-05,
      "loss": 1.348,
      "step": 3250
    },
    {
      "epoch": 0.5115588878475477,
      "grad_norm": 1.0057283639907837,
      "learning_rate": 4.885973133395814e-05,
      "loss": 1.389,
      "step": 3275
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 0.9449900388717651,
      "learning_rate": 4.8469228366135585e-05,
      "loss": 1.3524,
      "step": 3300
    },
    {
      "epoch": 0.5193689472039987,
      "grad_norm": 0.8599697351455688,
      "learning_rate": 4.807872539831303e-05,
      "loss": 1.4186,
      "step": 3325
    },
    {
      "epoch": 0.5232739768822243,
      "grad_norm": 0.9135838150978088,
      "learning_rate": 4.768822243049048e-05,
      "loss": 1.3734,
      "step": 3350
    },
    {
      "epoch": 0.5271790065604499,
      "grad_norm": 0.7260757088661194,
      "learning_rate": 4.7297719462667913e-05,
      "loss": 1.37,
      "step": 3375
    },
    {
      "epoch": 0.5310840362386754,
      "grad_norm": 0.8324730396270752,
      "learning_rate": 4.690721649484536e-05,
      "loss": 1.3938,
      "step": 3400
    },
    {
      "epoch": 0.534989065916901,
      "grad_norm": 1.1432992219924927,
      "learning_rate": 4.651671352702281e-05,
      "loss": 1.3877,
      "step": 3425
    },
    {
      "epoch": 0.5388940955951266,
      "grad_norm": 0.7782467603683472,
      "learning_rate": 4.612621055920025e-05,
      "loss": 1.3456,
      "step": 3450
    },
    {
      "epoch": 0.5427991252733521,
      "grad_norm": 0.727100670337677,
      "learning_rate": 4.57357075913777e-05,
      "loss": 1.4395,
      "step": 3475
    },
    {
      "epoch": 0.5467041549515776,
      "grad_norm": 0.8211419582366943,
      "learning_rate": 4.534520462355514e-05,
      "loss": 1.412,
      "step": 3500
    },
    {
      "epoch": 0.5506091846298032,
      "grad_norm": 0.6755484342575073,
      "learning_rate": 4.495470165573258e-05,
      "loss": 1.4133,
      "step": 3525
    },
    {
      "epoch": 0.5545142143080287,
      "grad_norm": 0.8624936938285828,
      "learning_rate": 4.456419868791003e-05,
      "loss": 1.4284,
      "step": 3550
    },
    {
      "epoch": 0.5584192439862543,
      "grad_norm": 0.9535272121429443,
      "learning_rate": 4.4173695720087476e-05,
      "loss": 1.4182,
      "step": 3575
    },
    {
      "epoch": 0.5623242736644799,
      "grad_norm": 0.8995130062103271,
      "learning_rate": 4.378319275226492e-05,
      "loss": 1.3576,
      "step": 3600
    },
    {
      "epoch": 0.5662293033427054,
      "grad_norm": 0.8603726029396057,
      "learning_rate": 4.339268978444236e-05,
      "loss": 1.3846,
      "step": 3625
    },
    {
      "epoch": 0.570134333020931,
      "grad_norm": 0.7719624042510986,
      "learning_rate": 4.300218681661981e-05,
      "loss": 1.4535,
      "step": 3650
    },
    {
      "epoch": 0.5740393626991566,
      "grad_norm": 0.9310029745101929,
      "learning_rate": 4.261168384879725e-05,
      "loss": 1.3824,
      "step": 3675
    },
    {
      "epoch": 0.577944392377382,
      "grad_norm": 1.049993634223938,
      "learning_rate": 4.2221180880974696e-05,
      "loss": 1.3819,
      "step": 3700
    },
    {
      "epoch": 0.5818494220556076,
      "grad_norm": 0.80288165807724,
      "learning_rate": 4.1830677913152146e-05,
      "loss": 1.3687,
      "step": 3725
    },
    {
      "epoch": 0.5857544517338332,
      "grad_norm": 0.8904058933258057,
      "learning_rate": 4.144017494532959e-05,
      "loss": 1.3472,
      "step": 3750
    },
    {
      "epoch": 0.5896594814120587,
      "grad_norm": 0.9186760783195496,
      "learning_rate": 4.104967197750703e-05,
      "loss": 1.3894,
      "step": 3775
    },
    {
      "epoch": 0.5935645110902843,
      "grad_norm": 0.8003730177879333,
      "learning_rate": 4.065916900968448e-05,
      "loss": 1.3594,
      "step": 3800
    },
    {
      "epoch": 0.5974695407685099,
      "grad_norm": 0.7443795204162598,
      "learning_rate": 4.0268666041861916e-05,
      "loss": 1.4191,
      "step": 3825
    },
    {
      "epoch": 0.6013745704467354,
      "grad_norm": 0.8892534375190735,
      "learning_rate": 3.9878163074039366e-05,
      "loss": 1.3938,
      "step": 3850
    },
    {
      "epoch": 0.605279600124961,
      "grad_norm": 0.7992183566093445,
      "learning_rate": 3.948766010621681e-05,
      "loss": 1.3595,
      "step": 3875
    },
    {
      "epoch": 0.6091846298031866,
      "grad_norm": 0.8434757590293884,
      "learning_rate": 3.909715713839425e-05,
      "loss": 1.4179,
      "step": 3900
    },
    {
      "epoch": 0.613089659481412,
      "grad_norm": 0.8580999374389648,
      "learning_rate": 3.87066541705717e-05,
      "loss": 1.3749,
      "step": 3925
    },
    {
      "epoch": 0.6169946891596376,
      "grad_norm": 0.8498902320861816,
      "learning_rate": 3.8316151202749144e-05,
      "loss": 1.358,
      "step": 3950
    },
    {
      "epoch": 0.6208997188378632,
      "grad_norm": 0.713224470615387,
      "learning_rate": 3.7925648234926586e-05,
      "loss": 1.3435,
      "step": 3975
    },
    {
      "epoch": 0.6248047485160887,
      "grad_norm": 1.0151127576828003,
      "learning_rate": 3.7535145267104036e-05,
      "loss": 1.4189,
      "step": 4000
    },
    {
      "epoch": 0.6248047485160887,
      "eval_loss": 1.3731718063354492,
      "eval_runtime": 1622.5739,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 4000
    },
    {
      "epoch": 0.6287097781943143,
      "grad_norm": 0.7106295824050903,
      "learning_rate": 3.714464229928147e-05,
      "loss": 1.3811,
      "step": 4025
    },
    {
      "epoch": 0.6326148078725399,
      "grad_norm": 0.892025351524353,
      "learning_rate": 3.675413933145892e-05,
      "loss": 1.3305,
      "step": 4050
    },
    {
      "epoch": 0.6365198375507654,
      "grad_norm": 0.7329587340354919,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.354,
      "step": 4075
    },
    {
      "epoch": 0.640424867228991,
      "grad_norm": 0.6800800561904907,
      "learning_rate": 3.597313339581381e-05,
      "loss": 1.3906,
      "step": 4100
    },
    {
      "epoch": 0.6443298969072165,
      "grad_norm": 1.3265095949172974,
      "learning_rate": 3.5582630427991256e-05,
      "loss": 1.4372,
      "step": 4125
    },
    {
      "epoch": 0.648234926585442,
      "grad_norm": 0.9539549946784973,
      "learning_rate": 3.51921274601687e-05,
      "loss": 1.3551,
      "step": 4150
    },
    {
      "epoch": 0.6521399562636676,
      "grad_norm": 0.9606791138648987,
      "learning_rate": 3.480162449234614e-05,
      "loss": 1.3093,
      "step": 4175
    },
    {
      "epoch": 0.6560449859418932,
      "grad_norm": 0.808586597442627,
      "learning_rate": 3.4411121524523585e-05,
      "loss": 1.3872,
      "step": 4200
    },
    {
      "epoch": 0.6599500156201187,
      "grad_norm": 0.9459164142608643,
      "learning_rate": 3.4020618556701034e-05,
      "loss": 1.4493,
      "step": 4225
    },
    {
      "epoch": 0.6638550452983443,
      "grad_norm": 0.7696070075035095,
      "learning_rate": 3.363011558887848e-05,
      "loss": 1.3404,
      "step": 4250
    },
    {
      "epoch": 0.6677600749765699,
      "grad_norm": 0.666983425617218,
      "learning_rate": 3.323961262105592e-05,
      "loss": 1.3437,
      "step": 4275
    },
    {
      "epoch": 0.6716651046547953,
      "grad_norm": 0.7108051776885986,
      "learning_rate": 3.284910965323337e-05,
      "loss": 1.3774,
      "step": 4300
    },
    {
      "epoch": 0.6755701343330209,
      "grad_norm": 0.9975783228874207,
      "learning_rate": 3.2474226804123714e-05,
      "loss": 1.382,
      "step": 4325
    },
    {
      "epoch": 0.6794751640112465,
      "grad_norm": 0.7070274949073792,
      "learning_rate": 3.208372383630116e-05,
      "loss": 1.4062,
      "step": 4350
    },
    {
      "epoch": 0.683380193689472,
      "grad_norm": 1.1871284246444702,
      "learning_rate": 3.16932208684786e-05,
      "loss": 1.3499,
      "step": 4375
    },
    {
      "epoch": 0.6872852233676976,
      "grad_norm": 0.8049858212471008,
      "learning_rate": 3.130271790065605e-05,
      "loss": 1.3882,
      "step": 4400
    },
    {
      "epoch": 0.6911902530459232,
      "grad_norm": 0.7419130206108093,
      "learning_rate": 3.091221493283349e-05,
      "loss": 1.3806,
      "step": 4425
    },
    {
      "epoch": 0.6950952827241487,
      "grad_norm": 0.7134928703308105,
      "learning_rate": 3.0521711965010935e-05,
      "loss": 1.389,
      "step": 4450
    },
    {
      "epoch": 0.6990003124023743,
      "grad_norm": 0.850683867931366,
      "learning_rate": 3.013120899718838e-05,
      "loss": 1.3574,
      "step": 4475
    },
    {
      "epoch": 0.7029053420805998,
      "grad_norm": 0.7843195796012878,
      "learning_rate": 2.9740706029365824e-05,
      "loss": 1.3615,
      "step": 4500
    },
    {
      "epoch": 0.7068103717588253,
      "grad_norm": 0.7871493101119995,
      "learning_rate": 2.935020306154327e-05,
      "loss": 1.2936,
      "step": 4525
    },
    {
      "epoch": 0.7107154014370509,
      "grad_norm": 1.0230937004089355,
      "learning_rate": 2.8959700093720716e-05,
      "loss": 1.3672,
      "step": 4550
    },
    {
      "epoch": 0.7146204311152765,
      "grad_norm": 0.901289165019989,
      "learning_rate": 2.8569197125898155e-05,
      "loss": 1.3627,
      "step": 4575
    },
    {
      "epoch": 0.718525460793502,
      "grad_norm": 0.9140220880508423,
      "learning_rate": 2.81786941580756e-05,
      "loss": 1.4286,
      "step": 4600
    },
    {
      "epoch": 0.7224304904717276,
      "grad_norm": 0.5817325711250305,
      "learning_rate": 2.7788191190253047e-05,
      "loss": 1.379,
      "step": 4625
    },
    {
      "epoch": 0.7263355201499532,
      "grad_norm": 0.7954283356666565,
      "learning_rate": 2.739768822243049e-05,
      "loss": 1.3527,
      "step": 4650
    },
    {
      "epoch": 0.7302405498281787,
      "grad_norm": 0.6346081495285034,
      "learning_rate": 2.7007185254607936e-05,
      "loss": 1.4137,
      "step": 4675
    },
    {
      "epoch": 0.7341455795064042,
      "grad_norm": 0.8675228357315063,
      "learning_rate": 2.6616682286785382e-05,
      "loss": 1.3248,
      "step": 4700
    },
    {
      "epoch": 0.7380506091846298,
      "grad_norm": 0.6280678510665894,
      "learning_rate": 2.6226179318962825e-05,
      "loss": 1.3556,
      "step": 4725
    },
    {
      "epoch": 0.7419556388628553,
      "grad_norm": 1.135744333267212,
      "learning_rate": 2.583567635114027e-05,
      "loss": 1.3373,
      "step": 4750
    },
    {
      "epoch": 0.7458606685410809,
      "grad_norm": 0.7343663573265076,
      "learning_rate": 2.5445173383317717e-05,
      "loss": 1.3954,
      "step": 4775
    },
    {
      "epoch": 0.7497656982193065,
      "grad_norm": 0.9837157130241394,
      "learning_rate": 2.5054670415495157e-05,
      "loss": 1.4088,
      "step": 4800
    },
    {
      "epoch": 0.753670727897532,
      "grad_norm": 0.9069740176200867,
      "learning_rate": 2.4664167447672603e-05,
      "loss": 1.3668,
      "step": 4825
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 0.9589853882789612,
      "learning_rate": 2.427366447985005e-05,
      "loss": 1.358,
      "step": 4850
    },
    {
      "epoch": 0.7614807872539832,
      "grad_norm": 0.803594708442688,
      "learning_rate": 2.3883161512027495e-05,
      "loss": 1.3844,
      "step": 4875
    },
    {
      "epoch": 0.7653858169322086,
      "grad_norm": 0.9047093987464905,
      "learning_rate": 2.3492658544204938e-05,
      "loss": 1.3675,
      "step": 4900
    },
    {
      "epoch": 0.7692908466104342,
      "grad_norm": 0.7741007208824158,
      "learning_rate": 2.310215557638238e-05,
      "loss": 1.363,
      "step": 4925
    },
    {
      "epoch": 0.7731958762886598,
      "grad_norm": 0.8362913131713867,
      "learning_rate": 2.2711652608559827e-05,
      "loss": 1.4205,
      "step": 4950
    },
    {
      "epoch": 0.7771009059668853,
      "grad_norm": 0.8468454480171204,
      "learning_rate": 2.232114964073727e-05,
      "loss": 1.3658,
      "step": 4975
    },
    {
      "epoch": 0.7810059356451109,
      "grad_norm": 0.735235333442688,
      "learning_rate": 2.1930646672914716e-05,
      "loss": 1.3646,
      "step": 5000
    },
    {
      "epoch": 0.7810059356451109,
      "eval_loss": 1.3693565130233765,
      "eval_runtime": 1622.4467,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 5000
    },
    {
      "epoch": 0.7849109653233365,
      "grad_norm": 0.9364868998527527,
      "learning_rate": 2.154014370509216e-05,
      "loss": 1.3967,
      "step": 5025
    },
    {
      "epoch": 0.788815995001562,
      "grad_norm": 0.6212465763092041,
      "learning_rate": 2.1149640737269604e-05,
      "loss": 1.3571,
      "step": 5050
    },
    {
      "epoch": 0.7927210246797876,
      "grad_norm": 0.7348495125770569,
      "learning_rate": 2.0759137769447047e-05,
      "loss": 1.3592,
      "step": 5075
    },
    {
      "epoch": 0.7966260543580131,
      "grad_norm": 0.9597716927528381,
      "learning_rate": 2.0368634801624493e-05,
      "loss": 1.4069,
      "step": 5100
    },
    {
      "epoch": 0.8005310840362386,
      "grad_norm": 0.6791498064994812,
      "learning_rate": 1.997813183380194e-05,
      "loss": 1.3155,
      "step": 5125
    },
    {
      "epoch": 0.8044361137144642,
      "grad_norm": 0.9482506513595581,
      "learning_rate": 1.9587628865979382e-05,
      "loss": 1.4001,
      "step": 5150
    },
    {
      "epoch": 0.8083411433926898,
      "grad_norm": 0.964714527130127,
      "learning_rate": 1.9197125898156825e-05,
      "loss": 1.4144,
      "step": 5175
    },
    {
      "epoch": 0.8122461730709153,
      "grad_norm": 0.8422079682350159,
      "learning_rate": 1.880662293033427e-05,
      "loss": 1.3789,
      "step": 5200
    },
    {
      "epoch": 0.8161512027491409,
      "grad_norm": 0.7407439947128296,
      "learning_rate": 1.8416119962511717e-05,
      "loss": 1.3958,
      "step": 5225
    },
    {
      "epoch": 0.8200562324273665,
      "grad_norm": 1.1520321369171143,
      "learning_rate": 1.802561699468916e-05,
      "loss": 1.4314,
      "step": 5250
    },
    {
      "epoch": 0.823961262105592,
      "grad_norm": 0.9952729344367981,
      "learning_rate": 1.7635114026866606e-05,
      "loss": 1.3489,
      "step": 5275
    },
    {
      "epoch": 0.8278662917838175,
      "grad_norm": 0.6066399812698364,
      "learning_rate": 1.724461105904405e-05,
      "loss": 1.3435,
      "step": 5300
    },
    {
      "epoch": 0.8317713214620431,
      "grad_norm": 0.7108361721038818,
      "learning_rate": 1.6854108091221495e-05,
      "loss": 1.3662,
      "step": 5325
    },
    {
      "epoch": 0.8356763511402686,
      "grad_norm": 0.8006077408790588,
      "learning_rate": 1.646360512339894e-05,
      "loss": 1.343,
      "step": 5350
    },
    {
      "epoch": 0.8395813808184942,
      "grad_norm": 0.9728885889053345,
      "learning_rate": 1.6073102155576384e-05,
      "loss": 1.3752,
      "step": 5375
    },
    {
      "epoch": 0.8434864104967198,
      "grad_norm": 0.7574647068977356,
      "learning_rate": 1.5682599187753826e-05,
      "loss": 1.3411,
      "step": 5400
    },
    {
      "epoch": 0.8473914401749453,
      "grad_norm": 0.8523254990577698,
      "learning_rate": 1.5292096219931273e-05,
      "loss": 1.3692,
      "step": 5425
    },
    {
      "epoch": 0.8512964698531709,
      "grad_norm": 0.8416500687599182,
      "learning_rate": 1.4901593252108717e-05,
      "loss": 1.3491,
      "step": 5450
    },
    {
      "epoch": 0.8552014995313965,
      "grad_norm": 0.823092520236969,
      "learning_rate": 1.4511090284286161e-05,
      "loss": 1.325,
      "step": 5475
    },
    {
      "epoch": 0.8591065292096219,
      "grad_norm": 0.9886195063591003,
      "learning_rate": 1.4120587316463607e-05,
      "loss": 1.4424,
      "step": 5500
    },
    {
      "epoch": 0.8630115588878475,
      "grad_norm": 0.8512805700302124,
      "learning_rate": 1.373008434864105e-05,
      "loss": 1.3217,
      "step": 5525
    },
    {
      "epoch": 0.8669165885660731,
      "grad_norm": 0.8333420157432556,
      "learning_rate": 1.3339581380818495e-05,
      "loss": 1.3563,
      "step": 5550
    },
    {
      "epoch": 0.8708216182442987,
      "grad_norm": 0.6682999134063721,
      "learning_rate": 1.2949078412995937e-05,
      "loss": 1.3076,
      "step": 5575
    },
    {
      "epoch": 0.8747266479225242,
      "grad_norm": 0.7954887747764587,
      "learning_rate": 1.2558575445173385e-05,
      "loss": 1.3856,
      "step": 5600
    },
    {
      "epoch": 0.8786316776007498,
      "grad_norm": 0.6596947312355042,
      "learning_rate": 1.218369259606373e-05,
      "loss": 1.3645,
      "step": 5625
    },
    {
      "epoch": 0.8825367072789754,
      "grad_norm": 0.9747390151023865,
      "learning_rate": 1.1793189628241175e-05,
      "loss": 1.329,
      "step": 5650
    },
    {
      "epoch": 0.8864417369572009,
      "grad_norm": 0.6473241448402405,
      "learning_rate": 1.140268666041862e-05,
      "loss": 1.3591,
      "step": 5675
    },
    {
      "epoch": 0.8903467666354264,
      "grad_norm": 0.6734678745269775,
      "learning_rate": 1.1012183692596065e-05,
      "loss": 1.323,
      "step": 5700
    },
    {
      "epoch": 0.894251796313652,
      "grad_norm": 0.7252177000045776,
      "learning_rate": 1.0621680724773508e-05,
      "loss": 1.4112,
      "step": 5725
    },
    {
      "epoch": 0.8981568259918775,
      "grad_norm": 0.8954679369926453,
      "learning_rate": 1.0231177756950953e-05,
      "loss": 1.3399,
      "step": 5750
    },
    {
      "epoch": 0.9020618556701031,
      "grad_norm": 1.1000677347183228,
      "learning_rate": 9.840674789128399e-06,
      "loss": 1.4044,
      "step": 5775
    },
    {
      "epoch": 0.9059668853483287,
      "grad_norm": 0.8410158157348633,
      "learning_rate": 9.450171821305841e-06,
      "loss": 1.397,
      "step": 5800
    },
    {
      "epoch": 0.9098719150265542,
      "grad_norm": 0.6987333297729492,
      "learning_rate": 9.059668853483288e-06,
      "loss": 1.3918,
      "step": 5825
    },
    {
      "epoch": 0.9137769447047798,
      "grad_norm": 0.8470657467842102,
      "learning_rate": 8.66916588566073e-06,
      "loss": 1.3682,
      "step": 5850
    },
    {
      "epoch": 0.9176819743830054,
      "grad_norm": 0.7091872692108154,
      "learning_rate": 8.278662917838176e-06,
      "loss": 1.3853,
      "step": 5875
    },
    {
      "epoch": 0.9215870040612308,
      "grad_norm": 0.7373557090759277,
      "learning_rate": 7.888159950015621e-06,
      "loss": 1.3458,
      "step": 5900
    },
    {
      "epoch": 0.9254920337394564,
      "grad_norm": 0.7899233102798462,
      "learning_rate": 7.4976569821930645e-06,
      "loss": 1.4056,
      "step": 5925
    },
    {
      "epoch": 0.929397063417682,
      "grad_norm": 1.1872673034667969,
      "learning_rate": 7.10715401437051e-06,
      "loss": 1.4163,
      "step": 5950
    },
    {
      "epoch": 0.9333020930959075,
      "grad_norm": 0.8266786932945251,
      "learning_rate": 6.716651046547954e-06,
      "loss": 1.402,
      "step": 5975
    },
    {
      "epoch": 0.9372071227741331,
      "grad_norm": 1.0458475351333618,
      "learning_rate": 6.326148078725399e-06,
      "loss": 1.3321,
      "step": 6000
    },
    {
      "epoch": 0.9372071227741331,
      "eval_loss": 1.3669209480285645,
      "eval_runtime": 1622.6337,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 6000
    },
    {
      "epoch": 0.9411121524523587,
      "grad_norm": 1.1221897602081299,
      "learning_rate": 5.935645110902843e-06,
      "loss": 1.3533,
      "step": 6025
    },
    {
      "epoch": 0.9450171821305842,
      "grad_norm": 1.0125004053115845,
      "learning_rate": 5.5451421430802874e-06,
      "loss": 1.3807,
      "step": 6050
    },
    {
      "epoch": 0.9489222118088098,
      "grad_norm": 0.9615964293479919,
      "learning_rate": 5.154639175257732e-06,
      "loss": 1.4028,
      "step": 6075
    },
    {
      "epoch": 0.9528272414870353,
      "grad_norm": 0.7577344179153442,
      "learning_rate": 4.764136207435177e-06,
      "loss": 1.38,
      "step": 6100
    },
    {
      "epoch": 0.9567322711652608,
      "grad_norm": 0.9583836793899536,
      "learning_rate": 4.3736332396126216e-06,
      "loss": 1.2673,
      "step": 6125
    },
    {
      "epoch": 0.9606373008434864,
      "grad_norm": 0.6736977100372314,
      "learning_rate": 3.983130271790066e-06,
      "loss": 1.4396,
      "step": 6150
    },
    {
      "epoch": 0.964542330521712,
      "grad_norm": 0.7640969753265381,
      "learning_rate": 3.59262730396751e-06,
      "loss": 1.3824,
      "step": 6175
    },
    {
      "epoch": 0.9684473601999375,
      "grad_norm": 0.909238338470459,
      "learning_rate": 3.202124336144955e-06,
      "loss": 1.3716,
      "step": 6200
    },
    {
      "epoch": 0.9723523898781631,
      "grad_norm": 0.923399806022644,
      "learning_rate": 2.8116213683223993e-06,
      "loss": 1.403,
      "step": 6225
    },
    {
      "epoch": 0.9762574195563887,
      "grad_norm": 0.9556292295455933,
      "learning_rate": 2.421118400499844e-06,
      "loss": 1.3713,
      "step": 6250
    },
    {
      "epoch": 0.9801624492346142,
      "grad_norm": 1.0249353647232056,
      "learning_rate": 2.0306154326772886e-06,
      "loss": 1.2827,
      "step": 6275
    },
    {
      "epoch": 0.9840674789128397,
      "grad_norm": 1.1308499574661255,
      "learning_rate": 1.640112464854733e-06,
      "loss": 1.4159,
      "step": 6300
    },
    {
      "epoch": 0.9879725085910653,
      "grad_norm": 0.8749229907989502,
      "learning_rate": 1.2496094970321776e-06,
      "loss": 1.3634,
      "step": 6325
    },
    {
      "epoch": 0.9918775382692908,
      "grad_norm": 0.8601365089416504,
      "learning_rate": 8.591065292096222e-07,
      "loss": 1.3991,
      "step": 6350
    },
    {
      "epoch": 0.9957825679475164,
      "grad_norm": 0.7126524448394775,
      "learning_rate": 4.6860356138706653e-07,
      "loss": 1.4219,
      "step": 6375
    },
    {
      "epoch": 0.999687597625742,
      "grad_norm": 0.8441383838653564,
      "learning_rate": 7.81005935645111e-08,
      "loss": 1.3463,
      "step": 6400
    }
  ],
  "logging_steps": 25,
  "max_steps": 6402,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.5854365768627e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
