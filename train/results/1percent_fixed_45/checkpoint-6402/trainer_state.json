{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 1000,
  "global_step": 6402,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0039050296782255547,
      "grad_norm": 2.667614221572876,
      "learning_rate": 9.960949703217745e-05,
      "loss": 2.086,
      "step": 25
    },
    {
      "epoch": 0.007810059356451109,
      "grad_norm": 1.3980447053909302,
      "learning_rate": 9.92189940643549e-05,
      "loss": 1.6807,
      "step": 50
    },
    {
      "epoch": 0.011715089034676664,
      "grad_norm": 1.364211916923523,
      "learning_rate": 9.882849109653233e-05,
      "loss": 1.6251,
      "step": 75
    },
    {
      "epoch": 0.015620118712902219,
      "grad_norm": 0.9786134362220764,
      "learning_rate": 9.843798812870978e-05,
      "loss": 1.5938,
      "step": 100
    },
    {
      "epoch": 0.01952514839112777,
      "grad_norm": 1.0299339294433594,
      "learning_rate": 9.804748516088723e-05,
      "loss": 1.5873,
      "step": 125
    },
    {
      "epoch": 0.023430178069353328,
      "grad_norm": 1.2109655141830444,
      "learning_rate": 9.765698219306467e-05,
      "loss": 1.5439,
      "step": 150
    },
    {
      "epoch": 0.02733520774757888,
      "grad_norm": 0.823433518409729,
      "learning_rate": 9.726647922524212e-05,
      "loss": 1.5006,
      "step": 175
    },
    {
      "epoch": 0.031240237425804437,
      "grad_norm": 0.9298912882804871,
      "learning_rate": 9.687597625741956e-05,
      "loss": 1.4431,
      "step": 200
    },
    {
      "epoch": 0.035145267104029994,
      "grad_norm": 0.8727163076400757,
      "learning_rate": 9.6485473289597e-05,
      "loss": 1.4224,
      "step": 225
    },
    {
      "epoch": 0.03905029678225554,
      "grad_norm": 0.7782970070838928,
      "learning_rate": 9.609497032177445e-05,
      "loss": 1.4625,
      "step": 250
    },
    {
      "epoch": 0.0429553264604811,
      "grad_norm": 1.1470890045166016,
      "learning_rate": 9.57044673539519e-05,
      "loss": 1.4997,
      "step": 275
    },
    {
      "epoch": 0.046860356138706656,
      "grad_norm": 1.0045326948165894,
      "learning_rate": 9.531396438612934e-05,
      "loss": 1.4302,
      "step": 300
    },
    {
      "epoch": 0.050765385816932206,
      "grad_norm": 1.1342378854751587,
      "learning_rate": 9.492346141830677e-05,
      "loss": 1.4588,
      "step": 325
    },
    {
      "epoch": 0.05467041549515776,
      "grad_norm": 0.7640489339828491,
      "learning_rate": 9.453295845048423e-05,
      "loss": 1.4104,
      "step": 350
    },
    {
      "epoch": 0.05857544517338332,
      "grad_norm": 0.9593393206596375,
      "learning_rate": 9.414245548266167e-05,
      "loss": 1.4541,
      "step": 375
    },
    {
      "epoch": 0.062480474851608875,
      "grad_norm": 1.4207419157028198,
      "learning_rate": 9.375195251483912e-05,
      "loss": 1.4996,
      "step": 400
    },
    {
      "epoch": 0.06638550452983442,
      "grad_norm": 0.8273871541023254,
      "learning_rate": 9.336144954701657e-05,
      "loss": 1.4147,
      "step": 425
    },
    {
      "epoch": 0.07029053420805999,
      "grad_norm": 1.649265170097351,
      "learning_rate": 9.2970946579194e-05,
      "loss": 1.4013,
      "step": 450
    },
    {
      "epoch": 0.07419556388628554,
      "grad_norm": 0.9102451205253601,
      "learning_rate": 9.258044361137144e-05,
      "loss": 1.4625,
      "step": 475
    },
    {
      "epoch": 0.07810059356451109,
      "grad_norm": 0.8882356882095337,
      "learning_rate": 9.21899406435489e-05,
      "loss": 1.4622,
      "step": 500
    },
    {
      "epoch": 0.08200562324273665,
      "grad_norm": 1.0613986253738403,
      "learning_rate": 9.179943767572634e-05,
      "loss": 1.4017,
      "step": 525
    },
    {
      "epoch": 0.0859106529209622,
      "grad_norm": 0.8058245778083801,
      "learning_rate": 9.140893470790379e-05,
      "loss": 1.4185,
      "step": 550
    },
    {
      "epoch": 0.08981568259918775,
      "grad_norm": 0.7437413930892944,
      "learning_rate": 9.101843174008123e-05,
      "loss": 1.4225,
      "step": 575
    },
    {
      "epoch": 0.09372071227741331,
      "grad_norm": 0.894009530544281,
      "learning_rate": 9.062792877225867e-05,
      "loss": 1.4916,
      "step": 600
    },
    {
      "epoch": 0.09762574195563886,
      "grad_norm": 1.0774874687194824,
      "learning_rate": 9.023742580443611e-05,
      "loss": 1.4311,
      "step": 625
    },
    {
      "epoch": 0.10153077163386441,
      "grad_norm": 1.0812619924545288,
      "learning_rate": 8.984692283661357e-05,
      "loss": 1.3946,
      "step": 650
    },
    {
      "epoch": 0.10543580131208997,
      "grad_norm": 1.1440340280532837,
      "learning_rate": 8.945641986879101e-05,
      "loss": 1.4454,
      "step": 675
    },
    {
      "epoch": 0.10934083099031552,
      "grad_norm": 1.149057388305664,
      "learning_rate": 8.906591690096846e-05,
      "loss": 1.3536,
      "step": 700
    },
    {
      "epoch": 0.11324586066854109,
      "grad_norm": 1.4595485925674438,
      "learning_rate": 8.86754139331459e-05,
      "loss": 1.4182,
      "step": 725
    },
    {
      "epoch": 0.11715089034676664,
      "grad_norm": 0.982612669467926,
      "learning_rate": 8.828491096532334e-05,
      "loss": 1.4427,
      "step": 750
    },
    {
      "epoch": 0.12105592002499219,
      "grad_norm": 0.8430896401405334,
      "learning_rate": 8.789440799750078e-05,
      "loss": 1.4372,
      "step": 775
    },
    {
      "epoch": 0.12496094970321775,
      "grad_norm": 0.7982050180435181,
      "learning_rate": 8.750390502967824e-05,
      "loss": 1.4192,
      "step": 800
    },
    {
      "epoch": 0.12886597938144329,
      "grad_norm": 0.7222572565078735,
      "learning_rate": 8.711340206185567e-05,
      "loss": 1.4379,
      "step": 825
    },
    {
      "epoch": 0.13277100905966885,
      "grad_norm": 0.8406205773353577,
      "learning_rate": 8.672289909403311e-05,
      "loss": 1.371,
      "step": 850
    },
    {
      "epoch": 0.1366760387378944,
      "grad_norm": 1.0065869092941284,
      "learning_rate": 8.633239612621057e-05,
      "loss": 1.4606,
      "step": 875
    },
    {
      "epoch": 0.14058106841611998,
      "grad_norm": 0.9374203085899353,
      "learning_rate": 8.59575132771009e-05,
      "loss": 1.3948,
      "step": 900
    },
    {
      "epoch": 0.1444860980943455,
      "grad_norm": 1.1805894374847412,
      "learning_rate": 8.556701030927835e-05,
      "loss": 1.3975,
      "step": 925
    },
    {
      "epoch": 0.14839112777257107,
      "grad_norm": 1.0600637197494507,
      "learning_rate": 8.51765073414558e-05,
      "loss": 1.38,
      "step": 950
    },
    {
      "epoch": 0.15229615745079664,
      "grad_norm": 0.8125050663948059,
      "learning_rate": 8.478600437363325e-05,
      "loss": 1.4302,
      "step": 975
    },
    {
      "epoch": 0.15620118712902217,
      "grad_norm": 1.1527090072631836,
      "learning_rate": 8.439550140581068e-05,
      "loss": 1.3926,
      "step": 1000
    },
    {
      "epoch": 0.15620118712902217,
      "eval_loss": 1.4052050113677979,
      "eval_runtime": 1622.7292,
      "eval_samples_per_second": 6.312,
      "eval_steps_per_second": 6.312,
      "step": 1000
    },
    {
      "epoch": 0.16010621680724774,
      "grad_norm": 1.1384228467941284,
      "learning_rate": 8.400499843798813e-05,
      "loss": 1.4006,
      "step": 1025
    },
    {
      "epoch": 0.1640112464854733,
      "grad_norm": 0.8426644206047058,
      "learning_rate": 8.361449547016558e-05,
      "loss": 1.4121,
      "step": 1050
    },
    {
      "epoch": 0.16791627616369884,
      "grad_norm": 0.9308421611785889,
      "learning_rate": 8.322399250234302e-05,
      "loss": 1.3806,
      "step": 1075
    },
    {
      "epoch": 0.1718213058419244,
      "grad_norm": 0.8931906223297119,
      "learning_rate": 8.283348953452048e-05,
      "loss": 1.4134,
      "step": 1100
    },
    {
      "epoch": 0.17572633552014996,
      "grad_norm": 1.3529839515686035,
      "learning_rate": 8.24429865666979e-05,
      "loss": 1.3534,
      "step": 1125
    },
    {
      "epoch": 0.1796313651983755,
      "grad_norm": 0.5932314991950989,
      "learning_rate": 8.205248359887535e-05,
      "loss": 1.4206,
      "step": 1150
    },
    {
      "epoch": 0.18353639487660106,
      "grad_norm": 0.9970126152038574,
      "learning_rate": 8.16619806310528e-05,
      "loss": 1.4121,
      "step": 1175
    },
    {
      "epoch": 0.18744142455482662,
      "grad_norm": 1.464310646057129,
      "learning_rate": 8.127147766323025e-05,
      "loss": 1.4092,
      "step": 1200
    },
    {
      "epoch": 0.19134645423305216,
      "grad_norm": 0.9243414998054504,
      "learning_rate": 8.088097469540769e-05,
      "loss": 1.412,
      "step": 1225
    },
    {
      "epoch": 0.19525148391127772,
      "grad_norm": 0.7515794634819031,
      "learning_rate": 8.049047172758513e-05,
      "loss": 1.4047,
      "step": 1250
    },
    {
      "epoch": 0.1991565135895033,
      "grad_norm": 1.0515974760055542,
      "learning_rate": 8.009996875976257e-05,
      "loss": 1.3923,
      "step": 1275
    },
    {
      "epoch": 0.20306154326772882,
      "grad_norm": 0.9257907271385193,
      "learning_rate": 7.970946579194002e-05,
      "loss": 1.4052,
      "step": 1300
    },
    {
      "epoch": 0.20696657294595439,
      "grad_norm": 0.9091492295265198,
      "learning_rate": 7.931896282411747e-05,
      "loss": 1.4048,
      "step": 1325
    },
    {
      "epoch": 0.21087160262417995,
      "grad_norm": 0.9852029085159302,
      "learning_rate": 7.892845985629492e-05,
      "loss": 1.4132,
      "step": 1350
    },
    {
      "epoch": 0.21477663230240548,
      "grad_norm": 0.8544608950614929,
      "learning_rate": 7.853795688847236e-05,
      "loss": 1.4107,
      "step": 1375
    },
    {
      "epoch": 0.21868166198063105,
      "grad_norm": 0.8615522980690002,
      "learning_rate": 7.81474539206498e-05,
      "loss": 1.4143,
      "step": 1400
    },
    {
      "epoch": 0.2225866916588566,
      "grad_norm": 0.9858955144882202,
      "learning_rate": 7.775695095282724e-05,
      "loss": 1.4129,
      "step": 1425
    },
    {
      "epoch": 0.22649172133708217,
      "grad_norm": 1.2510095834732056,
      "learning_rate": 7.736644798500469e-05,
      "loss": 1.4575,
      "step": 1450
    },
    {
      "epoch": 0.2303967510153077,
      "grad_norm": 0.7756524682044983,
      "learning_rate": 7.697594501718214e-05,
      "loss": 1.4522,
      "step": 1475
    },
    {
      "epoch": 0.23430178069353327,
      "grad_norm": 0.7558953166007996,
      "learning_rate": 7.658544204935957e-05,
      "loss": 1.4084,
      "step": 1500
    },
    {
      "epoch": 0.23820681037175884,
      "grad_norm": 1.0960522890090942,
      "learning_rate": 7.619493908153702e-05,
      "loss": 1.394,
      "step": 1525
    },
    {
      "epoch": 0.24211184004998437,
      "grad_norm": 0.8992601037025452,
      "learning_rate": 7.580443611371447e-05,
      "loss": 1.3485,
      "step": 1550
    },
    {
      "epoch": 0.24601686972820994,
      "grad_norm": 1.1658854484558105,
      "learning_rate": 7.541393314589191e-05,
      "loss": 1.4299,
      "step": 1575
    },
    {
      "epoch": 0.2499218994064355,
      "grad_norm": 0.9303913712501526,
      "learning_rate": 7.502343017806936e-05,
      "loss": 1.3628,
      "step": 1600
    },
    {
      "epoch": 0.25382692908466103,
      "grad_norm": 1.0385076999664307,
      "learning_rate": 7.46329272102468e-05,
      "loss": 1.4269,
      "step": 1625
    },
    {
      "epoch": 0.25773195876288657,
      "grad_norm": 0.9098231196403503,
      "learning_rate": 7.424242424242424e-05,
      "loss": 1.3965,
      "step": 1650
    },
    {
      "epoch": 0.26163698844111216,
      "grad_norm": 0.8599331974983215,
      "learning_rate": 7.385192127460169e-05,
      "loss": 1.4298,
      "step": 1675
    },
    {
      "epoch": 0.2655420181193377,
      "grad_norm": 1.060829520225525,
      "learning_rate": 7.346141830677914e-05,
      "loss": 1.4133,
      "step": 1700
    },
    {
      "epoch": 0.2694470477975633,
      "grad_norm": 0.9157875180244446,
      "learning_rate": 7.307091533895658e-05,
      "loss": 1.3746,
      "step": 1725
    },
    {
      "epoch": 0.2733520774757888,
      "grad_norm": 0.9746167659759521,
      "learning_rate": 7.268041237113403e-05,
      "loss": 1.3747,
      "step": 1750
    },
    {
      "epoch": 0.27725710715401436,
      "grad_norm": 0.9867209196090698,
      "learning_rate": 7.228990940331147e-05,
      "loss": 1.405,
      "step": 1775
    },
    {
      "epoch": 0.28116213683223995,
      "grad_norm": 1.1062097549438477,
      "learning_rate": 7.189940643548891e-05,
      "loss": 1.3748,
      "step": 1800
    },
    {
      "epoch": 0.2850671665104655,
      "grad_norm": 0.9221513867378235,
      "learning_rate": 7.150890346766636e-05,
      "loss": 1.3604,
      "step": 1825
    },
    {
      "epoch": 0.288972196188691,
      "grad_norm": 0.9435021877288818,
      "learning_rate": 7.111840049984381e-05,
      "loss": 1.355,
      "step": 1850
    },
    {
      "epoch": 0.2928772258669166,
      "grad_norm": 0.9071446061134338,
      "learning_rate": 7.072789753202124e-05,
      "loss": 1.3287,
      "step": 1875
    },
    {
      "epoch": 0.29678225554514215,
      "grad_norm": 1.0413818359375,
      "learning_rate": 7.033739456419868e-05,
      "loss": 1.4089,
      "step": 1900
    },
    {
      "epoch": 0.3006872852233677,
      "grad_norm": 0.9700104594230652,
      "learning_rate": 6.994689159637614e-05,
      "loss": 1.4351,
      "step": 1925
    },
    {
      "epoch": 0.3045923149015933,
      "grad_norm": 0.7480035424232483,
      "learning_rate": 6.955638862855358e-05,
      "loss": 1.3651,
      "step": 1950
    },
    {
      "epoch": 0.3084973445798188,
      "grad_norm": 1.122504472732544,
      "learning_rate": 6.916588566073103e-05,
      "loss": 1.3337,
      "step": 1975
    },
    {
      "epoch": 0.31240237425804435,
      "grad_norm": 0.9987568259239197,
      "learning_rate": 6.877538269290847e-05,
      "loss": 1.3862,
      "step": 2000
    },
    {
      "epoch": 0.31240237425804435,
      "eval_loss": 1.3857861757278442,
      "eval_runtime": 1622.7885,
      "eval_samples_per_second": 6.312,
      "eval_steps_per_second": 6.312,
      "step": 2000
    },
    {
      "epoch": 0.31630740393626994,
      "grad_norm": 1.0310364961624146,
      "learning_rate": 6.838487972508591e-05,
      "loss": 1.3515,
      "step": 2025
    },
    {
      "epoch": 0.3202124336144955,
      "grad_norm": 1.1168785095214844,
      "learning_rate": 6.799437675726335e-05,
      "loss": 1.4056,
      "step": 2050
    },
    {
      "epoch": 0.324117463292721,
      "grad_norm": 1.0255848169326782,
      "learning_rate": 6.760387378944081e-05,
      "loss": 1.4112,
      "step": 2075
    },
    {
      "epoch": 0.3280224929709466,
      "grad_norm": 0.7672733664512634,
      "learning_rate": 6.721337082161825e-05,
      "loss": 1.3343,
      "step": 2100
    },
    {
      "epoch": 0.33192752264917214,
      "grad_norm": 1.0296937227249146,
      "learning_rate": 6.68228678537957e-05,
      "loss": 1.3829,
      "step": 2125
    },
    {
      "epoch": 0.33583255232739767,
      "grad_norm": 1.0130810737609863,
      "learning_rate": 6.643236488597314e-05,
      "loss": 1.3593,
      "step": 2150
    },
    {
      "epoch": 0.33973758200562326,
      "grad_norm": 0.7353454828262329,
      "learning_rate": 6.604186191815058e-05,
      "loss": 1.3805,
      "step": 2175
    },
    {
      "epoch": 0.3436426116838488,
      "grad_norm": 0.8967730402946472,
      "learning_rate": 6.565135895032802e-05,
      "loss": 1.3988,
      "step": 2200
    },
    {
      "epoch": 0.34754764136207433,
      "grad_norm": 0.9539893269538879,
      "learning_rate": 6.526085598250548e-05,
      "loss": 1.4093,
      "step": 2225
    },
    {
      "epoch": 0.3514526710402999,
      "grad_norm": 0.8970681428909302,
      "learning_rate": 6.487035301468292e-05,
      "loss": 1.3807,
      "step": 2250
    },
    {
      "epoch": 0.35535770071852546,
      "grad_norm": 0.7226057648658752,
      "learning_rate": 6.447985004686035e-05,
      "loss": 1.4045,
      "step": 2275
    },
    {
      "epoch": 0.359262730396751,
      "grad_norm": 0.777022659778595,
      "learning_rate": 6.408934707903781e-05,
      "loss": 1.3229,
      "step": 2300
    },
    {
      "epoch": 0.3631677600749766,
      "grad_norm": 0.9122993350028992,
      "learning_rate": 6.369884411121525e-05,
      "loss": 1.4247,
      "step": 2325
    },
    {
      "epoch": 0.3670727897532021,
      "grad_norm": 0.9369353652000427,
      "learning_rate": 6.33083411433927e-05,
      "loss": 1.393,
      "step": 2350
    },
    {
      "epoch": 0.37097781943142766,
      "grad_norm": 0.7946913242340088,
      "learning_rate": 6.291783817557014e-05,
      "loss": 1.3578,
      "step": 2375
    },
    {
      "epoch": 0.37488284910965325,
      "grad_norm": 0.9526868462562561,
      "learning_rate": 6.252733520774758e-05,
      "loss": 1.4007,
      "step": 2400
    },
    {
      "epoch": 0.3787878787878788,
      "grad_norm": 0.739693820476532,
      "learning_rate": 6.213683223992502e-05,
      "loss": 1.3908,
      "step": 2425
    },
    {
      "epoch": 0.3826929084661043,
      "grad_norm": 1.2242399454116821,
      "learning_rate": 6.174632927210246e-05,
      "loss": 1.4136,
      "step": 2450
    },
    {
      "epoch": 0.3865979381443299,
      "grad_norm": 0.8884421586990356,
      "learning_rate": 6.135582630427992e-05,
      "loss": 1.3161,
      "step": 2475
    },
    {
      "epoch": 0.39050296782255545,
      "grad_norm": 1.0514496564865112,
      "learning_rate": 6.096532333645736e-05,
      "loss": 1.4042,
      "step": 2500
    },
    {
      "epoch": 0.394407997500781,
      "grad_norm": 0.82368403673172,
      "learning_rate": 6.05748203686348e-05,
      "loss": 1.3924,
      "step": 2525
    },
    {
      "epoch": 0.3983130271790066,
      "grad_norm": 0.9879562258720398,
      "learning_rate": 6.018431740081225e-05,
      "loss": 1.44,
      "step": 2550
    },
    {
      "epoch": 0.4022180568572321,
      "grad_norm": 0.8916620016098022,
      "learning_rate": 5.979381443298969e-05,
      "loss": 1.356,
      "step": 2575
    },
    {
      "epoch": 0.40612308653545764,
      "grad_norm": 0.9367232918739319,
      "learning_rate": 5.9403311465167135e-05,
      "loss": 1.3415,
      "step": 2600
    },
    {
      "epoch": 0.41002811621368324,
      "grad_norm": 0.9886413812637329,
      "learning_rate": 5.9012808497344584e-05,
      "loss": 1.4205,
      "step": 2625
    },
    {
      "epoch": 0.41393314589190877,
      "grad_norm": 0.7399585247039795,
      "learning_rate": 5.862230552952203e-05,
      "loss": 1.4242,
      "step": 2650
    },
    {
      "epoch": 0.4178381755701343,
      "grad_norm": 0.8312200903892517,
      "learning_rate": 5.823180256169947e-05,
      "loss": 1.3792,
      "step": 2675
    },
    {
      "epoch": 0.4217432052483599,
      "grad_norm": 0.6158322095870972,
      "learning_rate": 5.784129959387692e-05,
      "loss": 1.4083,
      "step": 2700
    },
    {
      "epoch": 0.42564823492658543,
      "grad_norm": 1.160950779914856,
      "learning_rate": 5.745079662605436e-05,
      "loss": 1.3931,
      "step": 2725
    },
    {
      "epoch": 0.42955326460481097,
      "grad_norm": 1.0193110704421997,
      "learning_rate": 5.70602936582318e-05,
      "loss": 1.3745,
      "step": 2750
    },
    {
      "epoch": 0.43345829428303656,
      "grad_norm": 0.7512489557266235,
      "learning_rate": 5.6669790690409254e-05,
      "loss": 1.374,
      "step": 2775
    },
    {
      "epoch": 0.4373633239612621,
      "grad_norm": 0.9833813309669495,
      "learning_rate": 5.627928772258669e-05,
      "loss": 1.4005,
      "step": 2800
    },
    {
      "epoch": 0.4412683536394877,
      "grad_norm": 0.6295449137687683,
      "learning_rate": 5.588878475476413e-05,
      "loss": 1.3484,
      "step": 2825
    },
    {
      "epoch": 0.4451733833177132,
      "grad_norm": 0.9160325527191162,
      "learning_rate": 5.549828178694159e-05,
      "loss": 1.3703,
      "step": 2850
    },
    {
      "epoch": 0.44907841299593876,
      "grad_norm": 0.6376701593399048,
      "learning_rate": 5.5107778819119025e-05,
      "loss": 1.3991,
      "step": 2875
    },
    {
      "epoch": 0.45298344267416435,
      "grad_norm": 0.899139940738678,
      "learning_rate": 5.471727585129647e-05,
      "loss": 1.3843,
      "step": 2900
    },
    {
      "epoch": 0.4568884723523899,
      "grad_norm": 0.646683931350708,
      "learning_rate": 5.432677288347392e-05,
      "loss": 1.3159,
      "step": 2925
    },
    {
      "epoch": 0.4607935020306154,
      "grad_norm": 0.6878605484962463,
      "learning_rate": 5.393626991565136e-05,
      "loss": 1.368,
      "step": 2950
    },
    {
      "epoch": 0.464698531708841,
      "grad_norm": 0.660723090171814,
      "learning_rate": 5.35457669478288e-05,
      "loss": 1.3609,
      "step": 2975
    },
    {
      "epoch": 0.46860356138706655,
      "grad_norm": 0.9045199155807495,
      "learning_rate": 5.315526398000625e-05,
      "loss": 1.408,
      "step": 3000
    },
    {
      "epoch": 0.46860356138706655,
      "eval_loss": 1.3759063482284546,
      "eval_runtime": 1622.5533,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 3000
    },
    {
      "epoch": 0.4725085910652921,
      "grad_norm": 0.6522685885429382,
      "learning_rate": 5.2764761012183695e-05,
      "loss": 1.3679,
      "step": 3025
    },
    {
      "epoch": 0.4764136207435177,
      "grad_norm": 0.7816814184188843,
      "learning_rate": 5.237425804436114e-05,
      "loss": 1.3404,
      "step": 3050
    },
    {
      "epoch": 0.4803186504217432,
      "grad_norm": 0.7656710743904114,
      "learning_rate": 5.198375507653859e-05,
      "loss": 1.3993,
      "step": 3075
    },
    {
      "epoch": 0.48422368009996875,
      "grad_norm": 0.7205098867416382,
      "learning_rate": 5.159325210871603e-05,
      "loss": 1.3086,
      "step": 3100
    },
    {
      "epoch": 0.48812870977819434,
      "grad_norm": 0.8074643015861511,
      "learning_rate": 5.1202749140893466e-05,
      "loss": 1.3808,
      "step": 3125
    },
    {
      "epoch": 0.49203373945641987,
      "grad_norm": 0.8281275629997253,
      "learning_rate": 5.081224617307092e-05,
      "loss": 1.4272,
      "step": 3150
    },
    {
      "epoch": 0.4959387691346454,
      "grad_norm": 0.8126469254493713,
      "learning_rate": 5.0421743205248365e-05,
      "loss": 1.3776,
      "step": 3175
    },
    {
      "epoch": 0.499843798812871,
      "grad_norm": 0.8844707012176514,
      "learning_rate": 5.00312402374258e-05,
      "loss": 1.4237,
      "step": 3200
    },
    {
      "epoch": 0.5037488284910965,
      "grad_norm": 0.9260271787643433,
      "learning_rate": 4.964073726960325e-05,
      "loss": 1.3967,
      "step": 3225
    },
    {
      "epoch": 0.5076538581693221,
      "grad_norm": 0.5531688928604126,
      "learning_rate": 4.925023430178069e-05,
      "loss": 1.3409,
      "step": 3250
    },
    {
      "epoch": 0.5115588878475477,
      "grad_norm": 0.8761987686157227,
      "learning_rate": 4.885973133395814e-05,
      "loss": 1.3996,
      "step": 3275
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 1.115472435951233,
      "learning_rate": 4.8469228366135585e-05,
      "loss": 1.4153,
      "step": 3300
    },
    {
      "epoch": 0.5193689472039987,
      "grad_norm": 0.8147813081741333,
      "learning_rate": 4.807872539831303e-05,
      "loss": 1.3781,
      "step": 3325
    },
    {
      "epoch": 0.5232739768822243,
      "grad_norm": 1.0270342826843262,
      "learning_rate": 4.768822243049048e-05,
      "loss": 1.3671,
      "step": 3350
    },
    {
      "epoch": 0.5271790065604499,
      "grad_norm": 0.8861477971076965,
      "learning_rate": 4.7297719462667913e-05,
      "loss": 1.4369,
      "step": 3375
    },
    {
      "epoch": 0.5310840362386754,
      "grad_norm": 0.863900363445282,
      "learning_rate": 4.690721649484536e-05,
      "loss": 1.4274,
      "step": 3400
    },
    {
      "epoch": 0.534989065916901,
      "grad_norm": 1.2747888565063477,
      "learning_rate": 4.651671352702281e-05,
      "loss": 1.4183,
      "step": 3425
    },
    {
      "epoch": 0.5388940955951266,
      "grad_norm": 1.1643182039260864,
      "learning_rate": 4.612621055920025e-05,
      "loss": 1.42,
      "step": 3450
    },
    {
      "epoch": 0.5427991252733521,
      "grad_norm": 0.4631425440311432,
      "learning_rate": 4.57357075913777e-05,
      "loss": 1.3635,
      "step": 3475
    },
    {
      "epoch": 0.5467041549515776,
      "grad_norm": 0.6729965209960938,
      "learning_rate": 4.534520462355514e-05,
      "loss": 1.4011,
      "step": 3500
    },
    {
      "epoch": 0.5506091846298032,
      "grad_norm": 0.837916910648346,
      "learning_rate": 4.495470165573258e-05,
      "loss": 1.4387,
      "step": 3525
    },
    {
      "epoch": 0.5545142143080287,
      "grad_norm": 1.130289912223816,
      "learning_rate": 4.456419868791003e-05,
      "loss": 1.3492,
      "step": 3550
    },
    {
      "epoch": 0.5584192439862543,
      "grad_norm": 0.8943081498146057,
      "learning_rate": 4.4173695720087476e-05,
      "loss": 1.3997,
      "step": 3575
    },
    {
      "epoch": 0.5623242736644799,
      "grad_norm": 0.9528043866157532,
      "learning_rate": 4.378319275226492e-05,
      "loss": 1.2748,
      "step": 3600
    },
    {
      "epoch": 0.5662293033427054,
      "grad_norm": 0.793690025806427,
      "learning_rate": 4.339268978444236e-05,
      "loss": 1.3811,
      "step": 3625
    },
    {
      "epoch": 0.570134333020931,
      "grad_norm": 0.8543319702148438,
      "learning_rate": 4.300218681661981e-05,
      "loss": 1.3688,
      "step": 3650
    },
    {
      "epoch": 0.5740393626991566,
      "grad_norm": 0.7971034646034241,
      "learning_rate": 4.261168384879725e-05,
      "loss": 1.363,
      "step": 3675
    },
    {
      "epoch": 0.577944392377382,
      "grad_norm": 0.8946098685264587,
      "learning_rate": 4.2221180880974696e-05,
      "loss": 1.4152,
      "step": 3700
    },
    {
      "epoch": 0.5818494220556076,
      "grad_norm": 0.8981408476829529,
      "learning_rate": 4.1830677913152146e-05,
      "loss": 1.3354,
      "step": 3725
    },
    {
      "epoch": 0.5857544517338332,
      "grad_norm": 0.9047496318817139,
      "learning_rate": 4.144017494532959e-05,
      "loss": 1.3915,
      "step": 3750
    },
    {
      "epoch": 0.5896594814120587,
      "grad_norm": 1.0139360427856445,
      "learning_rate": 4.104967197750703e-05,
      "loss": 1.3995,
      "step": 3775
    },
    {
      "epoch": 0.5935645110902843,
      "grad_norm": 0.8176496028900146,
      "learning_rate": 4.065916900968448e-05,
      "loss": 1.348,
      "step": 3800
    },
    {
      "epoch": 0.5974695407685099,
      "grad_norm": 0.7933390140533447,
      "learning_rate": 4.0268666041861916e-05,
      "loss": 1.4399,
      "step": 3825
    },
    {
      "epoch": 0.6013745704467354,
      "grad_norm": 0.8113753199577332,
      "learning_rate": 3.9878163074039366e-05,
      "loss": 1.3755,
      "step": 3850
    },
    {
      "epoch": 0.605279600124961,
      "grad_norm": 1.094759225845337,
      "learning_rate": 3.948766010621681e-05,
      "loss": 1.3787,
      "step": 3875
    },
    {
      "epoch": 0.6091846298031866,
      "grad_norm": 0.71561598777771,
      "learning_rate": 3.909715713839425e-05,
      "loss": 1.4259,
      "step": 3900
    },
    {
      "epoch": 0.613089659481412,
      "grad_norm": 0.8191795349121094,
      "learning_rate": 3.87066541705717e-05,
      "loss": 1.3591,
      "step": 3925
    },
    {
      "epoch": 0.6169946891596376,
      "grad_norm": 1.1845033168792725,
      "learning_rate": 3.8316151202749144e-05,
      "loss": 1.3892,
      "step": 3950
    },
    {
      "epoch": 0.6208997188378632,
      "grad_norm": 1.175190806388855,
      "learning_rate": 3.7925648234926586e-05,
      "loss": 1.3292,
      "step": 3975
    },
    {
      "epoch": 0.6248047485160887,
      "grad_norm": 0.9154787063598633,
      "learning_rate": 3.7535145267104036e-05,
      "loss": 1.4162,
      "step": 4000
    },
    {
      "epoch": 0.6248047485160887,
      "eval_loss": 1.3701887130737305,
      "eval_runtime": 1622.584,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 4000
    },
    {
      "epoch": 0.6287097781943143,
      "grad_norm": 1.1935877799987793,
      "learning_rate": 3.714464229928147e-05,
      "loss": 1.4319,
      "step": 4025
    },
    {
      "epoch": 0.6326148078725399,
      "grad_norm": 0.613724946975708,
      "learning_rate": 3.675413933145892e-05,
      "loss": 1.3449,
      "step": 4050
    },
    {
      "epoch": 0.6365198375507654,
      "grad_norm": 1.2018052339553833,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.4024,
      "step": 4075
    },
    {
      "epoch": 0.640424867228991,
      "grad_norm": 0.8014431595802307,
      "learning_rate": 3.597313339581381e-05,
      "loss": 1.4108,
      "step": 4100
    },
    {
      "epoch": 0.6443298969072165,
      "grad_norm": 0.7176395654678345,
      "learning_rate": 3.5582630427991256e-05,
      "loss": 1.4115,
      "step": 4125
    },
    {
      "epoch": 0.648234926585442,
      "grad_norm": 1.0104461908340454,
      "learning_rate": 3.51921274601687e-05,
      "loss": 1.4901,
      "step": 4150
    },
    {
      "epoch": 0.6521399562636676,
      "grad_norm": 0.770412027835846,
      "learning_rate": 3.480162449234614e-05,
      "loss": 1.3421,
      "step": 4175
    },
    {
      "epoch": 0.6560449859418932,
      "grad_norm": 0.8376518487930298,
      "learning_rate": 3.4411121524523585e-05,
      "loss": 1.4149,
      "step": 4200
    },
    {
      "epoch": 0.6599500156201187,
      "grad_norm": 0.8812894821166992,
      "learning_rate": 3.4020618556701034e-05,
      "loss": 1.3513,
      "step": 4225
    },
    {
      "epoch": 0.6638550452983443,
      "grad_norm": 0.6963175535202026,
      "learning_rate": 3.363011558887848e-05,
      "loss": 1.3291,
      "step": 4250
    },
    {
      "epoch": 0.6677600749765699,
      "grad_norm": 0.742632269859314,
      "learning_rate": 3.323961262105592e-05,
      "loss": 1.3713,
      "step": 4275
    },
    {
      "epoch": 0.6716651046547953,
      "grad_norm": 0.8418535590171814,
      "learning_rate": 3.284910965323337e-05,
      "loss": 1.3354,
      "step": 4300
    },
    {
      "epoch": 0.6755701343330209,
      "grad_norm": 0.9141480326652527,
      "learning_rate": 3.2458606685410805e-05,
      "loss": 1.3146,
      "step": 4325
    },
    {
      "epoch": 0.6794751640112465,
      "grad_norm": 0.7500324845314026,
      "learning_rate": 3.2068103717588255e-05,
      "loss": 1.3797,
      "step": 4350
    },
    {
      "epoch": 0.683380193689472,
      "grad_norm": 0.9812290072441101,
      "learning_rate": 3.1677600749765704e-05,
      "loss": 1.3834,
      "step": 4375
    },
    {
      "epoch": 0.6872852233676976,
      "grad_norm": 0.9759565591812134,
      "learning_rate": 3.128709778194314e-05,
      "loss": 1.3593,
      "step": 4400
    },
    {
      "epoch": 0.6911902530459232,
      "grad_norm": 0.9626295566558838,
      "learning_rate": 3.089659481412059e-05,
      "loss": 1.3722,
      "step": 4425
    },
    {
      "epoch": 0.6950952827241487,
      "grad_norm": 0.8151344060897827,
      "learning_rate": 3.0506091846298036e-05,
      "loss": 1.3936,
      "step": 4450
    },
    {
      "epoch": 0.6990003124023743,
      "grad_norm": 0.7135285139083862,
      "learning_rate": 3.0115588878475475e-05,
      "loss": 1.3557,
      "step": 4475
    },
    {
      "epoch": 0.7029053420805998,
      "grad_norm": 0.8061526417732239,
      "learning_rate": 2.972508591065292e-05,
      "loss": 1.3631,
      "step": 4500
    },
    {
      "epoch": 0.7068103717588253,
      "grad_norm": 0.862827479839325,
      "learning_rate": 2.9334582942830367e-05,
      "loss": 1.3316,
      "step": 4525
    },
    {
      "epoch": 0.7107154014370509,
      "grad_norm": 0.8099215626716614,
      "learning_rate": 2.894407997500781e-05,
      "loss": 1.4162,
      "step": 4550
    },
    {
      "epoch": 0.7146204311152765,
      "grad_norm": 0.8601449728012085,
      "learning_rate": 2.8553577007185256e-05,
      "loss": 1.4365,
      "step": 4575
    },
    {
      "epoch": 0.718525460793502,
      "grad_norm": 0.9073020219802856,
      "learning_rate": 2.8163074039362702e-05,
      "loss": 1.3927,
      "step": 4600
    },
    {
      "epoch": 0.7224304904717276,
      "grad_norm": 0.9113284349441528,
      "learning_rate": 2.7772571071540145e-05,
      "loss": 1.3259,
      "step": 4625
    },
    {
      "epoch": 0.7263355201499532,
      "grad_norm": 0.9161360859870911,
      "learning_rate": 2.738206810371759e-05,
      "loss": 1.3983,
      "step": 4650
    },
    {
      "epoch": 0.7302405498281787,
      "grad_norm": 0.778977632522583,
      "learning_rate": 2.6991565135895037e-05,
      "loss": 1.3792,
      "step": 4675
    },
    {
      "epoch": 0.7341455795064042,
      "grad_norm": 0.5949777364730835,
      "learning_rate": 2.6601062168072477e-05,
      "loss": 1.2958,
      "step": 4700
    },
    {
      "epoch": 0.7380506091846298,
      "grad_norm": 0.9184366464614868,
      "learning_rate": 2.6210559200249923e-05,
      "loss": 1.3444,
      "step": 4725
    },
    {
      "epoch": 0.7419556388628553,
      "grad_norm": 0.6728569865226746,
      "learning_rate": 2.582005623242737e-05,
      "loss": 1.3313,
      "step": 4750
    },
    {
      "epoch": 0.7458606685410809,
      "grad_norm": 1.125246286392212,
      "learning_rate": 2.542955326460481e-05,
      "loss": 1.3758,
      "step": 4775
    },
    {
      "epoch": 0.7497656982193065,
      "grad_norm": 0.9308058023452759,
      "learning_rate": 2.5039050296782258e-05,
      "loss": 1.3505,
      "step": 4800
    },
    {
      "epoch": 0.753670727897532,
      "grad_norm": 0.7900913953781128,
      "learning_rate": 2.46485473289597e-05,
      "loss": 1.3434,
      "step": 4825
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 0.9240538477897644,
      "learning_rate": 2.4258044361137146e-05,
      "loss": 1.3971,
      "step": 4850
    },
    {
      "epoch": 0.7614807872539832,
      "grad_norm": 0.5660123825073242,
      "learning_rate": 2.386754139331459e-05,
      "loss": 1.3471,
      "step": 4875
    },
    {
      "epoch": 0.7653858169322086,
      "grad_norm": 1.1822915077209473,
      "learning_rate": 2.3477038425492035e-05,
      "loss": 1.4148,
      "step": 4900
    },
    {
      "epoch": 0.7692908466104342,
      "grad_norm": 0.9435907006263733,
      "learning_rate": 2.310215557638238e-05,
      "loss": 1.3767,
      "step": 4925
    },
    {
      "epoch": 0.7731958762886598,
      "grad_norm": 0.9102172255516052,
      "learning_rate": 2.2711652608559827e-05,
      "loss": 1.3938,
      "step": 4950
    },
    {
      "epoch": 0.7771009059668853,
      "grad_norm": 0.7171729803085327,
      "learning_rate": 2.232114964073727e-05,
      "loss": 1.4176,
      "step": 4975
    },
    {
      "epoch": 0.7810059356451109,
      "grad_norm": 0.8130736351013184,
      "learning_rate": 2.1930646672914716e-05,
      "loss": 1.3492,
      "step": 5000
    },
    {
      "epoch": 0.7810059356451109,
      "eval_loss": 1.366065502166748,
      "eval_runtime": 1622.6071,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 5000
    },
    {
      "epoch": 0.7849109653233365,
      "grad_norm": 0.7610253691673279,
      "learning_rate": 2.154014370509216e-05,
      "loss": 1.374,
      "step": 5025
    },
    {
      "epoch": 0.788815995001562,
      "grad_norm": 1.2266952991485596,
      "learning_rate": 2.1149640737269604e-05,
      "loss": 1.4141,
      "step": 5050
    },
    {
      "epoch": 0.7927210246797876,
      "grad_norm": 0.8817358613014221,
      "learning_rate": 2.0759137769447047e-05,
      "loss": 1.4292,
      "step": 5075
    },
    {
      "epoch": 0.7966260543580131,
      "grad_norm": 0.8030802011489868,
      "learning_rate": 2.0368634801624493e-05,
      "loss": 1.3007,
      "step": 5100
    },
    {
      "epoch": 0.8005310840362386,
      "grad_norm": 0.7865251302719116,
      "learning_rate": 1.997813183380194e-05,
      "loss": 1.3977,
      "step": 5125
    },
    {
      "epoch": 0.8044361137144642,
      "grad_norm": 0.9429495334625244,
      "learning_rate": 1.9587628865979382e-05,
      "loss": 1.3406,
      "step": 5150
    },
    {
      "epoch": 0.8083411433926898,
      "grad_norm": 0.7856985926628113,
      "learning_rate": 1.9197125898156825e-05,
      "loss": 1.3436,
      "step": 5175
    },
    {
      "epoch": 0.8122461730709153,
      "grad_norm": 0.7528045177459717,
      "learning_rate": 1.880662293033427e-05,
      "loss": 1.3797,
      "step": 5200
    },
    {
      "epoch": 0.8161512027491409,
      "grad_norm": 0.8699958920478821,
      "learning_rate": 1.8416119962511717e-05,
      "loss": 1.3514,
      "step": 5225
    },
    {
      "epoch": 0.8200562324273665,
      "grad_norm": 0.9381590485572815,
      "learning_rate": 1.802561699468916e-05,
      "loss": 1.4192,
      "step": 5250
    },
    {
      "epoch": 0.823961262105592,
      "grad_norm": 0.6459061503410339,
      "learning_rate": 1.7635114026866606e-05,
      "loss": 1.3609,
      "step": 5275
    },
    {
      "epoch": 0.8278662917838175,
      "grad_norm": 1.0762709379196167,
      "learning_rate": 1.724461105904405e-05,
      "loss": 1.3533,
      "step": 5300
    },
    {
      "epoch": 0.8317713214620431,
      "grad_norm": 0.7176532745361328,
      "learning_rate": 1.6854108091221495e-05,
      "loss": 1.3706,
      "step": 5325
    },
    {
      "epoch": 0.8356763511402686,
      "grad_norm": 0.5969240665435791,
      "learning_rate": 1.646360512339894e-05,
      "loss": 1.3502,
      "step": 5350
    },
    {
      "epoch": 0.8395813808184942,
      "grad_norm": 1.2499198913574219,
      "learning_rate": 1.6073102155576384e-05,
      "loss": 1.3945,
      "step": 5375
    },
    {
      "epoch": 0.8434864104967198,
      "grad_norm": 1.0046554803848267,
      "learning_rate": 1.5682599187753826e-05,
      "loss": 1.3865,
      "step": 5400
    },
    {
      "epoch": 0.8473914401749453,
      "grad_norm": 0.8475502729415894,
      "learning_rate": 1.5292096219931273e-05,
      "loss": 1.3422,
      "step": 5425
    },
    {
      "epoch": 0.8512964698531709,
      "grad_norm": 0.7740499973297119,
      "learning_rate": 1.4901593252108717e-05,
      "loss": 1.3658,
      "step": 5450
    },
    {
      "epoch": 0.8552014995313965,
      "grad_norm": 0.6897113919258118,
      "learning_rate": 1.4511090284286161e-05,
      "loss": 1.4183,
      "step": 5475
    },
    {
      "epoch": 0.8591065292096219,
      "grad_norm": 0.9905065298080444,
      "learning_rate": 1.4120587316463607e-05,
      "loss": 1.4006,
      "step": 5500
    },
    {
      "epoch": 0.8630115588878475,
      "grad_norm": 0.9326148629188538,
      "learning_rate": 1.373008434864105e-05,
      "loss": 1.3768,
      "step": 5525
    },
    {
      "epoch": 0.8669165885660731,
      "grad_norm": 0.9911114573478699,
      "learning_rate": 1.3339581380818495e-05,
      "loss": 1.3802,
      "step": 5550
    },
    {
      "epoch": 0.8708216182442987,
      "grad_norm": 0.8792577385902405,
      "learning_rate": 1.2949078412995937e-05,
      "loss": 1.3657,
      "step": 5575
    },
    {
      "epoch": 0.8747266479225242,
      "grad_norm": 0.9377418160438538,
      "learning_rate": 1.2558575445173385e-05,
      "loss": 1.403,
      "step": 5600
    },
    {
      "epoch": 0.8786316776007498,
      "grad_norm": 0.8017416000366211,
      "learning_rate": 1.2168072477350828e-05,
      "loss": 1.393,
      "step": 5625
    },
    {
      "epoch": 0.8825367072789754,
      "grad_norm": 1.0059235095977783,
      "learning_rate": 1.1777569509528272e-05,
      "loss": 1.4104,
      "step": 5650
    },
    {
      "epoch": 0.8864417369572009,
      "grad_norm": 1.076444149017334,
      "learning_rate": 1.1387066541705718e-05,
      "loss": 1.3198,
      "step": 5675
    },
    {
      "epoch": 0.8903467666354264,
      "grad_norm": 0.704603374004364,
      "learning_rate": 1.0996563573883161e-05,
      "loss": 1.3613,
      "step": 5700
    },
    {
      "epoch": 0.894251796313652,
      "grad_norm": 0.871275007724762,
      "learning_rate": 1.0606060606060607e-05,
      "loss": 1.4229,
      "step": 5725
    },
    {
      "epoch": 0.8981568259918775,
      "grad_norm": 0.9533642530441284,
      "learning_rate": 1.021555763823805e-05,
      "loss": 1.3813,
      "step": 5750
    },
    {
      "epoch": 0.9020618556701031,
      "grad_norm": 0.8125781416893005,
      "learning_rate": 9.825054670415496e-06,
      "loss": 1.3593,
      "step": 5775
    },
    {
      "epoch": 0.9059668853483287,
      "grad_norm": 0.9488340020179749,
      "learning_rate": 9.43455170259294e-06,
      "loss": 1.4035,
      "step": 5800
    },
    {
      "epoch": 0.9098719150265542,
      "grad_norm": 1.0244286060333252,
      "learning_rate": 9.044048734770385e-06,
      "loss": 1.4476,
      "step": 5825
    },
    {
      "epoch": 0.9137769447047798,
      "grad_norm": 1.080264925956726,
      "learning_rate": 8.65354576694783e-06,
      "loss": 1.3875,
      "step": 5850
    },
    {
      "epoch": 0.9176819743830054,
      "grad_norm": 0.7280665040016174,
      "learning_rate": 8.263042799125274e-06,
      "loss": 1.345,
      "step": 5875
    },
    {
      "epoch": 0.9215870040612308,
      "grad_norm": 1.1642413139343262,
      "learning_rate": 7.872539831302718e-06,
      "loss": 1.3896,
      "step": 5900
    },
    {
      "epoch": 0.9254920337394564,
      "grad_norm": 0.8003162145614624,
      "learning_rate": 7.482036863480163e-06,
      "loss": 1.4301,
      "step": 5925
    },
    {
      "epoch": 0.929397063417682,
      "grad_norm": 0.8878989219665527,
      "learning_rate": 7.091533895657608e-06,
      "loss": 1.4233,
      "step": 5950
    },
    {
      "epoch": 0.9333020930959075,
      "grad_norm": 0.9796596765518188,
      "learning_rate": 6.701030927835052e-06,
      "loss": 1.4054,
      "step": 5975
    },
    {
      "epoch": 0.9372071227741331,
      "grad_norm": 0.8371107578277588,
      "learning_rate": 6.310527960012497e-06,
      "loss": 1.3779,
      "step": 6000
    },
    {
      "epoch": 0.9372071227741331,
      "eval_loss": 1.363592267036438,
      "eval_runtime": 1622.5393,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 6000
    },
    {
      "epoch": 0.9411121524523587,
      "grad_norm": 0.7409505844116211,
      "learning_rate": 5.920024992189941e-06,
      "loss": 1.3465,
      "step": 6025
    },
    {
      "epoch": 0.9450171821305842,
      "grad_norm": 0.6240249872207642,
      "learning_rate": 5.529522024367386e-06,
      "loss": 1.3315,
      "step": 6050
    },
    {
      "epoch": 0.9489222118088098,
      "grad_norm": 1.0925991535186768,
      "learning_rate": 5.139019056544829e-06,
      "loss": 1.324,
      "step": 6075
    },
    {
      "epoch": 0.9528272414870353,
      "grad_norm": 1.1035056114196777,
      "learning_rate": 4.748516088722275e-06,
      "loss": 1.368,
      "step": 6100
    },
    {
      "epoch": 0.9567322711652608,
      "grad_norm": 0.9592011570930481,
      "learning_rate": 4.358013120899719e-06,
      "loss": 1.405,
      "step": 6125
    },
    {
      "epoch": 0.9606373008434864,
      "grad_norm": 0.5805858373641968,
      "learning_rate": 3.9675101530771634e-06,
      "loss": 1.3402,
      "step": 6150
    },
    {
      "epoch": 0.964542330521712,
      "grad_norm": 0.7619680762290955,
      "learning_rate": 3.577007185254608e-06,
      "loss": 1.3275,
      "step": 6175
    },
    {
      "epoch": 0.9684473601999375,
      "grad_norm": 1.3250622749328613,
      "learning_rate": 3.1865042174320527e-06,
      "loss": 1.3276,
      "step": 6200
    },
    {
      "epoch": 0.9723523898781631,
      "grad_norm": 1.0222915410995483,
      "learning_rate": 2.796001249609497e-06,
      "loss": 1.3892,
      "step": 6225
    },
    {
      "epoch": 0.9762574195563887,
      "grad_norm": 0.951147735118866,
      "learning_rate": 2.405498281786942e-06,
      "loss": 1.2972,
      "step": 6250
    },
    {
      "epoch": 0.9801624492346142,
      "grad_norm": 0.9171885251998901,
      "learning_rate": 2.014995313964386e-06,
      "loss": 1.3771,
      "step": 6275
    },
    {
      "epoch": 0.9840674789128397,
      "grad_norm": 1.0935049057006836,
      "learning_rate": 1.6244923461418308e-06,
      "loss": 1.3905,
      "step": 6300
    },
    {
      "epoch": 0.9879725085910653,
      "grad_norm": 1.0777339935302734,
      "learning_rate": 1.2339893783192753e-06,
      "loss": 1.4062,
      "step": 6325
    },
    {
      "epoch": 0.9918775382692908,
      "grad_norm": 0.636448860168457,
      "learning_rate": 8.434864104967199e-07,
      "loss": 1.3728,
      "step": 6350
    },
    {
      "epoch": 0.9957825679475164,
      "grad_norm": 0.7165525555610657,
      "learning_rate": 4.529834426741643e-07,
      "loss": 1.3978,
      "step": 6375
    },
    {
      "epoch": 0.999687597625742,
      "grad_norm": 1.1730161905288696,
      "learning_rate": 6.248047485160887e-08,
      "loss": 1.3962,
      "step": 6400
    }
  ],
  "logging_steps": 25,
  "max_steps": 6402,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.586451820957573e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
