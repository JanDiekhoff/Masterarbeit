{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 1000,
  "global_step": 12804,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0039050296782255547,
      "grad_norm": 0.9788556098937988,
      "learning_rate": 9.960949703217745e-05,
      "loss": 2.0441,
      "step": 25
    },
    {
      "epoch": 0.007810059356451109,
      "grad_norm": 1.4186716079711914,
      "learning_rate": 9.92189940643549e-05,
      "loss": 1.6476,
      "step": 50
    },
    {
      "epoch": 0.011715089034676664,
      "grad_norm": 1.530958652496338,
      "learning_rate": 9.882849109653233e-05,
      "loss": 1.6357,
      "step": 75
    },
    {
      "epoch": 0.015620118712902219,
      "grad_norm": 1.1300246715545654,
      "learning_rate": 9.843798812870978e-05,
      "loss": 1.5908,
      "step": 100
    },
    {
      "epoch": 0.01952514839112777,
      "grad_norm": 1.1624640226364136,
      "learning_rate": 9.804748516088723e-05,
      "loss": 1.5148,
      "step": 125
    },
    {
      "epoch": 0.023430178069353328,
      "grad_norm": 1.275742530822754,
      "learning_rate": 9.765698219306467e-05,
      "loss": 1.5328,
      "step": 150
    },
    {
      "epoch": 0.02733520774757888,
      "grad_norm": 0.8366349935531616,
      "learning_rate": 9.726647922524212e-05,
      "loss": 1.533,
      "step": 175
    },
    {
      "epoch": 0.031240237425804437,
      "grad_norm": 1.1947709321975708,
      "learning_rate": 9.687597625741956e-05,
      "loss": 1.4323,
      "step": 200
    },
    {
      "epoch": 0.035145267104029994,
      "grad_norm": 0.9227701425552368,
      "learning_rate": 9.6485473289597e-05,
      "loss": 1.4247,
      "step": 225
    },
    {
      "epoch": 0.03905029678225554,
      "grad_norm": 1.4063547849655151,
      "learning_rate": 9.609497032177445e-05,
      "loss": 1.4529,
      "step": 250
    },
    {
      "epoch": 0.0429553264604811,
      "grad_norm": 1.2065435647964478,
      "learning_rate": 9.57044673539519e-05,
      "loss": 1.441,
      "step": 275
    },
    {
      "epoch": 0.046860356138706656,
      "grad_norm": 0.971281111240387,
      "learning_rate": 9.531396438612934e-05,
      "loss": 1.4531,
      "step": 300
    },
    {
      "epoch": 0.050765385816932206,
      "grad_norm": 0.9510043859481812,
      "learning_rate": 9.492346141830677e-05,
      "loss": 1.5193,
      "step": 325
    },
    {
      "epoch": 0.05467041549515776,
      "grad_norm": 1.0490731000900269,
      "learning_rate": 9.453295845048423e-05,
      "loss": 1.4733,
      "step": 350
    },
    {
      "epoch": 0.05857544517338332,
      "grad_norm": 1.1532464027404785,
      "learning_rate": 9.414245548266167e-05,
      "loss": 1.427,
      "step": 375
    },
    {
      "epoch": 0.062480474851608875,
      "grad_norm": 0.6971469521522522,
      "learning_rate": 9.375195251483912e-05,
      "loss": 1.4548,
      "step": 400
    },
    {
      "epoch": 0.06638550452983442,
      "grad_norm": 0.9145767092704773,
      "learning_rate": 9.336144954701657e-05,
      "loss": 1.4817,
      "step": 425
    },
    {
      "epoch": 0.07029053420805999,
      "grad_norm": 0.8630960583686829,
      "learning_rate": 9.2970946579194e-05,
      "loss": 1.4269,
      "step": 450
    },
    {
      "epoch": 0.07419556388628554,
      "grad_norm": 1.035193681716919,
      "learning_rate": 9.258044361137144e-05,
      "loss": 1.4544,
      "step": 475
    },
    {
      "epoch": 0.07810059356451109,
      "grad_norm": 1.4784947633743286,
      "learning_rate": 9.21899406435489e-05,
      "loss": 1.4585,
      "step": 500
    },
    {
      "epoch": 0.08200562324273665,
      "grad_norm": 0.8094277381896973,
      "learning_rate": 9.179943767572634e-05,
      "loss": 1.446,
      "step": 525
    },
    {
      "epoch": 0.0859106529209622,
      "grad_norm": 1.0660157203674316,
      "learning_rate": 9.140893470790379e-05,
      "loss": 1.4338,
      "step": 550
    },
    {
      "epoch": 0.08981568259918775,
      "grad_norm": 1.007818341255188,
      "learning_rate": 9.101843174008123e-05,
      "loss": 1.4244,
      "step": 575
    },
    {
      "epoch": 0.09372071227741331,
      "grad_norm": 0.8388475179672241,
      "learning_rate": 9.062792877225867e-05,
      "loss": 1.4219,
      "step": 600
    },
    {
      "epoch": 0.09762574195563886,
      "grad_norm": 0.9769904017448425,
      "learning_rate": 9.023742580443611e-05,
      "loss": 1.4356,
      "step": 625
    },
    {
      "epoch": 0.10153077163386441,
      "grad_norm": 1.0306223630905151,
      "learning_rate": 8.984692283661357e-05,
      "loss": 1.4269,
      "step": 650
    },
    {
      "epoch": 0.10543580131208997,
      "grad_norm": 0.9314174652099609,
      "learning_rate": 8.945641986879101e-05,
      "loss": 1.4484,
      "step": 675
    },
    {
      "epoch": 0.10934083099031552,
      "grad_norm": 1.0374778509140015,
      "learning_rate": 8.906591690096846e-05,
      "loss": 1.4284,
      "step": 700
    },
    {
      "epoch": 0.11324586066854109,
      "grad_norm": 0.9628512263298035,
      "learning_rate": 8.86754139331459e-05,
      "loss": 1.4641,
      "step": 725
    },
    {
      "epoch": 0.11715089034676664,
      "grad_norm": 0.7893606424331665,
      "learning_rate": 8.828491096532334e-05,
      "loss": 1.4292,
      "step": 750
    },
    {
      "epoch": 0.12105592002499219,
      "grad_norm": 0.8745779395103455,
      "learning_rate": 8.789440799750078e-05,
      "loss": 1.445,
      "step": 775
    },
    {
      "epoch": 0.12496094970321775,
      "grad_norm": 0.6995758414268494,
      "learning_rate": 8.750390502967824e-05,
      "loss": 1.4392,
      "step": 800
    },
    {
      "epoch": 0.12886597938144329,
      "grad_norm": 0.9901021718978882,
      "learning_rate": 8.711340206185567e-05,
      "loss": 1.4432,
      "step": 825
    },
    {
      "epoch": 0.13277100905966885,
      "grad_norm": 0.7265489101409912,
      "learning_rate": 8.672289909403311e-05,
      "loss": 1.4313,
      "step": 850
    },
    {
      "epoch": 0.1366760387378944,
      "grad_norm": 0.737176775932312,
      "learning_rate": 8.633239612621057e-05,
      "loss": 1.4521,
      "step": 875
    },
    {
      "epoch": 0.14058106841611998,
      "grad_norm": 0.9069027900695801,
      "learning_rate": 8.594189315838801e-05,
      "loss": 1.3692,
      "step": 900
    },
    {
      "epoch": 0.1444860980943455,
      "grad_norm": 0.8256837129592896,
      "learning_rate": 8.555139019056545e-05,
      "loss": 1.3786,
      "step": 925
    },
    {
      "epoch": 0.14839112777257107,
      "grad_norm": 0.9153324365615845,
      "learning_rate": 8.51608872227429e-05,
      "loss": 1.3139,
      "step": 950
    },
    {
      "epoch": 0.15229615745079664,
      "grad_norm": 1.0537070035934448,
      "learning_rate": 8.477038425492034e-05,
      "loss": 1.4855,
      "step": 975
    },
    {
      "epoch": 0.15620118712902217,
      "grad_norm": 0.9281678795814514,
      "learning_rate": 8.437988128709778e-05,
      "loss": 1.3694,
      "step": 1000
    },
    {
      "epoch": 0.15620118712902217,
      "eval_loss": 1.4100061655044556,
      "eval_runtime": 1622.8745,
      "eval_samples_per_second": 6.312,
      "eval_steps_per_second": 6.312,
      "step": 1000
    },
    {
      "epoch": 0.16010621680724774,
      "grad_norm": 0.8348686099052429,
      "learning_rate": 8.398937831927524e-05,
      "loss": 1.4679,
      "step": 1025
    },
    {
      "epoch": 0.1640112464854733,
      "grad_norm": 0.857980489730835,
      "learning_rate": 8.359887535145268e-05,
      "loss": 1.4241,
      "step": 1050
    },
    {
      "epoch": 0.16791627616369884,
      "grad_norm": 1.0315102338790894,
      "learning_rate": 8.320837238363012e-05,
      "loss": 1.4206,
      "step": 1075
    },
    {
      "epoch": 0.1718213058419244,
      "grad_norm": 0.8269699811935425,
      "learning_rate": 8.281786941580757e-05,
      "loss": 1.4232,
      "step": 1100
    },
    {
      "epoch": 0.17572633552014996,
      "grad_norm": 0.7871904373168945,
      "learning_rate": 8.242736644798501e-05,
      "loss": 1.4577,
      "step": 1125
    },
    {
      "epoch": 0.1796313651983755,
      "grad_norm": 0.9099403619766235,
      "learning_rate": 8.203686348016245e-05,
      "loss": 1.4107,
      "step": 1150
    },
    {
      "epoch": 0.18353639487660106,
      "grad_norm": 0.9328250288963318,
      "learning_rate": 8.16463605123399e-05,
      "loss": 1.4,
      "step": 1175
    },
    {
      "epoch": 0.18744142455482662,
      "grad_norm": 0.8486063480377197,
      "learning_rate": 8.125585754451735e-05,
      "loss": 1.452,
      "step": 1200
    },
    {
      "epoch": 0.19134645423305216,
      "grad_norm": 1.0273486375808716,
      "learning_rate": 8.086535457669478e-05,
      "loss": 1.466,
      "step": 1225
    },
    {
      "epoch": 0.19525148391127772,
      "grad_norm": 0.7445910573005676,
      "learning_rate": 8.047485160887222e-05,
      "loss": 1.4502,
      "step": 1250
    },
    {
      "epoch": 0.1991565135895033,
      "grad_norm": 1.0248730182647705,
      "learning_rate": 8.008434864104968e-05,
      "loss": 1.422,
      "step": 1275
    },
    {
      "epoch": 0.20306154326772882,
      "grad_norm": 0.9922653436660767,
      "learning_rate": 7.969384567322712e-05,
      "loss": 1.3643,
      "step": 1300
    },
    {
      "epoch": 0.20696657294595439,
      "grad_norm": 0.7457150816917419,
      "learning_rate": 7.930334270540456e-05,
      "loss": 1.4058,
      "step": 1325
    },
    {
      "epoch": 0.21087160262417995,
      "grad_norm": 0.7834466099739075,
      "learning_rate": 7.891283973758201e-05,
      "loss": 1.4087,
      "step": 1350
    },
    {
      "epoch": 0.21477663230240548,
      "grad_norm": 0.7649375200271606,
      "learning_rate": 7.852233676975945e-05,
      "loss": 1.4305,
      "step": 1375
    },
    {
      "epoch": 0.21868166198063105,
      "grad_norm": 1.2048529386520386,
      "learning_rate": 7.813183380193689e-05,
      "loss": 1.3963,
      "step": 1400
    },
    {
      "epoch": 0.2225866916588566,
      "grad_norm": 0.9572616815567017,
      "learning_rate": 7.774133083411435e-05,
      "loss": 1.3733,
      "step": 1425
    },
    {
      "epoch": 0.22649172133708217,
      "grad_norm": 0.8934391736984253,
      "learning_rate": 7.735082786629179e-05,
      "loss": 1.4179,
      "step": 1450
    },
    {
      "epoch": 0.2303967510153077,
      "grad_norm": 0.9330870509147644,
      "learning_rate": 7.696032489846922e-05,
      "loss": 1.3873,
      "step": 1475
    },
    {
      "epoch": 0.23430178069353327,
      "grad_norm": 0.8023552894592285,
      "learning_rate": 7.656982193064668e-05,
      "loss": 1.382,
      "step": 1500
    },
    {
      "epoch": 0.23820681037175884,
      "grad_norm": 1.0145927667617798,
      "learning_rate": 7.617931896282412e-05,
      "loss": 1.4593,
      "step": 1525
    },
    {
      "epoch": 0.24211184004998437,
      "grad_norm": 1.0062764883041382,
      "learning_rate": 7.578881599500156e-05,
      "loss": 1.4308,
      "step": 1550
    },
    {
      "epoch": 0.24601686972820994,
      "grad_norm": 0.8741281628608704,
      "learning_rate": 7.539831302717902e-05,
      "loss": 1.4212,
      "step": 1575
    },
    {
      "epoch": 0.2499218994064355,
      "grad_norm": 0.9855102300643921,
      "learning_rate": 7.500781005935645e-05,
      "loss": 1.4128,
      "step": 1600
    },
    {
      "epoch": 0.25382692908466103,
      "grad_norm": 0.8172687292098999,
      "learning_rate": 7.461730709153389e-05,
      "loss": 1.4174,
      "step": 1625
    },
    {
      "epoch": 0.25773195876288657,
      "grad_norm": 1.1485220193862915,
      "learning_rate": 7.422680412371135e-05,
      "loss": 1.4511,
      "step": 1650
    },
    {
      "epoch": 0.26163698844111216,
      "grad_norm": 1.2781294584274292,
      "learning_rate": 7.383630115588879e-05,
      "loss": 1.4094,
      "step": 1675
    },
    {
      "epoch": 0.2655420181193377,
      "grad_norm": 0.8155423998832703,
      "learning_rate": 7.344579818806623e-05,
      "loss": 1.3896,
      "step": 1700
    },
    {
      "epoch": 0.2694470477975633,
      "grad_norm": 1.19487464427948,
      "learning_rate": 7.305529522024368e-05,
      "loss": 1.3922,
      "step": 1725
    },
    {
      "epoch": 0.2733520774757888,
      "grad_norm": 0.8717193007469177,
      "learning_rate": 7.266479225242112e-05,
      "loss": 1.3826,
      "step": 1750
    },
    {
      "epoch": 0.27725710715401436,
      "grad_norm": 0.815072238445282,
      "learning_rate": 7.227428928459856e-05,
      "loss": 1.3427,
      "step": 1775
    },
    {
      "epoch": 0.28116213683223995,
      "grad_norm": 0.7282699346542358,
      "learning_rate": 7.188378631677602e-05,
      "loss": 1.4233,
      "step": 1800
    },
    {
      "epoch": 0.2850671665104655,
      "grad_norm": 0.8836639523506165,
      "learning_rate": 7.149328334895346e-05,
      "loss": 1.4416,
      "step": 1825
    },
    {
      "epoch": 0.288972196188691,
      "grad_norm": 1.1085466146469116,
      "learning_rate": 7.110278038113089e-05,
      "loss": 1.297,
      "step": 1850
    },
    {
      "epoch": 0.2928772258669166,
      "grad_norm": 0.8943423628807068,
      "learning_rate": 7.071227741330835e-05,
      "loss": 1.3439,
      "step": 1875
    },
    {
      "epoch": 0.29678225554514215,
      "grad_norm": 0.7290465831756592,
      "learning_rate": 7.032177444548579e-05,
      "loss": 1.3455,
      "step": 1900
    },
    {
      "epoch": 0.3006872852233677,
      "grad_norm": 1.0493628978729248,
      "learning_rate": 6.993127147766323e-05,
      "loss": 1.3515,
      "step": 1925
    },
    {
      "epoch": 0.3045923149015933,
      "grad_norm": 0.9758964776992798,
      "learning_rate": 6.954076850984069e-05,
      "loss": 1.3877,
      "step": 1950
    },
    {
      "epoch": 0.3084973445798188,
      "grad_norm": 0.8183075189590454,
      "learning_rate": 6.915026554201812e-05,
      "loss": 1.4081,
      "step": 1975
    },
    {
      "epoch": 0.31240237425804435,
      "grad_norm": 1.2012001276016235,
      "learning_rate": 6.875976257419556e-05,
      "loss": 1.3826,
      "step": 2000
    },
    {
      "epoch": 0.31240237425804435,
      "eval_loss": 1.3891282081604004,
      "eval_runtime": 1622.8317,
      "eval_samples_per_second": 6.312,
      "eval_steps_per_second": 6.312,
      "step": 2000
    },
    {
      "epoch": 0.31630740393626994,
      "grad_norm": 0.778975248336792,
      "learning_rate": 6.836925960637302e-05,
      "loss": 1.3761,
      "step": 2025
    },
    {
      "epoch": 0.3202124336144955,
      "grad_norm": 0.747718095779419,
      "learning_rate": 6.797875663855046e-05,
      "loss": 1.4318,
      "step": 2050
    },
    {
      "epoch": 0.324117463292721,
      "grad_norm": 0.9056251049041748,
      "learning_rate": 6.75882536707279e-05,
      "loss": 1.3882,
      "step": 2075
    },
    {
      "epoch": 0.3280224929709466,
      "grad_norm": 0.9129356741905212,
      "learning_rate": 6.719775070290534e-05,
      "loss": 1.4031,
      "step": 2100
    },
    {
      "epoch": 0.33192752264917214,
      "grad_norm": 0.667236328125,
      "learning_rate": 6.680724773508279e-05,
      "loss": 1.3969,
      "step": 2125
    },
    {
      "epoch": 0.33583255232739767,
      "grad_norm": 0.9704068303108215,
      "learning_rate": 6.641674476726023e-05,
      "loss": 1.3397,
      "step": 2150
    },
    {
      "epoch": 0.33973758200562326,
      "grad_norm": 1.06690514087677,
      "learning_rate": 6.602624179943769e-05,
      "loss": 1.4212,
      "step": 2175
    },
    {
      "epoch": 0.3436426116838488,
      "grad_norm": 0.8432579040527344,
      "learning_rate": 6.563573883161513e-05,
      "loss": 1.4374,
      "step": 2200
    },
    {
      "epoch": 0.34754764136207433,
      "grad_norm": 1.0442194938659668,
      "learning_rate": 6.524523586379257e-05,
      "loss": 1.373,
      "step": 2225
    },
    {
      "epoch": 0.3514526710402999,
      "grad_norm": 0.9351023435592651,
      "learning_rate": 6.487035301468292e-05,
      "loss": 1.4182,
      "step": 2250
    },
    {
      "epoch": 0.35535770071852546,
      "grad_norm": 0.9344373941421509,
      "learning_rate": 6.447985004686035e-05,
      "loss": 1.3841,
      "step": 2275
    },
    {
      "epoch": 0.359262730396751,
      "grad_norm": 0.9935104846954346,
      "learning_rate": 6.408934707903781e-05,
      "loss": 1.4326,
      "step": 2300
    },
    {
      "epoch": 0.3631677600749766,
      "grad_norm": 0.7968645095825195,
      "learning_rate": 6.369884411121525e-05,
      "loss": 1.3949,
      "step": 2325
    },
    {
      "epoch": 0.3670727897532021,
      "grad_norm": 0.7839841842651367,
      "learning_rate": 6.33083411433927e-05,
      "loss": 1.3706,
      "step": 2350
    },
    {
      "epoch": 0.37097781943142766,
      "grad_norm": 0.8733723759651184,
      "learning_rate": 6.291783817557014e-05,
      "loss": 1.4319,
      "step": 2375
    },
    {
      "epoch": 0.37488284910965325,
      "grad_norm": 1.784317970275879,
      "learning_rate": 6.252733520774758e-05,
      "loss": 1.3913,
      "step": 2400
    },
    {
      "epoch": 0.3787878787878788,
      "grad_norm": 1.04975163936615,
      "learning_rate": 6.213683223992502e-05,
      "loss": 1.4579,
      "step": 2425
    },
    {
      "epoch": 0.3826929084661043,
      "grad_norm": 1.2106798887252808,
      "learning_rate": 6.174632927210246e-05,
      "loss": 1.4207,
      "step": 2450
    },
    {
      "epoch": 0.3865979381443299,
      "grad_norm": 0.9787081480026245,
      "learning_rate": 6.135582630427992e-05,
      "loss": 1.3287,
      "step": 2475
    },
    {
      "epoch": 0.39050296782255545,
      "grad_norm": 0.755710244178772,
      "learning_rate": 6.096532333645736e-05,
      "loss": 1.4122,
      "step": 2500
    },
    {
      "epoch": 0.394407997500781,
      "grad_norm": 0.8430375456809998,
      "learning_rate": 6.05748203686348e-05,
      "loss": 1.4425,
      "step": 2525
    },
    {
      "epoch": 0.3983130271790066,
      "grad_norm": 0.8444249033927917,
      "learning_rate": 6.018431740081225e-05,
      "loss": 1.3714,
      "step": 2550
    },
    {
      "epoch": 0.4022180568572321,
      "grad_norm": 0.9024614095687866,
      "learning_rate": 5.979381443298969e-05,
      "loss": 1.3792,
      "step": 2575
    },
    {
      "epoch": 0.40612308653545764,
      "grad_norm": 0.9260613322257996,
      "learning_rate": 5.9403311465167135e-05,
      "loss": 1.3415,
      "step": 2600
    },
    {
      "epoch": 0.41002811621368324,
      "grad_norm": 0.7240073084831238,
      "learning_rate": 5.9012808497344584e-05,
      "loss": 1.3284,
      "step": 2625
    },
    {
      "epoch": 0.41393314589190877,
      "grad_norm": 0.7593271732330322,
      "learning_rate": 5.862230552952203e-05,
      "loss": 1.42,
      "step": 2650
    },
    {
      "epoch": 0.4178381755701343,
      "grad_norm": 0.9628000855445862,
      "learning_rate": 5.823180256169947e-05,
      "loss": 1.3598,
      "step": 2675
    },
    {
      "epoch": 0.4217432052483599,
      "grad_norm": 0.6669929623603821,
      "learning_rate": 5.784129959387692e-05,
      "loss": 1.3691,
      "step": 2700
    },
    {
      "epoch": 0.42564823492658543,
      "grad_norm": 0.8762942552566528,
      "learning_rate": 5.745079662605436e-05,
      "loss": 1.4063,
      "step": 2725
    },
    {
      "epoch": 0.42955326460481097,
      "grad_norm": 0.772219717502594,
      "learning_rate": 5.70602936582318e-05,
      "loss": 1.4078,
      "step": 2750
    },
    {
      "epoch": 0.43345829428303656,
      "grad_norm": 1.0171741247177124,
      "learning_rate": 5.6669790690409254e-05,
      "loss": 1.38,
      "step": 2775
    },
    {
      "epoch": 0.4373633239612621,
      "grad_norm": 0.765740156173706,
      "learning_rate": 5.627928772258669e-05,
      "loss": 1.4231,
      "step": 2800
    },
    {
      "epoch": 0.4412683536394877,
      "grad_norm": 0.8746947050094604,
      "learning_rate": 5.588878475476413e-05,
      "loss": 1.371,
      "step": 2825
    },
    {
      "epoch": 0.4451733833177132,
      "grad_norm": 0.7496356964111328,
      "learning_rate": 5.549828178694159e-05,
      "loss": 1.3442,
      "step": 2850
    },
    {
      "epoch": 0.44907841299593876,
      "grad_norm": 0.7783387899398804,
      "learning_rate": 5.5107778819119025e-05,
      "loss": 1.4312,
      "step": 2875
    },
    {
      "epoch": 0.45298344267416435,
      "grad_norm": 0.889725387096405,
      "learning_rate": 5.471727585129647e-05,
      "loss": 1.399,
      "step": 2900
    },
    {
      "epoch": 0.4568884723523899,
      "grad_norm": 1.023020625114441,
      "learning_rate": 5.432677288347392e-05,
      "loss": 1.3657,
      "step": 2925
    },
    {
      "epoch": 0.4607935020306154,
      "grad_norm": 0.9599210023880005,
      "learning_rate": 5.393626991565136e-05,
      "loss": 1.4014,
      "step": 2950
    },
    {
      "epoch": 0.464698531708841,
      "grad_norm": 1.1952301263809204,
      "learning_rate": 5.35457669478288e-05,
      "loss": 1.3319,
      "step": 2975
    },
    {
      "epoch": 0.46860356138706655,
      "grad_norm": 0.8350117802619934,
      "learning_rate": 5.315526398000625e-05,
      "loss": 1.3746,
      "step": 3000
    },
    {
      "epoch": 0.46860356138706655,
      "eval_loss": 1.379629135131836,
      "eval_runtime": 1622.5807,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 3000
    },
    {
      "epoch": 0.4725085910652921,
      "grad_norm": 0.7739664316177368,
      "learning_rate": 5.2764761012183695e-05,
      "loss": 1.4085,
      "step": 3025
    },
    {
      "epoch": 0.4764136207435177,
      "grad_norm": 0.781043529510498,
      "learning_rate": 5.237425804436114e-05,
      "loss": 1.3533,
      "step": 3050
    },
    {
      "epoch": 0.4803186504217432,
      "grad_norm": 0.6492843627929688,
      "learning_rate": 5.198375507653859e-05,
      "loss": 1.4445,
      "step": 3075
    },
    {
      "epoch": 0.48422368009996875,
      "grad_norm": 0.7984755635261536,
      "learning_rate": 5.159325210871603e-05,
      "loss": 1.3689,
      "step": 3100
    },
    {
      "epoch": 0.48812870977819434,
      "grad_norm": 0.7521188855171204,
      "learning_rate": 5.1202749140893466e-05,
      "loss": 1.4317,
      "step": 3125
    },
    {
      "epoch": 0.49203373945641987,
      "grad_norm": 0.7364665865898132,
      "learning_rate": 5.081224617307092e-05,
      "loss": 1.3606,
      "step": 3150
    },
    {
      "epoch": 0.4959387691346454,
      "grad_norm": 0.987529993057251,
      "learning_rate": 5.0421743205248365e-05,
      "loss": 1.3917,
      "step": 3175
    },
    {
      "epoch": 0.499843798812871,
      "grad_norm": 0.8404374718666077,
      "learning_rate": 5.00312402374258e-05,
      "loss": 1.3419,
      "step": 3200
    },
    {
      "epoch": 0.5037488284910965,
      "grad_norm": 1.2168902158737183,
      "learning_rate": 4.964073726960325e-05,
      "loss": 1.4761,
      "step": 3225
    },
    {
      "epoch": 0.5076538581693221,
      "grad_norm": 1.087868332862854,
      "learning_rate": 4.925023430178069e-05,
      "loss": 1.348,
      "step": 3250
    },
    {
      "epoch": 0.5115588878475477,
      "grad_norm": 1.0057283639907837,
      "learning_rate": 4.885973133395814e-05,
      "loss": 1.389,
      "step": 3275
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 0.9449900388717651,
      "learning_rate": 4.8469228366135585e-05,
      "loss": 1.3524,
      "step": 3300
    },
    {
      "epoch": 0.5193689472039987,
      "grad_norm": 0.8599697351455688,
      "learning_rate": 4.807872539831303e-05,
      "loss": 1.4186,
      "step": 3325
    },
    {
      "epoch": 0.5232739768822243,
      "grad_norm": 0.9135838150978088,
      "learning_rate": 4.768822243049048e-05,
      "loss": 1.3734,
      "step": 3350
    },
    {
      "epoch": 0.5271790065604499,
      "grad_norm": 0.7260757088661194,
      "learning_rate": 4.7297719462667913e-05,
      "loss": 1.37,
      "step": 3375
    },
    {
      "epoch": 0.5310840362386754,
      "grad_norm": 0.8324730396270752,
      "learning_rate": 4.690721649484536e-05,
      "loss": 1.3938,
      "step": 3400
    },
    {
      "epoch": 0.534989065916901,
      "grad_norm": 1.1432992219924927,
      "learning_rate": 4.651671352702281e-05,
      "loss": 1.3877,
      "step": 3425
    },
    {
      "epoch": 0.5388940955951266,
      "grad_norm": 0.7782467603683472,
      "learning_rate": 4.612621055920025e-05,
      "loss": 1.3456,
      "step": 3450
    },
    {
      "epoch": 0.5427991252733521,
      "grad_norm": 0.727100670337677,
      "learning_rate": 4.57357075913777e-05,
      "loss": 1.4395,
      "step": 3475
    },
    {
      "epoch": 0.5467041549515776,
      "grad_norm": 0.8211419582366943,
      "learning_rate": 4.534520462355514e-05,
      "loss": 1.412,
      "step": 3500
    },
    {
      "epoch": 0.5506091846298032,
      "grad_norm": 0.6755484342575073,
      "learning_rate": 4.495470165573258e-05,
      "loss": 1.4133,
      "step": 3525
    },
    {
      "epoch": 0.5545142143080287,
      "grad_norm": 0.8624936938285828,
      "learning_rate": 4.456419868791003e-05,
      "loss": 1.4284,
      "step": 3550
    },
    {
      "epoch": 0.5584192439862543,
      "grad_norm": 0.9535272121429443,
      "learning_rate": 4.4173695720087476e-05,
      "loss": 1.4182,
      "step": 3575
    },
    {
      "epoch": 0.5623242736644799,
      "grad_norm": 0.8995130062103271,
      "learning_rate": 4.378319275226492e-05,
      "loss": 1.3576,
      "step": 3600
    },
    {
      "epoch": 0.5662293033427054,
      "grad_norm": 0.8603726029396057,
      "learning_rate": 4.339268978444236e-05,
      "loss": 1.3846,
      "step": 3625
    },
    {
      "epoch": 0.570134333020931,
      "grad_norm": 0.7719624042510986,
      "learning_rate": 4.300218681661981e-05,
      "loss": 1.4535,
      "step": 3650
    },
    {
      "epoch": 0.5740393626991566,
      "grad_norm": 0.9310029745101929,
      "learning_rate": 4.261168384879725e-05,
      "loss": 1.3824,
      "step": 3675
    },
    {
      "epoch": 0.577944392377382,
      "grad_norm": 1.049993634223938,
      "learning_rate": 4.2221180880974696e-05,
      "loss": 1.3819,
      "step": 3700
    },
    {
      "epoch": 0.5818494220556076,
      "grad_norm": 0.80288165807724,
      "learning_rate": 4.1830677913152146e-05,
      "loss": 1.3687,
      "step": 3725
    },
    {
      "epoch": 0.5857544517338332,
      "grad_norm": 0.8904058933258057,
      "learning_rate": 4.144017494532959e-05,
      "loss": 1.3472,
      "step": 3750
    },
    {
      "epoch": 0.5896594814120587,
      "grad_norm": 0.9186760783195496,
      "learning_rate": 4.104967197750703e-05,
      "loss": 1.3894,
      "step": 3775
    },
    {
      "epoch": 0.5935645110902843,
      "grad_norm": 0.8003730177879333,
      "learning_rate": 4.065916900968448e-05,
      "loss": 1.3594,
      "step": 3800
    },
    {
      "epoch": 0.5974695407685099,
      "grad_norm": 0.7443795204162598,
      "learning_rate": 4.0268666041861916e-05,
      "loss": 1.4191,
      "step": 3825
    },
    {
      "epoch": 0.6013745704467354,
      "grad_norm": 0.8892534375190735,
      "learning_rate": 3.9878163074039366e-05,
      "loss": 1.3938,
      "step": 3850
    },
    {
      "epoch": 0.605279600124961,
      "grad_norm": 0.7992183566093445,
      "learning_rate": 3.948766010621681e-05,
      "loss": 1.3595,
      "step": 3875
    },
    {
      "epoch": 0.6091846298031866,
      "grad_norm": 0.8434757590293884,
      "learning_rate": 3.909715713839425e-05,
      "loss": 1.4179,
      "step": 3900
    },
    {
      "epoch": 0.613089659481412,
      "grad_norm": 0.8580999374389648,
      "learning_rate": 3.87066541705717e-05,
      "loss": 1.3749,
      "step": 3925
    },
    {
      "epoch": 0.6169946891596376,
      "grad_norm": 0.8498902320861816,
      "learning_rate": 3.8316151202749144e-05,
      "loss": 1.358,
      "step": 3950
    },
    {
      "epoch": 0.6208997188378632,
      "grad_norm": 0.713224470615387,
      "learning_rate": 3.7925648234926586e-05,
      "loss": 1.3435,
      "step": 3975
    },
    {
      "epoch": 0.6248047485160887,
      "grad_norm": 1.0151127576828003,
      "learning_rate": 3.7535145267104036e-05,
      "loss": 1.4189,
      "step": 4000
    },
    {
      "epoch": 0.6248047485160887,
      "eval_loss": 1.3731718063354492,
      "eval_runtime": 1622.5739,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 4000
    },
    {
      "epoch": 0.6287097781943143,
      "grad_norm": 0.7106295824050903,
      "learning_rate": 3.714464229928147e-05,
      "loss": 1.3811,
      "step": 4025
    },
    {
      "epoch": 0.6326148078725399,
      "grad_norm": 0.892025351524353,
      "learning_rate": 3.675413933145892e-05,
      "loss": 1.3305,
      "step": 4050
    },
    {
      "epoch": 0.6365198375507654,
      "grad_norm": 0.7329587340354919,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.354,
      "step": 4075
    },
    {
      "epoch": 0.640424867228991,
      "grad_norm": 0.6800800561904907,
      "learning_rate": 3.597313339581381e-05,
      "loss": 1.3906,
      "step": 4100
    },
    {
      "epoch": 0.6443298969072165,
      "grad_norm": 1.3265095949172974,
      "learning_rate": 3.5582630427991256e-05,
      "loss": 1.4372,
      "step": 4125
    },
    {
      "epoch": 0.648234926585442,
      "grad_norm": 0.9539549946784973,
      "learning_rate": 3.51921274601687e-05,
      "loss": 1.3551,
      "step": 4150
    },
    {
      "epoch": 0.6521399562636676,
      "grad_norm": 0.9606791138648987,
      "learning_rate": 3.480162449234614e-05,
      "loss": 1.3093,
      "step": 4175
    },
    {
      "epoch": 0.6560449859418932,
      "grad_norm": 0.808586597442627,
      "learning_rate": 3.4411121524523585e-05,
      "loss": 1.3872,
      "step": 4200
    },
    {
      "epoch": 0.6599500156201187,
      "grad_norm": 0.9459164142608643,
      "learning_rate": 3.4020618556701034e-05,
      "loss": 1.4493,
      "step": 4225
    },
    {
      "epoch": 0.6638550452983443,
      "grad_norm": 0.7696070075035095,
      "learning_rate": 3.363011558887848e-05,
      "loss": 1.3404,
      "step": 4250
    },
    {
      "epoch": 0.6677600749765699,
      "grad_norm": 0.666983425617218,
      "learning_rate": 3.323961262105592e-05,
      "loss": 1.3437,
      "step": 4275
    },
    {
      "epoch": 0.6716651046547953,
      "grad_norm": 0.7108051776885986,
      "learning_rate": 3.284910965323337e-05,
      "loss": 1.3774,
      "step": 4300
    },
    {
      "epoch": 0.6755701343330209,
      "grad_norm": 0.9975783228874207,
      "learning_rate": 3.2474226804123714e-05,
      "loss": 1.382,
      "step": 4325
    },
    {
      "epoch": 0.6794751640112465,
      "grad_norm": 0.7070274949073792,
      "learning_rate": 3.208372383630116e-05,
      "loss": 1.4062,
      "step": 4350
    },
    {
      "epoch": 0.683380193689472,
      "grad_norm": 1.1871284246444702,
      "learning_rate": 3.16932208684786e-05,
      "loss": 1.3499,
      "step": 4375
    },
    {
      "epoch": 0.6872852233676976,
      "grad_norm": 0.8049858212471008,
      "learning_rate": 3.130271790065605e-05,
      "loss": 1.3882,
      "step": 4400
    },
    {
      "epoch": 0.6911902530459232,
      "grad_norm": 0.7419130206108093,
      "learning_rate": 3.091221493283349e-05,
      "loss": 1.3806,
      "step": 4425
    },
    {
      "epoch": 0.6950952827241487,
      "grad_norm": 0.7134928703308105,
      "learning_rate": 3.0521711965010935e-05,
      "loss": 1.389,
      "step": 4450
    },
    {
      "epoch": 0.6990003124023743,
      "grad_norm": 0.850683867931366,
      "learning_rate": 3.013120899718838e-05,
      "loss": 1.3574,
      "step": 4475
    },
    {
      "epoch": 0.7029053420805998,
      "grad_norm": 0.7843195796012878,
      "learning_rate": 2.9740706029365824e-05,
      "loss": 1.3615,
      "step": 4500
    },
    {
      "epoch": 0.7068103717588253,
      "grad_norm": 0.7871493101119995,
      "learning_rate": 2.935020306154327e-05,
      "loss": 1.2936,
      "step": 4525
    },
    {
      "epoch": 0.7107154014370509,
      "grad_norm": 1.0230937004089355,
      "learning_rate": 2.8959700093720716e-05,
      "loss": 1.3672,
      "step": 4550
    },
    {
      "epoch": 0.7146204311152765,
      "grad_norm": 0.901289165019989,
      "learning_rate": 2.8569197125898155e-05,
      "loss": 1.3627,
      "step": 4575
    },
    {
      "epoch": 0.718525460793502,
      "grad_norm": 0.9140220880508423,
      "learning_rate": 2.81786941580756e-05,
      "loss": 1.4286,
      "step": 4600
    },
    {
      "epoch": 0.7224304904717276,
      "grad_norm": 0.5817325711250305,
      "learning_rate": 2.7788191190253047e-05,
      "loss": 1.379,
      "step": 4625
    },
    {
      "epoch": 0.7263355201499532,
      "grad_norm": 0.7954283356666565,
      "learning_rate": 2.739768822243049e-05,
      "loss": 1.3527,
      "step": 4650
    },
    {
      "epoch": 0.7302405498281787,
      "grad_norm": 0.6346081495285034,
      "learning_rate": 2.7007185254607936e-05,
      "loss": 1.4137,
      "step": 4675
    },
    {
      "epoch": 0.7341455795064042,
      "grad_norm": 0.8675228357315063,
      "learning_rate": 2.6616682286785382e-05,
      "loss": 1.3248,
      "step": 4700
    },
    {
      "epoch": 0.7380506091846298,
      "grad_norm": 0.6280678510665894,
      "learning_rate": 2.6226179318962825e-05,
      "loss": 1.3556,
      "step": 4725
    },
    {
      "epoch": 0.7419556388628553,
      "grad_norm": 1.135744333267212,
      "learning_rate": 2.583567635114027e-05,
      "loss": 1.3373,
      "step": 4750
    },
    {
      "epoch": 0.7458606685410809,
      "grad_norm": 0.7343663573265076,
      "learning_rate": 2.5445173383317717e-05,
      "loss": 1.3954,
      "step": 4775
    },
    {
      "epoch": 0.7497656982193065,
      "grad_norm": 0.9837157130241394,
      "learning_rate": 2.5054670415495157e-05,
      "loss": 1.4088,
      "step": 4800
    },
    {
      "epoch": 0.753670727897532,
      "grad_norm": 0.9069740176200867,
      "learning_rate": 2.4664167447672603e-05,
      "loss": 1.3668,
      "step": 4825
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 0.9589853882789612,
      "learning_rate": 2.427366447985005e-05,
      "loss": 1.358,
      "step": 4850
    },
    {
      "epoch": 0.7614807872539832,
      "grad_norm": 0.803594708442688,
      "learning_rate": 2.3883161512027495e-05,
      "loss": 1.3844,
      "step": 4875
    },
    {
      "epoch": 0.7653858169322086,
      "grad_norm": 0.9047093987464905,
      "learning_rate": 2.3492658544204938e-05,
      "loss": 1.3675,
      "step": 4900
    },
    {
      "epoch": 0.7692908466104342,
      "grad_norm": 0.7741007208824158,
      "learning_rate": 2.310215557638238e-05,
      "loss": 1.363,
      "step": 4925
    },
    {
      "epoch": 0.7731958762886598,
      "grad_norm": 0.8362913131713867,
      "learning_rate": 2.2711652608559827e-05,
      "loss": 1.4205,
      "step": 4950
    },
    {
      "epoch": 0.7771009059668853,
      "grad_norm": 0.8468454480171204,
      "learning_rate": 2.232114964073727e-05,
      "loss": 1.3658,
      "step": 4975
    },
    {
      "epoch": 0.7810059356451109,
      "grad_norm": 0.735235333442688,
      "learning_rate": 2.1930646672914716e-05,
      "loss": 1.3646,
      "step": 5000
    },
    {
      "epoch": 0.7810059356451109,
      "eval_loss": 1.3693565130233765,
      "eval_runtime": 1622.4467,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 5000
    },
    {
      "epoch": 0.7849109653233365,
      "grad_norm": 0.9364868998527527,
      "learning_rate": 2.154014370509216e-05,
      "loss": 1.3967,
      "step": 5025
    },
    {
      "epoch": 0.788815995001562,
      "grad_norm": 0.6212465763092041,
      "learning_rate": 2.1149640737269604e-05,
      "loss": 1.3571,
      "step": 5050
    },
    {
      "epoch": 0.7927210246797876,
      "grad_norm": 0.7348495125770569,
      "learning_rate": 2.0759137769447047e-05,
      "loss": 1.3592,
      "step": 5075
    },
    {
      "epoch": 0.7966260543580131,
      "grad_norm": 0.9597716927528381,
      "learning_rate": 2.0368634801624493e-05,
      "loss": 1.4069,
      "step": 5100
    },
    {
      "epoch": 0.8005310840362386,
      "grad_norm": 0.6791498064994812,
      "learning_rate": 1.997813183380194e-05,
      "loss": 1.3155,
      "step": 5125
    },
    {
      "epoch": 0.8044361137144642,
      "grad_norm": 0.9482506513595581,
      "learning_rate": 1.9587628865979382e-05,
      "loss": 1.4001,
      "step": 5150
    },
    {
      "epoch": 0.8083411433926898,
      "grad_norm": 0.964714527130127,
      "learning_rate": 1.9197125898156825e-05,
      "loss": 1.4144,
      "step": 5175
    },
    {
      "epoch": 0.8122461730709153,
      "grad_norm": 0.8422079682350159,
      "learning_rate": 1.880662293033427e-05,
      "loss": 1.3789,
      "step": 5200
    },
    {
      "epoch": 0.8161512027491409,
      "grad_norm": 0.7407439947128296,
      "learning_rate": 1.8416119962511717e-05,
      "loss": 1.3958,
      "step": 5225
    },
    {
      "epoch": 0.8200562324273665,
      "grad_norm": 1.1520321369171143,
      "learning_rate": 1.802561699468916e-05,
      "loss": 1.4314,
      "step": 5250
    },
    {
      "epoch": 0.823961262105592,
      "grad_norm": 0.9952729344367981,
      "learning_rate": 1.7635114026866606e-05,
      "loss": 1.3489,
      "step": 5275
    },
    {
      "epoch": 0.8278662917838175,
      "grad_norm": 0.6066399812698364,
      "learning_rate": 1.724461105904405e-05,
      "loss": 1.3435,
      "step": 5300
    },
    {
      "epoch": 0.8317713214620431,
      "grad_norm": 0.7108361721038818,
      "learning_rate": 1.6854108091221495e-05,
      "loss": 1.3662,
      "step": 5325
    },
    {
      "epoch": 0.8356763511402686,
      "grad_norm": 0.8006077408790588,
      "learning_rate": 1.646360512339894e-05,
      "loss": 1.343,
      "step": 5350
    },
    {
      "epoch": 0.8395813808184942,
      "grad_norm": 0.9728885889053345,
      "learning_rate": 1.6073102155576384e-05,
      "loss": 1.3752,
      "step": 5375
    },
    {
      "epoch": 0.8434864104967198,
      "grad_norm": 0.7574647068977356,
      "learning_rate": 1.5682599187753826e-05,
      "loss": 1.3411,
      "step": 5400
    },
    {
      "epoch": 0.8473914401749453,
      "grad_norm": 0.8523254990577698,
      "learning_rate": 1.5292096219931273e-05,
      "loss": 1.3692,
      "step": 5425
    },
    {
      "epoch": 0.8512964698531709,
      "grad_norm": 0.8416500687599182,
      "learning_rate": 1.4901593252108717e-05,
      "loss": 1.3491,
      "step": 5450
    },
    {
      "epoch": 0.8552014995313965,
      "grad_norm": 0.823092520236969,
      "learning_rate": 1.4511090284286161e-05,
      "loss": 1.325,
      "step": 5475
    },
    {
      "epoch": 0.8591065292096219,
      "grad_norm": 0.9886195063591003,
      "learning_rate": 1.4120587316463607e-05,
      "loss": 1.4424,
      "step": 5500
    },
    {
      "epoch": 0.8630115588878475,
      "grad_norm": 0.8512805700302124,
      "learning_rate": 1.373008434864105e-05,
      "loss": 1.3217,
      "step": 5525
    },
    {
      "epoch": 0.8669165885660731,
      "grad_norm": 0.8333420157432556,
      "learning_rate": 1.3339581380818495e-05,
      "loss": 1.3563,
      "step": 5550
    },
    {
      "epoch": 0.8708216182442987,
      "grad_norm": 0.6682999134063721,
      "learning_rate": 1.2949078412995937e-05,
      "loss": 1.3076,
      "step": 5575
    },
    {
      "epoch": 0.8747266479225242,
      "grad_norm": 0.7954887747764587,
      "learning_rate": 1.2558575445173385e-05,
      "loss": 1.3856,
      "step": 5600
    },
    {
      "epoch": 0.8786316776007498,
      "grad_norm": 0.6596947312355042,
      "learning_rate": 1.218369259606373e-05,
      "loss": 1.3645,
      "step": 5625
    },
    {
      "epoch": 0.8825367072789754,
      "grad_norm": 0.9747390151023865,
      "learning_rate": 1.1793189628241175e-05,
      "loss": 1.329,
      "step": 5650
    },
    {
      "epoch": 0.8864417369572009,
      "grad_norm": 0.6473241448402405,
      "learning_rate": 1.140268666041862e-05,
      "loss": 1.3591,
      "step": 5675
    },
    {
      "epoch": 0.8903467666354264,
      "grad_norm": 0.6734678745269775,
      "learning_rate": 1.1012183692596065e-05,
      "loss": 1.323,
      "step": 5700
    },
    {
      "epoch": 0.894251796313652,
      "grad_norm": 0.7252177000045776,
      "learning_rate": 1.0621680724773508e-05,
      "loss": 1.4112,
      "step": 5725
    },
    {
      "epoch": 0.8981568259918775,
      "grad_norm": 0.8954679369926453,
      "learning_rate": 1.0231177756950953e-05,
      "loss": 1.3399,
      "step": 5750
    },
    {
      "epoch": 0.9020618556701031,
      "grad_norm": 1.1000677347183228,
      "learning_rate": 9.840674789128399e-06,
      "loss": 1.4044,
      "step": 5775
    },
    {
      "epoch": 0.9059668853483287,
      "grad_norm": 0.8410158157348633,
      "learning_rate": 9.450171821305841e-06,
      "loss": 1.397,
      "step": 5800
    },
    {
      "epoch": 0.9098719150265542,
      "grad_norm": 0.6987333297729492,
      "learning_rate": 9.059668853483288e-06,
      "loss": 1.3918,
      "step": 5825
    },
    {
      "epoch": 0.9137769447047798,
      "grad_norm": 0.8470657467842102,
      "learning_rate": 8.66916588566073e-06,
      "loss": 1.3682,
      "step": 5850
    },
    {
      "epoch": 0.9176819743830054,
      "grad_norm": 0.7091872692108154,
      "learning_rate": 8.278662917838176e-06,
      "loss": 1.3853,
      "step": 5875
    },
    {
      "epoch": 0.9215870040612308,
      "grad_norm": 0.7373557090759277,
      "learning_rate": 7.888159950015621e-06,
      "loss": 1.3458,
      "step": 5900
    },
    {
      "epoch": 0.9254920337394564,
      "grad_norm": 0.7899233102798462,
      "learning_rate": 7.4976569821930645e-06,
      "loss": 1.4056,
      "step": 5925
    },
    {
      "epoch": 0.929397063417682,
      "grad_norm": 1.1872673034667969,
      "learning_rate": 7.10715401437051e-06,
      "loss": 1.4163,
      "step": 5950
    },
    {
      "epoch": 0.9333020930959075,
      "grad_norm": 0.8266786932945251,
      "learning_rate": 6.716651046547954e-06,
      "loss": 1.402,
      "step": 5975
    },
    {
      "epoch": 0.9372071227741331,
      "grad_norm": 1.0458475351333618,
      "learning_rate": 6.326148078725399e-06,
      "loss": 1.3321,
      "step": 6000
    },
    {
      "epoch": 0.9372071227741331,
      "eval_loss": 1.3669209480285645,
      "eval_runtime": 1622.6337,
      "eval_samples_per_second": 6.313,
      "eval_steps_per_second": 6.313,
      "step": 6000
    },
    {
      "epoch": 0.9411121524523587,
      "grad_norm": 1.1221897602081299,
      "learning_rate": 5.935645110902843e-06,
      "loss": 1.3533,
      "step": 6025
    },
    {
      "epoch": 0.9450171821305842,
      "grad_norm": 1.0125004053115845,
      "learning_rate": 5.5451421430802874e-06,
      "loss": 1.3807,
      "step": 6050
    },
    {
      "epoch": 0.9489222118088098,
      "grad_norm": 0.9615964293479919,
      "learning_rate": 5.154639175257732e-06,
      "loss": 1.4028,
      "step": 6075
    },
    {
      "epoch": 0.9528272414870353,
      "grad_norm": 0.7577344179153442,
      "learning_rate": 4.764136207435177e-06,
      "loss": 1.38,
      "step": 6100
    },
    {
      "epoch": 0.9567322711652608,
      "grad_norm": 0.9583836793899536,
      "learning_rate": 4.3736332396126216e-06,
      "loss": 1.2673,
      "step": 6125
    },
    {
      "epoch": 0.9606373008434864,
      "grad_norm": 0.6736977100372314,
      "learning_rate": 3.983130271790066e-06,
      "loss": 1.4396,
      "step": 6150
    },
    {
      "epoch": 0.964542330521712,
      "grad_norm": 0.7640969753265381,
      "learning_rate": 3.59262730396751e-06,
      "loss": 1.3824,
      "step": 6175
    },
    {
      "epoch": 0.9684473601999375,
      "grad_norm": 0.909238338470459,
      "learning_rate": 3.202124336144955e-06,
      "loss": 1.3716,
      "step": 6200
    },
    {
      "epoch": 0.9723523898781631,
      "grad_norm": 0.923399806022644,
      "learning_rate": 2.8116213683223993e-06,
      "loss": 1.403,
      "step": 6225
    },
    {
      "epoch": 0.9762574195563887,
      "grad_norm": 0.9556292295455933,
      "learning_rate": 2.421118400499844e-06,
      "loss": 1.3713,
      "step": 6250
    },
    {
      "epoch": 0.9801624492346142,
      "grad_norm": 1.0249353647232056,
      "learning_rate": 2.0306154326772886e-06,
      "loss": 1.2827,
      "step": 6275
    },
    {
      "epoch": 0.9840674789128397,
      "grad_norm": 1.1308499574661255,
      "learning_rate": 1.640112464854733e-06,
      "loss": 1.4159,
      "step": 6300
    },
    {
      "epoch": 0.9879725085910653,
      "grad_norm": 0.8749229907989502,
      "learning_rate": 1.2496094970321776e-06,
      "loss": 1.3634,
      "step": 6325
    },
    {
      "epoch": 0.9918775382692908,
      "grad_norm": 0.8601365089416504,
      "learning_rate": 8.591065292096222e-07,
      "loss": 1.3991,
      "step": 6350
    },
    {
      "epoch": 0.9957825679475164,
      "grad_norm": 0.7126524448394775,
      "learning_rate": 4.6860356138706653e-07,
      "loss": 1.4219,
      "step": 6375
    },
    {
      "epoch": 0.999687597625742,
      "grad_norm": 0.8441383838653564,
      "learning_rate": 7.81005935645111e-08,
      "loss": 1.3463,
      "step": 6400
    },
    {
      "epoch": 1.0035926273039675,
      "grad_norm": 0.7897502183914185,
      "learning_rate": 4.984379881287098e-05,
      "loss": 1.4062,
      "step": 6425
    },
    {
      "epoch": 1.007497656982193,
      "grad_norm": 0.6900014281272888,
      "learning_rate": 4.9648547328959705e-05,
      "loss": 1.346,
      "step": 6450
    },
    {
      "epoch": 1.0114026866604187,
      "grad_norm": 0.7675171494483948,
      "learning_rate": 4.9453295845048426e-05,
      "loss": 1.3128,
      "step": 6475
    },
    {
      "epoch": 1.0153077163386441,
      "grad_norm": 0.6910794973373413,
      "learning_rate": 4.925804436113715e-05,
      "loss": 1.4034,
      "step": 6500
    },
    {
      "epoch": 1.0192127460168696,
      "grad_norm": 0.9522333145141602,
      "learning_rate": 4.906279287722587e-05,
      "loss": 1.3676,
      "step": 6525
    },
    {
      "epoch": 1.0231177756950953,
      "grad_norm": 0.7269165515899658,
      "learning_rate": 4.886754139331459e-05,
      "loss": 1.3715,
      "step": 6550
    },
    {
      "epoch": 1.0270228053733208,
      "grad_norm": 0.954698383808136,
      "learning_rate": 4.867228990940331e-05,
      "loss": 1.3235,
      "step": 6575
    },
    {
      "epoch": 1.0309278350515463,
      "grad_norm": 0.7565621137619019,
      "learning_rate": 4.847703842549204e-05,
      "loss": 1.3654,
      "step": 6600
    },
    {
      "epoch": 1.034832864729772,
      "grad_norm": 0.8482614755630493,
      "learning_rate": 4.828178694158076e-05,
      "loss": 1.3478,
      "step": 6625
    },
    {
      "epoch": 1.0387378944079975,
      "grad_norm": 1.0371958017349243,
      "learning_rate": 4.808653545766948e-05,
      "loss": 1.4003,
      "step": 6650
    },
    {
      "epoch": 1.042642924086223,
      "grad_norm": 1.0408945083618164,
      "learning_rate": 4.7891283973758204e-05,
      "loss": 1.3603,
      "step": 6675
    },
    {
      "epoch": 1.0465479537644486,
      "grad_norm": 1.0935609340667725,
      "learning_rate": 4.7696032489846925e-05,
      "loss": 1.3588,
      "step": 6700
    },
    {
      "epoch": 1.0504529834426741,
      "grad_norm": 0.76204913854599,
      "learning_rate": 4.750078100593565e-05,
      "loss": 1.3708,
      "step": 6725
    },
    {
      "epoch": 1.0543580131208996,
      "grad_norm": 0.6880338788032532,
      "learning_rate": 4.7305529522024375e-05,
      "loss": 1.3148,
      "step": 6750
    },
    {
      "epoch": 1.0582630427991253,
      "grad_norm": 0.8484424948692322,
      "learning_rate": 4.711027803811309e-05,
      "loss": 1.4161,
      "step": 6775
    },
    {
      "epoch": 1.0621680724773508,
      "grad_norm": 0.7255854606628418,
      "learning_rate": 4.691502655420181e-05,
      "loss": 1.4029,
      "step": 6800
    },
    {
      "epoch": 1.0660731021555763,
      "grad_norm": 0.9558801054954529,
      "learning_rate": 4.671977507029054e-05,
      "loss": 1.3961,
      "step": 6825
    },
    {
      "epoch": 1.069978131833802,
      "grad_norm": 0.617160439491272,
      "learning_rate": 4.652452358637926e-05,
      "loss": 1.3687,
      "step": 6850
    },
    {
      "epoch": 1.0738831615120275,
      "grad_norm": 1.3027188777923584,
      "learning_rate": 4.632927210246798e-05,
      "loss": 1.407,
      "step": 6875
    },
    {
      "epoch": 1.077788191190253,
      "grad_norm": 0.7245245575904846,
      "learning_rate": 4.61340206185567e-05,
      "loss": 1.3528,
      "step": 6900
    },
    {
      "epoch": 1.0816932208684786,
      "grad_norm": 0.7162719964981079,
      "learning_rate": 4.5938769134645424e-05,
      "loss": 1.4123,
      "step": 6925
    },
    {
      "epoch": 1.0855982505467041,
      "grad_norm": 0.9939456582069397,
      "learning_rate": 4.5743517650734146e-05,
      "loss": 1.3473,
      "step": 6950
    },
    {
      "epoch": 1.0895032802249296,
      "grad_norm": 1.121680736541748,
      "learning_rate": 4.5548266166822874e-05,
      "loss": 1.3428,
      "step": 6975
    },
    {
      "epoch": 1.0934083099031553,
      "grad_norm": 0.7238386869430542,
      "learning_rate": 4.5353014682911595e-05,
      "loss": 1.3184,
      "step": 7000
    },
    {
      "epoch": 1.0934083099031553,
      "eval_loss": 1.367346167564392,
      "eval_runtime": 1635.1448,
      "eval_samples_per_second": 6.264,
      "eval_steps_per_second": 6.264,
      "step": 7000
    },
    {
      "epoch": 1.0973133395813808,
      "grad_norm": 0.6896882653236389,
      "learning_rate": 4.515776319900032e-05,
      "loss": 1.3549,
      "step": 7025
    },
    {
      "epoch": 1.1012183692596063,
      "grad_norm": 0.690481424331665,
      "learning_rate": 4.496251171508904e-05,
      "loss": 1.2954,
      "step": 7050
    },
    {
      "epoch": 1.105123398937832,
      "grad_norm": 0.9109671711921692,
      "learning_rate": 4.476726023117776e-05,
      "loss": 1.3108,
      "step": 7075
    },
    {
      "epoch": 1.1090284286160574,
      "grad_norm": 0.7367666363716125,
      "learning_rate": 4.457200874726648e-05,
      "loss": 1.3477,
      "step": 7100
    },
    {
      "epoch": 1.1129334582942831,
      "grad_norm": 0.6674938797950745,
      "learning_rate": 4.43767572633552e-05,
      "loss": 1.2804,
      "step": 7125
    },
    {
      "epoch": 1.1168384879725086,
      "grad_norm": 0.8316558003425598,
      "learning_rate": 4.4181505779443924e-05,
      "loss": 1.4126,
      "step": 7150
    },
    {
      "epoch": 1.120743517650734,
      "grad_norm": 0.723075270652771,
      "learning_rate": 4.3986254295532645e-05,
      "loss": 1.3459,
      "step": 7175
    },
    {
      "epoch": 1.1246485473289598,
      "grad_norm": 0.8664693832397461,
      "learning_rate": 4.3791002811621366e-05,
      "loss": 1.3826,
      "step": 7200
    },
    {
      "epoch": 1.1285535770071853,
      "grad_norm": 0.8418654799461365,
      "learning_rate": 4.3595751327710094e-05,
      "loss": 1.3726,
      "step": 7225
    },
    {
      "epoch": 1.1324586066854108,
      "grad_norm": 1.0758962631225586,
      "learning_rate": 4.3400499843798816e-05,
      "loss": 1.3332,
      "step": 7250
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 0.8435102105140686,
      "learning_rate": 4.320524835988754e-05,
      "loss": 1.4031,
      "step": 7275
    },
    {
      "epoch": 1.140268666041862,
      "grad_norm": 0.7807736992835999,
      "learning_rate": 4.300999687597626e-05,
      "loss": 1.339,
      "step": 7300
    },
    {
      "epoch": 1.1441736957200874,
      "grad_norm": 0.8392592668533325,
      "learning_rate": 4.281474539206498e-05,
      "loss": 1.3041,
      "step": 7325
    },
    {
      "epoch": 1.148078725398313,
      "grad_norm": 0.8652057647705078,
      "learning_rate": 4.26194939081537e-05,
      "loss": 1.3986,
      "step": 7350
    },
    {
      "epoch": 1.1519837550765386,
      "grad_norm": 0.7893068790435791,
      "learning_rate": 4.242424242424243e-05,
      "loss": 1.3174,
      "step": 7375
    },
    {
      "epoch": 1.155888784754764,
      "grad_norm": 1.021916151046753,
      "learning_rate": 4.222899094033115e-05,
      "loss": 1.3445,
      "step": 7400
    },
    {
      "epoch": 1.1597938144329896,
      "grad_norm": 1.0012433528900146,
      "learning_rate": 4.2033739456419865e-05,
      "loss": 1.3271,
      "step": 7425
    },
    {
      "epoch": 1.1636988441112153,
      "grad_norm": 0.827292263507843,
      "learning_rate": 4.1838487972508593e-05,
      "loss": 1.338,
      "step": 7450
    },
    {
      "epoch": 1.1676038737894407,
      "grad_norm": 0.7504109144210815,
      "learning_rate": 4.1643236488597315e-05,
      "loss": 1.3961,
      "step": 7475
    },
    {
      "epoch": 1.1715089034676662,
      "grad_norm": 0.7914094924926758,
      "learning_rate": 4.1447985004686036e-05,
      "loss": 1.3658,
      "step": 7500
    },
    {
      "epoch": 1.175413933145892,
      "grad_norm": 0.8138331770896912,
      "learning_rate": 4.1252733520774764e-05,
      "loss": 1.3846,
      "step": 7525
    },
    {
      "epoch": 1.1793189628241174,
      "grad_norm": 0.7650206089019775,
      "learning_rate": 4.105748203686348e-05,
      "loss": 1.3596,
      "step": 7550
    },
    {
      "epoch": 1.1832239925023431,
      "grad_norm": 0.8807560801506042,
      "learning_rate": 4.0870040612308655e-05,
      "loss": 1.3023,
      "step": 7575
    },
    {
      "epoch": 1.1871290221805686,
      "grad_norm": 0.7314361333847046,
      "learning_rate": 4.0674789128397376e-05,
      "loss": 1.3394,
      "step": 7600
    },
    {
      "epoch": 1.191034051858794,
      "grad_norm": 0.798811137676239,
      "learning_rate": 4.04795376444861e-05,
      "loss": 1.3957,
      "step": 7625
    },
    {
      "epoch": 1.1949390815370198,
      "grad_norm": 0.794355034828186,
      "learning_rate": 4.0284286160574826e-05,
      "loss": 1.3553,
      "step": 7650
    },
    {
      "epoch": 1.1988441112152453,
      "grad_norm": 0.7296790480613708,
      "learning_rate": 4.008903467666355e-05,
      "loss": 1.3838,
      "step": 7675
    },
    {
      "epoch": 1.2027491408934707,
      "grad_norm": 0.620858371257782,
      "learning_rate": 3.989378319275227e-05,
      "loss": 1.3809,
      "step": 7700
    },
    {
      "epoch": 1.2066541705716964,
      "grad_norm": 0.8834940195083618,
      "learning_rate": 3.969853170884099e-05,
      "loss": 1.3337,
      "step": 7725
    },
    {
      "epoch": 1.210559200249922,
      "grad_norm": 0.7673628330230713,
      "learning_rate": 3.950328022492971e-05,
      "loss": 1.3337,
      "step": 7750
    },
    {
      "epoch": 1.2144642299281474,
      "grad_norm": 0.8214130997657776,
      "learning_rate": 3.930802874101843e-05,
      "loss": 1.3305,
      "step": 7775
    },
    {
      "epoch": 1.218369259606373,
      "grad_norm": 0.8132809996604919,
      "learning_rate": 3.911277725710716e-05,
      "loss": 1.3332,
      "step": 7800
    },
    {
      "epoch": 1.2222742892845986,
      "grad_norm": 0.8521868586540222,
      "learning_rate": 3.8917525773195875e-05,
      "loss": 1.3933,
      "step": 7825
    },
    {
      "epoch": 1.226179318962824,
      "grad_norm": 0.9464898109436035,
      "learning_rate": 3.87222742892846e-05,
      "loss": 1.3717,
      "step": 7850
    },
    {
      "epoch": 1.2300843486410498,
      "grad_norm": 1.2934428453445435,
      "learning_rate": 3.8527022805373325e-05,
      "loss": 1.3453,
      "step": 7875
    },
    {
      "epoch": 1.2339893783192752,
      "grad_norm": 0.8383726477622986,
      "learning_rate": 3.8331771321462046e-05,
      "loss": 1.3614,
      "step": 7900
    },
    {
      "epoch": 1.2378944079975007,
      "grad_norm": 0.7801920771598816,
      "learning_rate": 3.813651983755077e-05,
      "loss": 1.374,
      "step": 7925
    },
    {
      "epoch": 1.2417994376757264,
      "grad_norm": 0.9214403033256531,
      "learning_rate": 3.794126835363949e-05,
      "loss": 1.3556,
      "step": 7950
    },
    {
      "epoch": 1.245704467353952,
      "grad_norm": 0.7777683734893799,
      "learning_rate": 3.774601686972821e-05,
      "loss": 1.367,
      "step": 7975
    },
    {
      "epoch": 1.2496094970321774,
      "grad_norm": 0.8512343764305115,
      "learning_rate": 3.755076538581693e-05,
      "loss": 1.311,
      "step": 8000
    },
    {
      "epoch": 1.2496094970321774,
      "eval_loss": 1.3646577596664429,
      "eval_runtime": 1635.0512,
      "eval_samples_per_second": 6.265,
      "eval_steps_per_second": 6.265,
      "step": 8000
    },
    {
      "epoch": 1.2535145267104029,
      "grad_norm": 0.9265210032463074,
      "learning_rate": 3.735551390190566e-05,
      "loss": 1.3442,
      "step": 8025
    },
    {
      "epoch": 1.2574195563886286,
      "grad_norm": 0.7041323184967041,
      "learning_rate": 3.716026241799438e-05,
      "loss": 1.3113,
      "step": 8050
    },
    {
      "epoch": 1.261324586066854,
      "grad_norm": 0.9148221611976624,
      "learning_rate": 3.69650109340831e-05,
      "loss": 1.3694,
      "step": 8075
    },
    {
      "epoch": 1.2652296157450795,
      "grad_norm": 0.891467273235321,
      "learning_rate": 3.6769759450171824e-05,
      "loss": 1.3114,
      "step": 8100
    },
    {
      "epoch": 1.2691346454233052,
      "grad_norm": 1.0062735080718994,
      "learning_rate": 3.6574507966260545e-05,
      "loss": 1.365,
      "step": 8125
    },
    {
      "epoch": 1.2730396751015307,
      "grad_norm": 0.61658775806427,
      "learning_rate": 3.637925648234927e-05,
      "loss": 1.3201,
      "step": 8150
    },
    {
      "epoch": 1.2769447047797562,
      "grad_norm": 0.8909085392951965,
      "learning_rate": 3.6184004998437995e-05,
      "loss": 1.389,
      "step": 8175
    },
    {
      "epoch": 1.280849734457982,
      "grad_norm": 1.0938748121261597,
      "learning_rate": 3.5988753514526716e-05,
      "loss": 1.2945,
      "step": 8200
    },
    {
      "epoch": 1.2847547641362074,
      "grad_norm": 0.8691226840019226,
      "learning_rate": 3.579350203061543e-05,
      "loss": 1.3173,
      "step": 8225
    },
    {
      "epoch": 1.2886597938144329,
      "grad_norm": 0.6926887631416321,
      "learning_rate": 3.559825054670416e-05,
      "loss": 1.3858,
      "step": 8250
    },
    {
      "epoch": 1.2925648234926586,
      "grad_norm": 0.8537850975990295,
      "learning_rate": 3.540299906279288e-05,
      "loss": 1.3765,
      "step": 8275
    },
    {
      "epoch": 1.296469853170884,
      "grad_norm": 0.6698374152183533,
      "learning_rate": 3.52077475788816e-05,
      "loss": 1.2583,
      "step": 8300
    },
    {
      "epoch": 1.3003748828491095,
      "grad_norm": 1.0240541696548462,
      "learning_rate": 3.501249609497032e-05,
      "loss": 1.3623,
      "step": 8325
    },
    {
      "epoch": 1.3042799125273352,
      "grad_norm": 0.9658970236778259,
      "learning_rate": 3.4817244611059044e-05,
      "loss": 1.378,
      "step": 8350
    },
    {
      "epoch": 1.3081849422055607,
      "grad_norm": 0.8077911138534546,
      "learning_rate": 3.4621993127147766e-05,
      "loss": 1.3083,
      "step": 8375
    },
    {
      "epoch": 1.3120899718837864,
      "grad_norm": 0.8437012434005737,
      "learning_rate": 3.442674164323649e-05,
      "loss": 1.3944,
      "step": 8400
    },
    {
      "epoch": 1.3159950015620119,
      "grad_norm": 0.8080506324768066,
      "learning_rate": 3.4231490159325215e-05,
      "loss": 1.2616,
      "step": 8425
    },
    {
      "epoch": 1.3199000312402374,
      "grad_norm": 0.7001646757125854,
      "learning_rate": 3.403623867541394e-05,
      "loss": 1.3971,
      "step": 8450
    },
    {
      "epoch": 1.323805060918463,
      "grad_norm": 0.6363238096237183,
      "learning_rate": 3.384098719150265e-05,
      "loss": 1.4173,
      "step": 8475
    },
    {
      "epoch": 1.3277100905966885,
      "grad_norm": 0.9102014899253845,
      "learning_rate": 3.364573570759138e-05,
      "loss": 1.3858,
      "step": 8500
    },
    {
      "epoch": 1.331615120274914,
      "grad_norm": 0.8934385776519775,
      "learning_rate": 3.34504842236801e-05,
      "loss": 1.4068,
      "step": 8525
    },
    {
      "epoch": 1.3355201499531397,
      "grad_norm": 0.8061802387237549,
      "learning_rate": 3.325523273976882e-05,
      "loss": 1.4313,
      "step": 8550
    },
    {
      "epoch": 1.3394251796313652,
      "grad_norm": 1.237291932106018,
      "learning_rate": 3.305998125585755e-05,
      "loss": 1.3357,
      "step": 8575
    },
    {
      "epoch": 1.3433302093095907,
      "grad_norm": 1.063120722770691,
      "learning_rate": 3.2864729771946265e-05,
      "loss": 1.2929,
      "step": 8600
    },
    {
      "epoch": 1.3472352389878164,
      "grad_norm": 0.7264732122421265,
      "learning_rate": 3.2669478288034986e-05,
      "loss": 1.3826,
      "step": 8625
    },
    {
      "epoch": 1.3511402686660419,
      "grad_norm": 1.0675426721572876,
      "learning_rate": 3.2474226804123714e-05,
      "loss": 1.3075,
      "step": 8650
    },
    {
      "epoch": 1.3550452983442673,
      "grad_norm": 0.8204506635665894,
      "learning_rate": 3.2278975320212436e-05,
      "loss": 1.3512,
      "step": 8675
    },
    {
      "epoch": 1.358950328022493,
      "grad_norm": 1.2552356719970703,
      "learning_rate": 3.208372383630116e-05,
      "loss": 1.3557,
      "step": 8700
    },
    {
      "epoch": 1.3628553577007185,
      "grad_norm": 1.1798059940338135,
      "learning_rate": 3.188847235238988e-05,
      "loss": 1.3878,
      "step": 8725
    },
    {
      "epoch": 1.366760387378944,
      "grad_norm": 0.7149034738540649,
      "learning_rate": 3.16932208684786e-05,
      "loss": 1.4098,
      "step": 8750
    },
    {
      "epoch": 1.3706654170571697,
      "grad_norm": 0.9428892135620117,
      "learning_rate": 3.149796938456732e-05,
      "loss": 1.3277,
      "step": 8775
    },
    {
      "epoch": 1.3745704467353952,
      "grad_norm": 0.7274487614631653,
      "learning_rate": 3.130271790065605e-05,
      "loss": 1.3377,
      "step": 8800
    },
    {
      "epoch": 1.3784754764136207,
      "grad_norm": 0.9834299087524414,
      "learning_rate": 3.110746641674477e-05,
      "loss": 1.4021,
      "step": 8825
    },
    {
      "epoch": 1.3823805060918464,
      "grad_norm": 0.7523283362388611,
      "learning_rate": 3.091221493283349e-05,
      "loss": 1.3402,
      "step": 8850
    },
    {
      "epoch": 1.3862855357700719,
      "grad_norm": 0.9305262565612793,
      "learning_rate": 3.0716963448922213e-05,
      "loss": 1.355,
      "step": 8875
    },
    {
      "epoch": 1.3901905654482973,
      "grad_norm": 0.811578094959259,
      "learning_rate": 3.0521711965010935e-05,
      "loss": 1.3425,
      "step": 8900
    },
    {
      "epoch": 1.394095595126523,
      "grad_norm": 0.5529634356498718,
      "learning_rate": 3.0326460481099656e-05,
      "loss": 1.3474,
      "step": 8925
    },
    {
      "epoch": 1.3980006248047485,
      "grad_norm": 1.125211477279663,
      "learning_rate": 3.013120899718838e-05,
      "loss": 1.3399,
      "step": 8950
    },
    {
      "epoch": 1.401905654482974,
      "grad_norm": 0.9219701886177063,
      "learning_rate": 2.9935957513277102e-05,
      "loss": 1.3499,
      "step": 8975
    },
    {
      "epoch": 1.4058106841611997,
      "grad_norm": 1.2497669458389282,
      "learning_rate": 2.9740706029365824e-05,
      "loss": 1.3355,
      "step": 9000
    },
    {
      "epoch": 1.4058106841611997,
      "eval_loss": 1.3620555400848389,
      "eval_runtime": 1635.3178,
      "eval_samples_per_second": 6.264,
      "eval_steps_per_second": 6.264,
      "step": 9000
    },
    {
      "epoch": 1.4097157138394252,
      "grad_norm": 0.665522575378418,
      "learning_rate": 2.954545454545455e-05,
      "loss": 1.3051,
      "step": 9025
    },
    {
      "epoch": 1.4136207435176507,
      "grad_norm": 0.5996708273887634,
      "learning_rate": 2.935020306154327e-05,
      "loss": 1.4006,
      "step": 9050
    },
    {
      "epoch": 1.4175257731958764,
      "grad_norm": 1.0607454776763916,
      "learning_rate": 2.9154951577631988e-05,
      "loss": 1.3679,
      "step": 9075
    },
    {
      "epoch": 1.4214308028741018,
      "grad_norm": 0.9716747999191284,
      "learning_rate": 2.8959700093720716e-05,
      "loss": 1.3351,
      "step": 9100
    },
    {
      "epoch": 1.4253358325523273,
      "grad_norm": 0.8874661922454834,
      "learning_rate": 2.8764448609809437e-05,
      "loss": 1.3244,
      "step": 9125
    },
    {
      "epoch": 1.429240862230553,
      "grad_norm": 1.0018553733825684,
      "learning_rate": 2.8569197125898155e-05,
      "loss": 1.4254,
      "step": 9150
    },
    {
      "epoch": 1.4331458919087785,
      "grad_norm": 1.1871497631072998,
      "learning_rate": 2.8373945641986883e-05,
      "loss": 1.3362,
      "step": 9175
    },
    {
      "epoch": 1.437050921587004,
      "grad_norm": 0.7893287539482117,
      "learning_rate": 2.81786941580756e-05,
      "loss": 1.3495,
      "step": 9200
    },
    {
      "epoch": 1.4409559512652297,
      "grad_norm": 0.761947751045227,
      "learning_rate": 2.7983442674164323e-05,
      "loss": 1.3161,
      "step": 9225
    },
    {
      "epoch": 1.4448609809434552,
      "grad_norm": 0.8534244298934937,
      "learning_rate": 2.7788191190253047e-05,
      "loss": 1.4444,
      "step": 9250
    },
    {
      "epoch": 1.4487660106216806,
      "grad_norm": 0.8835830092430115,
      "learning_rate": 2.759293970634177e-05,
      "loss": 1.3066,
      "step": 9275
    },
    {
      "epoch": 1.4526710402999063,
      "grad_norm": 0.960702121257782,
      "learning_rate": 2.739768822243049e-05,
      "loss": 1.4124,
      "step": 9300
    },
    {
      "epoch": 1.4565760699781318,
      "grad_norm": 0.8537827730178833,
      "learning_rate": 2.7202436738519215e-05,
      "loss": 1.3413,
      "step": 9325
    },
    {
      "epoch": 1.4604810996563573,
      "grad_norm": 1.0278260707855225,
      "learning_rate": 2.7007185254607936e-05,
      "loss": 1.3748,
      "step": 9350
    },
    {
      "epoch": 1.464386129334583,
      "grad_norm": 0.7484654188156128,
      "learning_rate": 2.6811933770696658e-05,
      "loss": 1.3164,
      "step": 9375
    },
    {
      "epoch": 1.4682911590128085,
      "grad_norm": 0.8077751398086548,
      "learning_rate": 2.6616682286785382e-05,
      "loss": 1.3575,
      "step": 9400
    },
    {
      "epoch": 1.472196188691034,
      "grad_norm": 0.8895701169967651,
      "learning_rate": 2.6421430802874104e-05,
      "loss": 1.3668,
      "step": 9425
    },
    {
      "epoch": 1.4761012183692597,
      "grad_norm": 0.7941737174987793,
      "learning_rate": 2.6226179318962825e-05,
      "loss": 1.295,
      "step": 9450
    },
    {
      "epoch": 1.4800062480474852,
      "grad_norm": 0.9121620655059814,
      "learning_rate": 2.603092783505155e-05,
      "loss": 1.4386,
      "step": 9475
    },
    {
      "epoch": 1.4839112777257109,
      "grad_norm": 0.7017568349838257,
      "learning_rate": 2.583567635114027e-05,
      "loss": 1.2947,
      "step": 9500
    },
    {
      "epoch": 1.4878163074039363,
      "grad_norm": 0.996441125869751,
      "learning_rate": 2.564042486722899e-05,
      "loss": 1.3377,
      "step": 9525
    },
    {
      "epoch": 1.4917213370821618,
      "grad_norm": 0.6413044929504395,
      "learning_rate": 2.5445173383317717e-05,
      "loss": 1.3336,
      "step": 9550
    },
    {
      "epoch": 1.4956263667603875,
      "grad_norm": 0.7449758648872375,
      "learning_rate": 2.5249921899406435e-05,
      "loss": 1.3363,
      "step": 9575
    },
    {
      "epoch": 1.499531396438613,
      "grad_norm": 0.7543124556541443,
      "learning_rate": 2.5054670415495157e-05,
      "loss": 1.4304,
      "step": 9600
    },
    {
      "epoch": 1.5034364261168385,
      "grad_norm": 0.8017299771308899,
      "learning_rate": 2.485941893158388e-05,
      "loss": 1.3288,
      "step": 9625
    },
    {
      "epoch": 1.5073414557950642,
      "grad_norm": 0.7455822825431824,
      "learning_rate": 2.4664167447672603e-05,
      "loss": 1.326,
      "step": 9650
    },
    {
      "epoch": 1.5112464854732894,
      "grad_norm": 1.1995030641555786,
      "learning_rate": 2.4468915963761328e-05,
      "loss": 1.2954,
      "step": 9675
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 0.6345981955528259,
      "learning_rate": 2.427366447985005e-05,
      "loss": 1.3394,
      "step": 9700
    },
    {
      "epoch": 1.5190565448297408,
      "grad_norm": 0.9438307881355286,
      "learning_rate": 2.407841299593877e-05,
      "loss": 1.3446,
      "step": 9725
    },
    {
      "epoch": 1.522961574507966,
      "grad_norm": 0.9402878284454346,
      "learning_rate": 2.3883161512027495e-05,
      "loss": 1.3311,
      "step": 9750
    },
    {
      "epoch": 1.5268666041861918,
      "grad_norm": 0.8922075033187866,
      "learning_rate": 2.3687910028116213e-05,
      "loss": 1.3821,
      "step": 9775
    },
    {
      "epoch": 1.5307716338644175,
      "grad_norm": 1.0270122289657593,
      "learning_rate": 2.3492658544204938e-05,
      "loss": 1.3741,
      "step": 9800
    },
    {
      "epoch": 1.5346766635426428,
      "grad_norm": 0.9030953645706177,
      "learning_rate": 2.329740706029366e-05,
      "loss": 1.3737,
      "step": 9825
    },
    {
      "epoch": 1.5385816932208685,
      "grad_norm": 0.8428076505661011,
      "learning_rate": 2.310215557638238e-05,
      "loss": 1.353,
      "step": 9850
    },
    {
      "epoch": 1.5424867228990942,
      "grad_norm": 0.9921271800994873,
      "learning_rate": 2.2906904092471105e-05,
      "loss": 1.3362,
      "step": 9875
    },
    {
      "epoch": 1.5463917525773194,
      "grad_norm": 0.8196167945861816,
      "learning_rate": 2.2711652608559827e-05,
      "loss": 1.3721,
      "step": 9900
    },
    {
      "epoch": 1.5502967822555451,
      "grad_norm": 0.8525394797325134,
      "learning_rate": 2.2516401124648548e-05,
      "loss": 1.3713,
      "step": 9925
    },
    {
      "epoch": 1.5542018119337708,
      "grad_norm": 1.1488862037658691,
      "learning_rate": 2.232114964073727e-05,
      "loss": 1.3779,
      "step": 9950
    },
    {
      "epoch": 1.558106841611996,
      "grad_norm": 0.5047322511672974,
      "learning_rate": 2.2125898156825994e-05,
      "loss": 1.3488,
      "step": 9975
    },
    {
      "epoch": 1.5620118712902218,
      "grad_norm": 0.8630703687667847,
      "learning_rate": 2.1930646672914716e-05,
      "loss": 1.3233,
      "step": 10000
    },
    {
      "epoch": 1.5620118712902218,
      "eval_loss": 1.360047698020935,
      "eval_runtime": 1635.2035,
      "eval_samples_per_second": 6.264,
      "eval_steps_per_second": 6.264,
      "step": 10000
    },
    {
      "epoch": 1.5659169009684475,
      "grad_norm": 0.8866132497787476,
      "learning_rate": 2.1735395189003437e-05,
      "loss": 1.352,
      "step": 10025
    },
    {
      "epoch": 1.569821930646673,
      "grad_norm": 0.7050042152404785,
      "learning_rate": 2.154014370509216e-05,
      "loss": 1.349,
      "step": 10050
    },
    {
      "epoch": 1.5737269603248984,
      "grad_norm": 1.2839722633361816,
      "learning_rate": 2.1344892221180883e-05,
      "loss": 1.3086,
      "step": 10075
    },
    {
      "epoch": 1.5776319900031242,
      "grad_norm": 0.7116836309432983,
      "learning_rate": 2.1149640737269604e-05,
      "loss": 1.374,
      "step": 10100
    },
    {
      "epoch": 1.5815370196813496,
      "grad_norm": 1.0118811130523682,
      "learning_rate": 2.0954389253358326e-05,
      "loss": 1.3655,
      "step": 10125
    },
    {
      "epoch": 1.5854420493595751,
      "grad_norm": 0.6999498605728149,
      "learning_rate": 2.0759137769447047e-05,
      "loss": 1.358,
      "step": 10150
    },
    {
      "epoch": 1.5893470790378008,
      "grad_norm": 0.9378767609596252,
      "learning_rate": 2.0563886285535772e-05,
      "loss": 1.3475,
      "step": 10175
    },
    {
      "epoch": 1.5932521087160263,
      "grad_norm": 1.4833121299743652,
      "learning_rate": 2.0368634801624493e-05,
      "loss": 1.33,
      "step": 10200
    },
    {
      "epoch": 1.5971571383942518,
      "grad_norm": 0.9702766537666321,
      "learning_rate": 2.0173383317713215e-05,
      "loss": 1.3419,
      "step": 10225
    },
    {
      "epoch": 1.6010621680724775,
      "grad_norm": 0.8680833578109741,
      "learning_rate": 1.997813183380194e-05,
      "loss": 1.3191,
      "step": 10250
    },
    {
      "epoch": 1.604967197750703,
      "grad_norm": 1.0828355550765991,
      "learning_rate": 1.9782880349890657e-05,
      "loss": 1.364,
      "step": 10275
    },
    {
      "epoch": 1.6088722274289284,
      "grad_norm": 0.862125039100647,
      "learning_rate": 1.9587628865979382e-05,
      "loss": 1.3483,
      "step": 10300
    },
    {
      "epoch": 1.6127772571071541,
      "grad_norm": 0.729792058467865,
      "learning_rate": 1.9392377382068107e-05,
      "loss": 1.381,
      "step": 10325
    },
    {
      "epoch": 1.6166822867853796,
      "grad_norm": 0.7955142855644226,
      "learning_rate": 1.9197125898156825e-05,
      "loss": 1.334,
      "step": 10350
    },
    {
      "epoch": 1.620587316463605,
      "grad_norm": 0.7715886831283569,
      "learning_rate": 1.900187441424555e-05,
      "loss": 1.3431,
      "step": 10375
    },
    {
      "epoch": 1.6244923461418308,
      "grad_norm": 0.9992542266845703,
      "learning_rate": 1.880662293033427e-05,
      "loss": 1.3309,
      "step": 10400
    },
    {
      "epoch": 1.6283973758200563,
      "grad_norm": 0.735744059085846,
      "learning_rate": 1.8611371446422992e-05,
      "loss": 1.3441,
      "step": 10425
    },
    {
      "epoch": 1.6323024054982818,
      "grad_norm": 0.6735221743583679,
      "learning_rate": 1.8416119962511717e-05,
      "loss": 1.339,
      "step": 10450
    },
    {
      "epoch": 1.6362074351765075,
      "grad_norm": 0.9419386386871338,
      "learning_rate": 1.822086847860044e-05,
      "loss": 1.3064,
      "step": 10475
    },
    {
      "epoch": 1.640112464854733,
      "grad_norm": 0.9118633270263672,
      "learning_rate": 1.802561699468916e-05,
      "loss": 1.3289,
      "step": 10500
    },
    {
      "epoch": 1.6440174945329584,
      "grad_norm": 0.7735126614570618,
      "learning_rate": 1.783036551077788e-05,
      "loss": 1.3407,
      "step": 10525
    },
    {
      "epoch": 1.6479225242111841,
      "grad_norm": 0.6859211325645447,
      "learning_rate": 1.7635114026866606e-05,
      "loss": 1.3184,
      "step": 10550
    },
    {
      "epoch": 1.6518275538894096,
      "grad_norm": 1.1763262748718262,
      "learning_rate": 1.7439862542955327e-05,
      "loss": 1.3316,
      "step": 10575
    },
    {
      "epoch": 1.655732583567635,
      "grad_norm": 0.8942413330078125,
      "learning_rate": 1.724461105904405e-05,
      "loss": 1.3435,
      "step": 10600
    },
    {
      "epoch": 1.6596376132458608,
      "grad_norm": 0.8217234015464783,
      "learning_rate": 1.7049359575132773e-05,
      "loss": 1.3255,
      "step": 10625
    },
    {
      "epoch": 1.6635426429240863,
      "grad_norm": 0.7428781390190125,
      "learning_rate": 1.6854108091221495e-05,
      "loss": 1.3686,
      "step": 10650
    },
    {
      "epoch": 1.6674476726023117,
      "grad_norm": 0.7960435748100281,
      "learning_rate": 1.6658856607310216e-05,
      "loss": 1.3744,
      "step": 10675
    },
    {
      "epoch": 1.6713527022805375,
      "grad_norm": 1.1932882070541382,
      "learning_rate": 1.646360512339894e-05,
      "loss": 1.3455,
      "step": 10700
    },
    {
      "epoch": 1.675257731958763,
      "grad_norm": 0.8534852266311646,
      "learning_rate": 1.626835363948766e-05,
      "loss": 1.2989,
      "step": 10725
    },
    {
      "epoch": 1.6791627616369884,
      "grad_norm": 0.7823891043663025,
      "learning_rate": 1.6073102155576384e-05,
      "loss": 1.3631,
      "step": 10750
    },
    {
      "epoch": 1.6830677913152141,
      "grad_norm": 0.9389708638191223,
      "learning_rate": 1.5877850671665105e-05,
      "loss": 1.3569,
      "step": 10775
    },
    {
      "epoch": 1.6869728209934396,
      "grad_norm": 1.0086593627929688,
      "learning_rate": 1.5682599187753826e-05,
      "loss": 1.3121,
      "step": 10800
    },
    {
      "epoch": 1.690877850671665,
      "grad_norm": 0.8192769289016724,
      "learning_rate": 1.548734770384255e-05,
      "loss": 1.2889,
      "step": 10825
    },
    {
      "epoch": 1.6947828803498908,
      "grad_norm": 0.9471564888954163,
      "learning_rate": 1.5292096219931273e-05,
      "loss": 1.4061,
      "step": 10850
    },
    {
      "epoch": 1.6986879100281163,
      "grad_norm": 0.6777927279472351,
      "learning_rate": 1.5096844736019994e-05,
      "loss": 1.3516,
      "step": 10875
    },
    {
      "epoch": 1.7025929397063417,
      "grad_norm": 0.7602481842041016,
      "learning_rate": 1.4901593252108717e-05,
      "loss": 1.3177,
      "step": 10900
    },
    {
      "epoch": 1.7064979693845674,
      "grad_norm": 0.688730001449585,
      "learning_rate": 1.470634176819744e-05,
      "loss": 1.2903,
      "step": 10925
    },
    {
      "epoch": 1.710402999062793,
      "grad_norm": 0.9189403057098389,
      "learning_rate": 1.4511090284286161e-05,
      "loss": 1.3697,
      "step": 10950
    },
    {
      "epoch": 1.7143080287410184,
      "grad_norm": 0.8055533170700073,
      "learning_rate": 1.4315838800374884e-05,
      "loss": 1.3176,
      "step": 10975
    },
    {
      "epoch": 1.718213058419244,
      "grad_norm": 0.895561695098877,
      "learning_rate": 1.4120587316463607e-05,
      "loss": 1.296,
      "step": 11000
    },
    {
      "epoch": 1.718213058419244,
      "eval_loss": 1.3586912155151367,
      "eval_runtime": 1635.1092,
      "eval_samples_per_second": 6.264,
      "eval_steps_per_second": 6.264,
      "step": 11000
    },
    {
      "epoch": 1.7221180880974696,
      "grad_norm": 0.8228324055671692,
      "learning_rate": 1.3925335832552327e-05,
      "loss": 1.3242,
      "step": 11025
    },
    {
      "epoch": 1.726023117775695,
      "grad_norm": 0.7236921191215515,
      "learning_rate": 1.373008434864105e-05,
      "loss": 1.3845,
      "step": 11050
    },
    {
      "epoch": 1.7299281474539208,
      "grad_norm": 0.7082531452178955,
      "learning_rate": 1.3534832864729773e-05,
      "loss": 1.3466,
      "step": 11075
    },
    {
      "epoch": 1.7338331771321462,
      "grad_norm": 0.8667230606079102,
      "learning_rate": 1.3339581380818495e-05,
      "loss": 1.3586,
      "step": 11100
    },
    {
      "epoch": 1.7377382068103717,
      "grad_norm": 0.9191804528236389,
      "learning_rate": 1.3144329896907218e-05,
      "loss": 1.3528,
      "step": 11125
    },
    {
      "epoch": 1.7416432364885974,
      "grad_norm": 0.9565922617912292,
      "learning_rate": 1.2949078412995937e-05,
      "loss": 1.3345,
      "step": 11150
    },
    {
      "epoch": 1.745548266166823,
      "grad_norm": 0.8687381744384766,
      "learning_rate": 1.275382692908466e-05,
      "loss": 1.3377,
      "step": 11175
    },
    {
      "epoch": 1.7494532958450484,
      "grad_norm": 0.7679663896560669,
      "learning_rate": 1.2558575445173385e-05,
      "loss": 1.3837,
      "step": 11200
    },
    {
      "epoch": 1.753358325523274,
      "grad_norm": 0.8074920177459717,
      "learning_rate": 1.2363323961262107e-05,
      "loss": 1.3534,
      "step": 11225
    },
    {
      "epoch": 1.7572633552014996,
      "grad_norm": 0.7949455976486206,
      "learning_rate": 1.2168072477350828e-05,
      "loss": 1.3836,
      "step": 11250
    },
    {
      "epoch": 1.761168384879725,
      "grad_norm": 0.8258870244026184,
      "learning_rate": 1.1972820993439551e-05,
      "loss": 1.3543,
      "step": 11275
    },
    {
      "epoch": 1.7650734145579507,
      "grad_norm": 0.7055574059486389,
      "learning_rate": 1.1777569509528272e-05,
      "loss": 1.3026,
      "step": 11300
    },
    {
      "epoch": 1.7689784442361762,
      "grad_norm": 0.9045096635818481,
      "learning_rate": 1.1582318025616995e-05,
      "loss": 1.3732,
      "step": 11325
    },
    {
      "epoch": 1.7728834739144017,
      "grad_norm": 1.18605637550354,
      "learning_rate": 1.1387066541705718e-05,
      "loss": 1.3378,
      "step": 11350
    },
    {
      "epoch": 1.7767885035926274,
      "grad_norm": 0.8408441543579102,
      "learning_rate": 1.119181505779444e-05,
      "loss": 1.4203,
      "step": 11375
    },
    {
      "epoch": 1.780693533270853,
      "grad_norm": 0.5422136187553406,
      "learning_rate": 1.0996563573883161e-05,
      "loss": 1.3323,
      "step": 11400
    },
    {
      "epoch": 1.7845985629490784,
      "grad_norm": 0.6522179841995239,
      "learning_rate": 1.0801312089971884e-05,
      "loss": 1.3481,
      "step": 11425
    },
    {
      "epoch": 1.788503592627304,
      "grad_norm": 0.6663833856582642,
      "learning_rate": 1.0606060606060607e-05,
      "loss": 1.3149,
      "step": 11450
    },
    {
      "epoch": 1.7924086223055296,
      "grad_norm": 0.6988307237625122,
      "learning_rate": 1.0410809122149329e-05,
      "loss": 1.3365,
      "step": 11475
    },
    {
      "epoch": 1.796313651983755,
      "grad_norm": 0.7961581349372864,
      "learning_rate": 1.021555763823805e-05,
      "loss": 1.3669,
      "step": 11500
    },
    {
      "epoch": 1.8002186816619807,
      "grad_norm": 0.9078136682510376,
      "learning_rate": 1.0020306154326773e-05,
      "loss": 1.3197,
      "step": 11525
    },
    {
      "epoch": 1.8041237113402062,
      "grad_norm": 0.6752046346664429,
      "learning_rate": 9.825054670415496e-06,
      "loss": 1.3774,
      "step": 11550
    },
    {
      "epoch": 1.8080287410184317,
      "grad_norm": 1.0643398761749268,
      "learning_rate": 9.629803186504218e-06,
      "loss": 1.3394,
      "step": 11575
    },
    {
      "epoch": 1.8119337706966574,
      "grad_norm": 0.7834459543228149,
      "learning_rate": 9.43455170259294e-06,
      "loss": 1.3263,
      "step": 11600
    },
    {
      "epoch": 1.8158388003748829,
      "grad_norm": 1.1990642547607422,
      "learning_rate": 9.239300218681662e-06,
      "loss": 1.4201,
      "step": 11625
    },
    {
      "epoch": 1.8197438300531084,
      "grad_norm": 1.00058913230896,
      "learning_rate": 9.044048734770385e-06,
      "loss": 1.3515,
      "step": 11650
    },
    {
      "epoch": 1.823648859731334,
      "grad_norm": 0.6796801090240479,
      "learning_rate": 8.848797250859108e-06,
      "loss": 1.3567,
      "step": 11675
    },
    {
      "epoch": 1.8275538894095595,
      "grad_norm": 0.5703482031822205,
      "learning_rate": 8.65354576694783e-06,
      "loss": 1.3142,
      "step": 11700
    },
    {
      "epoch": 1.831458919087785,
      "grad_norm": 0.7782943844795227,
      "learning_rate": 8.45829428303655e-06,
      "loss": 1.3286,
      "step": 11725
    },
    {
      "epoch": 1.8353639487660107,
      "grad_norm": 0.9680484533309937,
      "learning_rate": 8.263042799125274e-06,
      "loss": 1.3449,
      "step": 11750
    },
    {
      "epoch": 1.8392689784442362,
      "grad_norm": 1.0061954259872437,
      "learning_rate": 8.067791315213997e-06,
      "loss": 1.3895,
      "step": 11775
    },
    {
      "epoch": 1.8431740081224617,
      "grad_norm": 1.0677402019500732,
      "learning_rate": 7.872539831302718e-06,
      "loss": 1.3706,
      "step": 11800
    },
    {
      "epoch": 1.8470790378006874,
      "grad_norm": 0.8281382918357849,
      "learning_rate": 7.677288347391441e-06,
      "loss": 1.3701,
      "step": 11825
    },
    {
      "epoch": 1.8509840674789129,
      "grad_norm": 0.81825852394104,
      "learning_rate": 7.482036863480163e-06,
      "loss": 1.3598,
      "step": 11850
    },
    {
      "epoch": 1.8548890971571383,
      "grad_norm": 0.8646783232688904,
      "learning_rate": 7.286785379568885e-06,
      "loss": 1.3657,
      "step": 11875
    },
    {
      "epoch": 1.858794126835364,
      "grad_norm": 0.6419709920883179,
      "learning_rate": 7.091533895657608e-06,
      "loss": 1.3416,
      "step": 11900
    },
    {
      "epoch": 1.8626991565135895,
      "grad_norm": 0.6792585253715515,
      "learning_rate": 6.89628241174633e-06,
      "loss": 1.3184,
      "step": 11925
    },
    {
      "epoch": 1.866604186191815,
      "grad_norm": 0.9182591438293457,
      "learning_rate": 6.701030927835052e-06,
      "loss": 1.3298,
      "step": 11950
    },
    {
      "epoch": 1.8705092158700407,
      "grad_norm": 0.7097083926200867,
      "learning_rate": 6.505779443923774e-06,
      "loss": 1.3184,
      "step": 11975
    },
    {
      "epoch": 1.8744142455482662,
      "grad_norm": 0.7960913181304932,
      "learning_rate": 6.310527960012497e-06,
      "loss": 1.3158,
      "step": 12000
    },
    {
      "epoch": 1.8744142455482662,
      "eval_loss": 1.357531189918518,
      "eval_runtime": 1635.0422,
      "eval_samples_per_second": 6.265,
      "eval_steps_per_second": 6.265,
      "step": 12000
    },
    {
      "epoch": 1.8783192752264917,
      "grad_norm": 0.8219979405403137,
      "learning_rate": 6.115276476101218e-06,
      "loss": 1.3697,
      "step": 12025
    },
    {
      "epoch": 1.8822243049047174,
      "grad_norm": 1.0766667127609253,
      "learning_rate": 5.920024992189941e-06,
      "loss": 1.3249,
      "step": 12050
    },
    {
      "epoch": 1.8861293345829429,
      "grad_norm": 1.1119651794433594,
      "learning_rate": 5.724773508278663e-06,
      "loss": 1.3999,
      "step": 12075
    },
    {
      "epoch": 1.8900343642611683,
      "grad_norm": 1.1348328590393066,
      "learning_rate": 5.529522024367386e-06,
      "loss": 1.3693,
      "step": 12100
    },
    {
      "epoch": 1.893939393939394,
      "grad_norm": 0.9494262337684631,
      "learning_rate": 5.334270540456108e-06,
      "loss": 1.3452,
      "step": 12125
    },
    {
      "epoch": 1.8978444236176195,
      "grad_norm": 0.8339325189590454,
      "learning_rate": 5.139019056544829e-06,
      "loss": 1.3896,
      "step": 12150
    },
    {
      "epoch": 1.901749453295845,
      "grad_norm": 1.0635807514190674,
      "learning_rate": 4.943767572633552e-06,
      "loss": 1.2873,
      "step": 12175
    },
    {
      "epoch": 1.9056544829740707,
      "grad_norm": 1.001002550125122,
      "learning_rate": 4.748516088722275e-06,
      "loss": 1.3604,
      "step": 12200
    },
    {
      "epoch": 1.9095595126522962,
      "grad_norm": 1.145897388458252,
      "learning_rate": 4.553264604810997e-06,
      "loss": 1.3658,
      "step": 12225
    },
    {
      "epoch": 1.9134645423305217,
      "grad_norm": 1.126111388206482,
      "learning_rate": 4.358013120899719e-06,
      "loss": 1.356,
      "step": 12250
    },
    {
      "epoch": 1.9173695720087474,
      "grad_norm": 0.6927289366722107,
      "learning_rate": 4.162761636988441e-06,
      "loss": 1.3122,
      "step": 12275
    },
    {
      "epoch": 1.9212746016869728,
      "grad_norm": 0.9078302383422852,
      "learning_rate": 3.9675101530771634e-06,
      "loss": 1.3404,
      "step": 12300
    },
    {
      "epoch": 1.9251796313651983,
      "grad_norm": 1.009809970855713,
      "learning_rate": 3.772258669165886e-06,
      "loss": 1.3016,
      "step": 12325
    },
    {
      "epoch": 1.929084661043424,
      "grad_norm": 0.7213473320007324,
      "learning_rate": 3.577007185254608e-06,
      "loss": 1.3542,
      "step": 12350
    },
    {
      "epoch": 1.9329896907216495,
      "grad_norm": 1.0267682075500488,
      "learning_rate": 3.38175570134333e-06,
      "loss": 1.39,
      "step": 12375
    },
    {
      "epoch": 1.936894720399875,
      "grad_norm": 0.6322237253189087,
      "learning_rate": 3.1865042174320527e-06,
      "loss": 1.3587,
      "step": 12400
    },
    {
      "epoch": 1.9407997500781007,
      "grad_norm": 0.4952605962753296,
      "learning_rate": 2.991252733520775e-06,
      "loss": 1.3638,
      "step": 12425
    },
    {
      "epoch": 1.9447047797563262,
      "grad_norm": 0.893375039100647,
      "learning_rate": 2.8038113089659484e-06,
      "loss": 1.3612,
      "step": 12450
    },
    {
      "epoch": 1.9486098094345516,
      "grad_norm": 0.6410025954246521,
      "learning_rate": 2.6085598250546702e-06,
      "loss": 1.3878,
      "step": 12475
    },
    {
      "epoch": 1.9525148391127773,
      "grad_norm": 0.6571201682090759,
      "learning_rate": 2.413308341143393e-06,
      "loss": 1.3602,
      "step": 12500
    },
    {
      "epoch": 1.9564198687910028,
      "grad_norm": 0.5807616114616394,
      "learning_rate": 2.218056857232115e-06,
      "loss": 1.3254,
      "step": 12525
    },
    {
      "epoch": 1.9603248984692283,
      "grad_norm": 0.7779384255409241,
      "learning_rate": 2.0228053733208373e-06,
      "loss": 1.3305,
      "step": 12550
    },
    {
      "epoch": 1.964229928147454,
      "grad_norm": 0.7653586864471436,
      "learning_rate": 1.8275538894095595e-06,
      "loss": 1.2868,
      "step": 12575
    },
    {
      "epoch": 1.9681349578256795,
      "grad_norm": 0.8925297260284424,
      "learning_rate": 1.632302405498282e-06,
      "loss": 1.3258,
      "step": 12600
    },
    {
      "epoch": 1.972039987503905,
      "grad_norm": 0.7617678642272949,
      "learning_rate": 1.4370509215870041e-06,
      "loss": 1.3086,
      "step": 12625
    },
    {
      "epoch": 1.9759450171821307,
      "grad_norm": 0.8036205768585205,
      "learning_rate": 1.2417994376757266e-06,
      "loss": 1.3318,
      "step": 12650
    },
    {
      "epoch": 1.9798500468603561,
      "grad_norm": 0.7145025730133057,
      "learning_rate": 1.0465479537644486e-06,
      "loss": 1.2871,
      "step": 12675
    },
    {
      "epoch": 1.9837550765385816,
      "grad_norm": 1.3601382970809937,
      "learning_rate": 8.51296469853171e-07,
      "loss": 1.3588,
      "step": 12700
    },
    {
      "epoch": 1.9876601062168073,
      "grad_norm": 0.6604810953140259,
      "learning_rate": 6.560449859418932e-07,
      "loss": 1.3382,
      "step": 12725
    },
    {
      "epoch": 1.9915651358950328,
      "grad_norm": 0.7752665281295776,
      "learning_rate": 4.607935020306154e-07,
      "loss": 1.338,
      "step": 12750
    },
    {
      "epoch": 1.9954701655732583,
      "grad_norm": 0.9869459867477417,
      "learning_rate": 2.655420181193377e-07,
      "loss": 1.3991,
      "step": 12775
    },
    {
      "epoch": 1.999375195251484,
      "grad_norm": 0.8886002898216248,
      "learning_rate": 7.029053420805999e-08,
      "loss": 1.347,
      "step": 12800
    }
  ],
  "logging_steps": 25,
  "max_steps": 12804,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.31708731537254e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
