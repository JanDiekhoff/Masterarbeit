{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9999218933062564,
  "eval_steps": 1000,
  "global_step": 12802,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0039053346871826917,
      "grad_norm": 3.2465217113494873,
      "learning_rate": 9.9609436025621e-05,
      "loss": 2.1021,
      "step": 25
    },
    {
      "epoch": 0.007810669374365383,
      "grad_norm": 1.1683964729309082,
      "learning_rate": 9.921887205124199e-05,
      "loss": 1.6778,
      "step": 50
    },
    {
      "epoch": 0.011716004061548074,
      "grad_norm": 1.0458828210830688,
      "learning_rate": 9.8828308076863e-05,
      "loss": 1.6162,
      "step": 75
    },
    {
      "epoch": 0.015621338748730767,
      "grad_norm": 1.1215345859527588,
      "learning_rate": 9.843774410248398e-05,
      "loss": 1.5214,
      "step": 100
    },
    {
      "epoch": 0.01952667343591346,
      "grad_norm": 0.8124238848686218,
      "learning_rate": 9.804718012810498e-05,
      "loss": 1.551,
      "step": 125
    },
    {
      "epoch": 0.02343200812309615,
      "grad_norm": 1.1576467752456665,
      "learning_rate": 9.765661615372598e-05,
      "loss": 1.5233,
      "step": 150
    },
    {
      "epoch": 0.02733734281027884,
      "grad_norm": 0.9178279042243958,
      "learning_rate": 9.726605217934698e-05,
      "loss": 1.4985,
      "step": 175
    },
    {
      "epoch": 0.031242677497461534,
      "grad_norm": 0.9064067602157593,
      "learning_rate": 9.687548820496799e-05,
      "loss": 1.5261,
      "step": 200
    },
    {
      "epoch": 0.03514801218464422,
      "grad_norm": 0.9114634394645691,
      "learning_rate": 9.648492423058899e-05,
      "loss": 1.4715,
      "step": 225
    },
    {
      "epoch": 0.03905334687182692,
      "grad_norm": 1.2622907161712646,
      "learning_rate": 9.609436025620997e-05,
      "loss": 1.5396,
      "step": 250
    },
    {
      "epoch": 0.04295868155900961,
      "grad_norm": 1.2203083038330078,
      "learning_rate": 9.570379628183097e-05,
      "loss": 1.4599,
      "step": 275
    },
    {
      "epoch": 0.0468640162461923,
      "grad_norm": 1.0415164232254028,
      "learning_rate": 9.531323230745196e-05,
      "loss": 1.4784,
      "step": 300
    },
    {
      "epoch": 0.05076935093337499,
      "grad_norm": 1.1780155897140503,
      "learning_rate": 9.492266833307296e-05,
      "loss": 1.4008,
      "step": 325
    },
    {
      "epoch": 0.05467468562055768,
      "grad_norm": 0.9165364503860474,
      "learning_rate": 9.453210435869396e-05,
      "loss": 1.38,
      "step": 350
    },
    {
      "epoch": 0.05858002030774037,
      "grad_norm": 1.247885823249817,
      "learning_rate": 9.414154038431495e-05,
      "loss": 1.4829,
      "step": 375
    },
    {
      "epoch": 0.06248535499492307,
      "grad_norm": 0.8763705492019653,
      "learning_rate": 9.375097640993595e-05,
      "loss": 1.4248,
      "step": 400
    },
    {
      "epoch": 0.06639068968210575,
      "grad_norm": 1.141935110092163,
      "learning_rate": 9.336041243555694e-05,
      "loss": 1.4143,
      "step": 425
    },
    {
      "epoch": 0.07029602436928845,
      "grad_norm": 0.7177324891090393,
      "learning_rate": 9.296984846117794e-05,
      "loss": 1.4389,
      "step": 450
    },
    {
      "epoch": 0.07420135905647114,
      "grad_norm": 0.8669571876525879,
      "learning_rate": 9.257928448679894e-05,
      "loss": 1.391,
      "step": 475
    },
    {
      "epoch": 0.07810669374365384,
      "grad_norm": 1.1431673765182495,
      "learning_rate": 9.218872051241993e-05,
      "loss": 1.427,
      "step": 500
    },
    {
      "epoch": 0.08201202843083652,
      "grad_norm": 0.8612999320030212,
      "learning_rate": 9.179815653804093e-05,
      "loss": 1.4743,
      "step": 525
    },
    {
      "epoch": 0.08591736311801922,
      "grad_norm": 0.7818436622619629,
      "learning_rate": 9.140759256366193e-05,
      "loss": 1.4884,
      "step": 550
    },
    {
      "epoch": 0.08982269780520191,
      "grad_norm": 0.7049092650413513,
      "learning_rate": 9.101702858928293e-05,
      "loss": 1.4361,
      "step": 575
    },
    {
      "epoch": 0.0937280324923846,
      "grad_norm": 0.9018144011497498,
      "learning_rate": 9.062646461490393e-05,
      "loss": 1.4553,
      "step": 600
    },
    {
      "epoch": 0.09763336717956729,
      "grad_norm": 1.1254284381866455,
      "learning_rate": 9.023590064052492e-05,
      "loss": 1.4594,
      "step": 625
    },
    {
      "epoch": 0.10153870186674999,
      "grad_norm": 0.8887649178504944,
      "learning_rate": 8.984533666614592e-05,
      "loss": 1.5094,
      "step": 650
    },
    {
      "epoch": 0.10544403655393267,
      "grad_norm": 0.8469434380531311,
      "learning_rate": 8.945477269176692e-05,
      "loss": 1.4282,
      "step": 675
    },
    {
      "epoch": 0.10934937124111536,
      "grad_norm": 0.8114902973175049,
      "learning_rate": 8.906420871738791e-05,
      "loss": 1.4451,
      "step": 700
    },
    {
      "epoch": 0.11325470592829806,
      "grad_norm": 1.1834198236465454,
      "learning_rate": 8.867364474300891e-05,
      "loss": 1.4714,
      "step": 725
    },
    {
      "epoch": 0.11716004061548074,
      "grad_norm": 0.8823350667953491,
      "learning_rate": 8.828308076862991e-05,
      "loss": 1.4202,
      "step": 750
    },
    {
      "epoch": 0.12106537530266344,
      "grad_norm": 0.7953850030899048,
      "learning_rate": 8.78925167942509e-05,
      "loss": 1.4129,
      "step": 775
    },
    {
      "epoch": 0.12497070998984613,
      "grad_norm": 0.7873246073722839,
      "learning_rate": 8.75019528198719e-05,
      "loss": 1.4156,
      "step": 800
    },
    {
      "epoch": 0.12887604467702882,
      "grad_norm": 0.6885635852813721,
      "learning_rate": 8.711138884549289e-05,
      "loss": 1.4368,
      "step": 825
    },
    {
      "epoch": 0.1327813793642115,
      "grad_norm": 1.1447787284851074,
      "learning_rate": 8.672082487111389e-05,
      "loss": 1.4678,
      "step": 850
    },
    {
      "epoch": 0.1366867140513942,
      "grad_norm": 0.9177465438842773,
      "learning_rate": 8.633026089673489e-05,
      "loss": 1.3658,
      "step": 875
    },
    {
      "epoch": 0.1405920487385769,
      "grad_norm": 1.0802029371261597,
      "learning_rate": 8.593969692235589e-05,
      "loss": 1.3807,
      "step": 900
    },
    {
      "epoch": 0.1444973834257596,
      "grad_norm": 0.7436348795890808,
      "learning_rate": 8.554913294797689e-05,
      "loss": 1.4801,
      "step": 925
    },
    {
      "epoch": 0.14840271811294228,
      "grad_norm": 0.8422478437423706,
      "learning_rate": 8.515856897359788e-05,
      "loss": 1.4181,
      "step": 950
    },
    {
      "epoch": 0.15230805280012497,
      "grad_norm": 0.714457631111145,
      "learning_rate": 8.476800499921888e-05,
      "loss": 1.425,
      "step": 975
    },
    {
      "epoch": 0.15621338748730768,
      "grad_norm": 0.7346399426460266,
      "learning_rate": 8.437744102483988e-05,
      "loss": 1.4406,
      "step": 1000
    },
    {
      "epoch": 0.15621338748730768,
      "eval_loss": 1.4085553884506226,
      "eval_runtime": 1621.4977,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 1000
    },
    {
      "epoch": 0.16011872217449036,
      "grad_norm": 0.7755522131919861,
      "learning_rate": 8.398687705046087e-05,
      "loss": 1.497,
      "step": 1025
    },
    {
      "epoch": 0.16402405686167304,
      "grad_norm": 0.7198747992515564,
      "learning_rate": 8.359631307608187e-05,
      "loss": 1.3876,
      "step": 1050
    },
    {
      "epoch": 0.16792939154885575,
      "grad_norm": 0.7547372579574585,
      "learning_rate": 8.320574910170287e-05,
      "loss": 1.4114,
      "step": 1075
    },
    {
      "epoch": 0.17183472623603843,
      "grad_norm": 0.7939823269844055,
      "learning_rate": 8.281518512732386e-05,
      "loss": 1.3696,
      "step": 1100
    },
    {
      "epoch": 0.17574006092322111,
      "grad_norm": 0.880377471446991,
      "learning_rate": 8.242462115294486e-05,
      "loss": 1.4274,
      "step": 1125
    },
    {
      "epoch": 0.17964539561040382,
      "grad_norm": 1.1362334489822388,
      "learning_rate": 8.203405717856584e-05,
      "loss": 1.4381,
      "step": 1150
    },
    {
      "epoch": 0.1835507302975865,
      "grad_norm": 1.0400172472000122,
      "learning_rate": 8.164349320418685e-05,
      "loss": 1.3768,
      "step": 1175
    },
    {
      "epoch": 0.1874560649847692,
      "grad_norm": 0.9381090402603149,
      "learning_rate": 8.125292922980785e-05,
      "loss": 1.3723,
      "step": 1200
    },
    {
      "epoch": 0.1913613996719519,
      "grad_norm": 0.6042956113815308,
      "learning_rate": 8.086236525542883e-05,
      "loss": 1.4514,
      "step": 1225
    },
    {
      "epoch": 0.19526673435913458,
      "grad_norm": 0.8863415122032166,
      "learning_rate": 8.047180128104984e-05,
      "loss": 1.4024,
      "step": 1250
    },
    {
      "epoch": 0.19917206904631726,
      "grad_norm": 0.8462222814559937,
      "learning_rate": 8.008123730667084e-05,
      "loss": 1.443,
      "step": 1275
    },
    {
      "epoch": 0.20307740373349997,
      "grad_norm": 0.6853643655776978,
      "learning_rate": 7.969067333229184e-05,
      "loss": 1.3688,
      "step": 1300
    },
    {
      "epoch": 0.20698273842068265,
      "grad_norm": 1.452087163925171,
      "learning_rate": 7.930010935791284e-05,
      "loss": 1.3644,
      "step": 1325
    },
    {
      "epoch": 0.21088807310786534,
      "grad_norm": 0.9469685554504395,
      "learning_rate": 7.890954538353383e-05,
      "loss": 1.4085,
      "step": 1350
    },
    {
      "epoch": 0.21479340779504805,
      "grad_norm": 0.8635916709899902,
      "learning_rate": 7.851898140915483e-05,
      "loss": 1.4282,
      "step": 1375
    },
    {
      "epoch": 0.21869874248223073,
      "grad_norm": 0.819979727268219,
      "learning_rate": 7.812841743477583e-05,
      "loss": 1.4151,
      "step": 1400
    },
    {
      "epoch": 0.2226040771694134,
      "grad_norm": 0.6791641116142273,
      "learning_rate": 7.773785346039681e-05,
      "loss": 1.4202,
      "step": 1425
    },
    {
      "epoch": 0.22650941185659612,
      "grad_norm": 0.9602513909339905,
      "learning_rate": 7.734728948601782e-05,
      "loss": 1.3821,
      "step": 1450
    },
    {
      "epoch": 0.2304147465437788,
      "grad_norm": 0.9818315505981445,
      "learning_rate": 7.69567255116388e-05,
      "loss": 1.4221,
      "step": 1475
    },
    {
      "epoch": 0.23432008123096149,
      "grad_norm": 0.883847177028656,
      "learning_rate": 7.65661615372598e-05,
      "loss": 1.3867,
      "step": 1500
    },
    {
      "epoch": 0.2382254159181442,
      "grad_norm": 0.8888888955116272,
      "learning_rate": 7.61755975628808e-05,
      "loss": 1.4057,
      "step": 1525
    },
    {
      "epoch": 0.24213075060532688,
      "grad_norm": 0.791121780872345,
      "learning_rate": 7.578503358850179e-05,
      "loss": 1.3807,
      "step": 1550
    },
    {
      "epoch": 0.24603608529250956,
      "grad_norm": 0.6994274854660034,
      "learning_rate": 7.539446961412279e-05,
      "loss": 1.3847,
      "step": 1575
    },
    {
      "epoch": 0.24994141997969227,
      "grad_norm": 0.8135121464729309,
      "learning_rate": 7.50039056397438e-05,
      "loss": 1.4215,
      "step": 1600
    },
    {
      "epoch": 0.25384675466687495,
      "grad_norm": 0.6589803099632263,
      "learning_rate": 7.46133416653648e-05,
      "loss": 1.3883,
      "step": 1625
    },
    {
      "epoch": 0.25775208935405763,
      "grad_norm": 0.7393799424171448,
      "learning_rate": 7.42227776909858e-05,
      "loss": 1.4246,
      "step": 1650
    },
    {
      "epoch": 0.2616574240412403,
      "grad_norm": 0.8831437230110168,
      "learning_rate": 7.383221371660678e-05,
      "loss": 1.3648,
      "step": 1675
    },
    {
      "epoch": 0.265562758728423,
      "grad_norm": 0.920042097568512,
      "learning_rate": 7.344164974222778e-05,
      "loss": 1.3967,
      "step": 1700
    },
    {
      "epoch": 0.26946809341560574,
      "grad_norm": 0.885888934135437,
      "learning_rate": 7.305108576784879e-05,
      "loss": 1.3872,
      "step": 1725
    },
    {
      "epoch": 0.2733734281027884,
      "grad_norm": 1.0735024213790894,
      "learning_rate": 7.266052179346977e-05,
      "loss": 1.3957,
      "step": 1750
    },
    {
      "epoch": 0.2772787627899711,
      "grad_norm": 0.9115954637527466,
      "learning_rate": 7.226995781909077e-05,
      "loss": 1.3945,
      "step": 1775
    },
    {
      "epoch": 0.2811840974771538,
      "grad_norm": 0.8568029403686523,
      "learning_rate": 7.187939384471176e-05,
      "loss": 1.3863,
      "step": 1800
    },
    {
      "epoch": 0.28508943216433646,
      "grad_norm": 0.6662747263908386,
      "learning_rate": 7.148882987033276e-05,
      "loss": 1.4811,
      "step": 1825
    },
    {
      "epoch": 0.2889947668515192,
      "grad_norm": 1.1174888610839844,
      "learning_rate": 7.109826589595376e-05,
      "loss": 1.3925,
      "step": 1850
    },
    {
      "epoch": 0.2929001015387019,
      "grad_norm": 0.8547325730323792,
      "learning_rate": 7.070770192157475e-05,
      "loss": 1.3573,
      "step": 1875
    },
    {
      "epoch": 0.29680543622588457,
      "grad_norm": 0.8674880266189575,
      "learning_rate": 7.031713794719575e-05,
      "loss": 1.3931,
      "step": 1900
    },
    {
      "epoch": 0.30071077091306725,
      "grad_norm": 0.9799916744232178,
      "learning_rate": 6.992657397281675e-05,
      "loss": 1.435,
      "step": 1925
    },
    {
      "epoch": 0.30461610560024993,
      "grad_norm": 0.8731327056884766,
      "learning_rate": 6.953600999843774e-05,
      "loss": 1.4106,
      "step": 1950
    },
    {
      "epoch": 0.3085214402874326,
      "grad_norm": 0.9855532646179199,
      "learning_rate": 6.914544602405874e-05,
      "loss": 1.443,
      "step": 1975
    },
    {
      "epoch": 0.31242677497461535,
      "grad_norm": 1.0308401584625244,
      "learning_rate": 6.875488204967974e-05,
      "loss": 1.3588,
      "step": 2000
    },
    {
      "epoch": 0.31242677497461535,
      "eval_loss": 1.3906242847442627,
      "eval_runtime": 1621.4924,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 2000
    },
    {
      "epoch": 0.31633210966179803,
      "grad_norm": 0.7043284177780151,
      "learning_rate": 6.836431807530074e-05,
      "loss": 1.4098,
      "step": 2025
    },
    {
      "epoch": 0.3202374443489807,
      "grad_norm": 1.2149544954299927,
      "learning_rate": 6.797375410092174e-05,
      "loss": 1.3782,
      "step": 2050
    },
    {
      "epoch": 0.3241427790361634,
      "grad_norm": 0.6752206683158875,
      "learning_rate": 6.758319012654273e-05,
      "loss": 1.3926,
      "step": 2075
    },
    {
      "epoch": 0.3280481137233461,
      "grad_norm": 0.8697562217712402,
      "learning_rate": 6.719262615216373e-05,
      "loss": 1.4171,
      "step": 2100
    },
    {
      "epoch": 0.33195344841052876,
      "grad_norm": 0.8683820962905884,
      "learning_rate": 6.680206217778472e-05,
      "loss": 1.3641,
      "step": 2125
    },
    {
      "epoch": 0.3358587830977115,
      "grad_norm": 0.9228382110595703,
      "learning_rate": 6.641149820340572e-05,
      "loss": 1.3736,
      "step": 2150
    },
    {
      "epoch": 0.3397641177848942,
      "grad_norm": 0.7752336859703064,
      "learning_rate": 6.602093422902672e-05,
      "loss": 1.386,
      "step": 2175
    },
    {
      "epoch": 0.34366945247207686,
      "grad_norm": 0.7451473474502563,
      "learning_rate": 6.563037025464771e-05,
      "loss": 1.431,
      "step": 2200
    },
    {
      "epoch": 0.34757478715925955,
      "grad_norm": 0.9055505990982056,
      "learning_rate": 6.523980628026871e-05,
      "loss": 1.4389,
      "step": 2225
    },
    {
      "epoch": 0.35148012184644223,
      "grad_norm": 0.9343944787979126,
      "learning_rate": 6.484924230588971e-05,
      "loss": 1.373,
      "step": 2250
    },
    {
      "epoch": 0.3553854565336249,
      "grad_norm": 0.8370698094367981,
      "learning_rate": 6.44586783315107e-05,
      "loss": 1.4104,
      "step": 2275
    },
    {
      "epoch": 0.35929079122080765,
      "grad_norm": 0.6486676931381226,
      "learning_rate": 6.40681143571317e-05,
      "loss": 1.4103,
      "step": 2300
    },
    {
      "epoch": 0.36319612590799033,
      "grad_norm": 1.0935900211334229,
      "learning_rate": 6.369317294172786e-05,
      "loss": 1.4174,
      "step": 2325
    },
    {
      "epoch": 0.367101460595173,
      "grad_norm": 0.8440026640892029,
      "learning_rate": 6.330260896734885e-05,
      "loss": 1.3951,
      "step": 2350
    },
    {
      "epoch": 0.3710067952823557,
      "grad_norm": 0.8636385202407837,
      "learning_rate": 6.291204499296985e-05,
      "loss": 1.3864,
      "step": 2375
    },
    {
      "epoch": 0.3749121299695384,
      "grad_norm": 1.0544004440307617,
      "learning_rate": 6.252148101859084e-05,
      "loss": 1.4254,
      "step": 2400
    },
    {
      "epoch": 0.37881746465672106,
      "grad_norm": 1.2913252115249634,
      "learning_rate": 6.213091704421184e-05,
      "loss": 1.4154,
      "step": 2425
    },
    {
      "epoch": 0.3827227993439038,
      "grad_norm": 0.9033505916595459,
      "learning_rate": 6.174035306983284e-05,
      "loss": 1.4078,
      "step": 2450
    },
    {
      "epoch": 0.3866281340310865,
      "grad_norm": 1.5760395526885986,
      "learning_rate": 6.134978909545384e-05,
      "loss": 1.4163,
      "step": 2475
    },
    {
      "epoch": 0.39053346871826916,
      "grad_norm": 0.8405604958534241,
      "learning_rate": 6.0959225121074834e-05,
      "loss": 1.3473,
      "step": 2500
    },
    {
      "epoch": 0.39443880340545184,
      "grad_norm": 1.1086634397506714,
      "learning_rate": 6.056866114669583e-05,
      "loss": 1.3528,
      "step": 2525
    },
    {
      "epoch": 0.3983441380926345,
      "grad_norm": 0.8433387875556946,
      "learning_rate": 6.017809717231683e-05,
      "loss": 1.448,
      "step": 2550
    },
    {
      "epoch": 0.4022494727798172,
      "grad_norm": 0.8500542640686035,
      "learning_rate": 5.978753319793783e-05,
      "loss": 1.4054,
      "step": 2575
    },
    {
      "epoch": 0.40615480746699995,
      "grad_norm": 0.860120415687561,
      "learning_rate": 5.939696922355882e-05,
      "loss": 1.4298,
      "step": 2600
    },
    {
      "epoch": 0.4100601421541826,
      "grad_norm": 0.688825249671936,
      "learning_rate": 5.900640524917982e-05,
      "loss": 1.385,
      "step": 2625
    },
    {
      "epoch": 0.4139654768413653,
      "grad_norm": 0.8465675115585327,
      "learning_rate": 5.861584127480082e-05,
      "loss": 1.3763,
      "step": 2650
    },
    {
      "epoch": 0.417870811528548,
      "grad_norm": 1.2347468137741089,
      "learning_rate": 5.822527730042181e-05,
      "loss": 1.3925,
      "step": 2675
    },
    {
      "epoch": 0.4217761462157307,
      "grad_norm": 1.2148834466934204,
      "learning_rate": 5.783471332604281e-05,
      "loss": 1.3894,
      "step": 2700
    },
    {
      "epoch": 0.42568148090291336,
      "grad_norm": 0.8276163339614868,
      "learning_rate": 5.74441493516638e-05,
      "loss": 1.3941,
      "step": 2725
    },
    {
      "epoch": 0.4295868155900961,
      "grad_norm": 0.7274352312088013,
      "learning_rate": 5.70535853772848e-05,
      "loss": 1.4233,
      "step": 2750
    },
    {
      "epoch": 0.4334921502772788,
      "grad_norm": 0.8085888624191284,
      "learning_rate": 5.6663021402905804e-05,
      "loss": 1.3764,
      "step": 2775
    },
    {
      "epoch": 0.43739748496446146,
      "grad_norm": 0.8890697956085205,
      "learning_rate": 5.627245742852679e-05,
      "loss": 1.3698,
      "step": 2800
    },
    {
      "epoch": 0.44130281965164414,
      "grad_norm": 0.7871195077896118,
      "learning_rate": 5.588189345414779e-05,
      "loss": 1.4277,
      "step": 2825
    },
    {
      "epoch": 0.4452081543388268,
      "grad_norm": 0.7770936489105225,
      "learning_rate": 5.5491329479768787e-05,
      "loss": 1.3841,
      "step": 2850
    },
    {
      "epoch": 0.4491134890260095,
      "grad_norm": 0.7169707417488098,
      "learning_rate": 5.510076550538979e-05,
      "loss": 1.4128,
      "step": 2875
    },
    {
      "epoch": 0.45301882371319224,
      "grad_norm": 0.824567437171936,
      "learning_rate": 5.471020153101079e-05,
      "loss": 1.39,
      "step": 2900
    },
    {
      "epoch": 0.4569241584003749,
      "grad_norm": 0.7587940096855164,
      "learning_rate": 5.4319637556631776e-05,
      "loss": 1.3886,
      "step": 2925
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 0.9113674759864807,
      "learning_rate": 5.392907358225278e-05,
      "loss": 1.3662,
      "step": 2950
    },
    {
      "epoch": 0.4647348277747403,
      "grad_norm": 0.7056671380996704,
      "learning_rate": 5.353850960787378e-05,
      "loss": 1.3772,
      "step": 2975
    },
    {
      "epoch": 0.46864016246192297,
      "grad_norm": 1.3100237846374512,
      "learning_rate": 5.3147945633494765e-05,
      "loss": 1.3781,
      "step": 3000
    },
    {
      "epoch": 0.46864016246192297,
      "eval_loss": 1.3806625604629517,
      "eval_runtime": 1621.5533,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 3000
    },
    {
      "epoch": 0.47254549714910565,
      "grad_norm": 0.9259299635887146,
      "learning_rate": 5.2757381659115766e-05,
      "loss": 1.3941,
      "step": 3025
    },
    {
      "epoch": 0.4764508318362884,
      "grad_norm": 1.0350550413131714,
      "learning_rate": 5.236681768473676e-05,
      "loss": 1.3685,
      "step": 3050
    },
    {
      "epoch": 0.4803561665234711,
      "grad_norm": 0.7242240309715271,
      "learning_rate": 5.197625371035776e-05,
      "loss": 1.4776,
      "step": 3075
    },
    {
      "epoch": 0.48426150121065376,
      "grad_norm": 1.0832544565200806,
      "learning_rate": 5.158568973597876e-05,
      "loss": 1.4344,
      "step": 3100
    },
    {
      "epoch": 0.48816683589783644,
      "grad_norm": 0.7072556018829346,
      "learning_rate": 5.119512576159975e-05,
      "loss": 1.3611,
      "step": 3125
    },
    {
      "epoch": 0.4920721705850191,
      "grad_norm": 0.7741387486457825,
      "learning_rate": 5.080456178722075e-05,
      "loss": 1.3342,
      "step": 3150
    },
    {
      "epoch": 0.4959775052722018,
      "grad_norm": 0.7482285499572754,
      "learning_rate": 5.041399781284175e-05,
      "loss": 1.3706,
      "step": 3175
    },
    {
      "epoch": 0.49988283995938454,
      "grad_norm": 0.9397870302200317,
      "learning_rate": 5.002343383846274e-05,
      "loss": 1.3911,
      "step": 3200
    },
    {
      "epoch": 0.5037881746465672,
      "grad_norm": 1.3380074501037598,
      "learning_rate": 4.963286986408374e-05,
      "loss": 1.3817,
      "step": 3225
    },
    {
      "epoch": 0.5076935093337499,
      "grad_norm": 1.1256049871444702,
      "learning_rate": 4.924230588970474e-05,
      "loss": 1.3473,
      "step": 3250
    },
    {
      "epoch": 0.5115988440209326,
      "grad_norm": 0.8798999786376953,
      "learning_rate": 4.8851741915325735e-05,
      "loss": 1.4274,
      "step": 3275
    },
    {
      "epoch": 0.5155041787081153,
      "grad_norm": 0.7999401092529297,
      "learning_rate": 4.846117794094673e-05,
      "loss": 1.4047,
      "step": 3300
    },
    {
      "epoch": 0.519409513395298,
      "grad_norm": 0.6698806285858154,
      "learning_rate": 4.807061396656772e-05,
      "loss": 1.35,
      "step": 3325
    },
    {
      "epoch": 0.5233148480824806,
      "grad_norm": 0.8130303621292114,
      "learning_rate": 4.7680049992188724e-05,
      "loss": 1.4038,
      "step": 3350
    },
    {
      "epoch": 0.5272201827696633,
      "grad_norm": 1.296355128288269,
      "learning_rate": 4.728948601780972e-05,
      "loss": 1.3506,
      "step": 3375
    },
    {
      "epoch": 0.531125517456846,
      "grad_norm": 0.9970064759254456,
      "learning_rate": 4.689892204343071e-05,
      "loss": 1.4195,
      "step": 3400
    },
    {
      "epoch": 0.5350308521440288,
      "grad_norm": 0.8253654837608337,
      "learning_rate": 4.6508358069051713e-05,
      "loss": 1.3936,
      "step": 3425
    },
    {
      "epoch": 0.5389361868312115,
      "grad_norm": 1.8508747816085815,
      "learning_rate": 4.6117794094672714e-05,
      "loss": 1.4283,
      "step": 3450
    },
    {
      "epoch": 0.5428415215183942,
      "grad_norm": 0.7999590635299683,
      "learning_rate": 4.572723012029371e-05,
      "loss": 1.327,
      "step": 3475
    },
    {
      "epoch": 0.5467468562055768,
      "grad_norm": 0.7973755598068237,
      "learning_rate": 4.53366661459147e-05,
      "loss": 1.3583,
      "step": 3500
    },
    {
      "epoch": 0.5506521908927595,
      "grad_norm": 0.8767470121383667,
      "learning_rate": 4.49461021715357e-05,
      "loss": 1.4173,
      "step": 3525
    },
    {
      "epoch": 0.5545575255799422,
      "grad_norm": 0.8256537318229675,
      "learning_rate": 4.45555381971567e-05,
      "loss": 1.3849,
      "step": 3550
    },
    {
      "epoch": 0.5584628602671249,
      "grad_norm": 0.7352432012557983,
      "learning_rate": 4.416497422277769e-05,
      "loss": 1.3562,
      "step": 3575
    },
    {
      "epoch": 0.5623681949543076,
      "grad_norm": 0.7893133163452148,
      "learning_rate": 4.3774410248398686e-05,
      "loss": 1.3458,
      "step": 3600
    },
    {
      "epoch": 0.5662735296414902,
      "grad_norm": 0.6675043106079102,
      "learning_rate": 4.338384627401969e-05,
      "loss": 1.3503,
      "step": 3625
    },
    {
      "epoch": 0.5701788643286729,
      "grad_norm": 0.7892453670501709,
      "learning_rate": 4.299328229964069e-05,
      "loss": 1.4059,
      "step": 3650
    },
    {
      "epoch": 0.5740841990158556,
      "grad_norm": 1.0979344844818115,
      "learning_rate": 4.260271832526168e-05,
      "loss": 1.4222,
      "step": 3675
    },
    {
      "epoch": 0.5779895337030384,
      "grad_norm": 1.1182317733764648,
      "learning_rate": 4.2212154350882676e-05,
      "loss": 1.3518,
      "step": 3700
    },
    {
      "epoch": 0.5818948683902211,
      "grad_norm": 0.7349278330802917,
      "learning_rate": 4.182159037650367e-05,
      "loss": 1.3484,
      "step": 3725
    },
    {
      "epoch": 0.5858002030774038,
      "grad_norm": 0.9451165199279785,
      "learning_rate": 4.1431026402124665e-05,
      "loss": 1.3595,
      "step": 3750
    },
    {
      "epoch": 0.5897055377645865,
      "grad_norm": 0.8639544248580933,
      "learning_rate": 4.1040462427745666e-05,
      "loss": 1.3577,
      "step": 3775
    },
    {
      "epoch": 0.5936108724517691,
      "grad_norm": 0.7390472888946533,
      "learning_rate": 4.0649898453366667e-05,
      "loss": 1.3573,
      "step": 3800
    },
    {
      "epoch": 0.5975162071389518,
      "grad_norm": 0.9243931770324707,
      "learning_rate": 4.025933447898766e-05,
      "loss": 1.3918,
      "step": 3825
    },
    {
      "epoch": 0.6014215418261345,
      "grad_norm": 0.7551735043525696,
      "learning_rate": 3.9868770504608655e-05,
      "loss": 1.3817,
      "step": 3850
    },
    {
      "epoch": 0.6053268765133172,
      "grad_norm": 1.2113673686981201,
      "learning_rate": 3.9478206530229656e-05,
      "loss": 1.3977,
      "step": 3875
    },
    {
      "epoch": 0.6092322112004999,
      "grad_norm": 0.9740294814109802,
      "learning_rate": 3.908764255585065e-05,
      "loss": 1.3481,
      "step": 3900
    },
    {
      "epoch": 0.6131375458876825,
      "grad_norm": 0.6352384686470032,
      "learning_rate": 3.8697078581471644e-05,
      "loss": 1.3798,
      "step": 3925
    },
    {
      "epoch": 0.6170428805748652,
      "grad_norm": 0.992870569229126,
      "learning_rate": 3.830651460709264e-05,
      "loss": 1.4388,
      "step": 3950
    },
    {
      "epoch": 0.6209482152620479,
      "grad_norm": 0.7837244272232056,
      "learning_rate": 3.791595063271364e-05,
      "loss": 1.4264,
      "step": 3975
    },
    {
      "epoch": 0.6248535499492307,
      "grad_norm": 0.6938894391059875,
      "learning_rate": 3.752538665833464e-05,
      "loss": 1.3434,
      "step": 4000
    },
    {
      "epoch": 0.6248535499492307,
      "eval_loss": 1.374707818031311,
      "eval_runtime": 1621.4987,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 4000
    },
    {
      "epoch": 0.6287588846364134,
      "grad_norm": 0.7759961485862732,
      "learning_rate": 3.7134822683955634e-05,
      "loss": 1.3547,
      "step": 4025
    },
    {
      "epoch": 0.6326642193235961,
      "grad_norm": 1.0880918502807617,
      "learning_rate": 3.674425870957663e-05,
      "loss": 1.3858,
      "step": 4050
    },
    {
      "epoch": 0.6365695540107787,
      "grad_norm": 0.7066709995269775,
      "learning_rate": 3.635369473519763e-05,
      "loss": 1.3205,
      "step": 4075
    },
    {
      "epoch": 0.6404748886979614,
      "grad_norm": 0.9959076642990112,
      "learning_rate": 3.5963130760818624e-05,
      "loss": 1.4053,
      "step": 4100
    },
    {
      "epoch": 0.6443802233851441,
      "grad_norm": 0.7303863763809204,
      "learning_rate": 3.557256678643962e-05,
      "loss": 1.3596,
      "step": 4125
    },
    {
      "epoch": 0.6482855580723268,
      "grad_norm": 0.9452314376831055,
      "learning_rate": 3.5197625371035774e-05,
      "loss": 1.3883,
      "step": 4150
    },
    {
      "epoch": 0.6521908927595095,
      "grad_norm": 0.63216233253479,
      "learning_rate": 3.4807061396656775e-05,
      "loss": 1.3509,
      "step": 4175
    },
    {
      "epoch": 0.6560962274466922,
      "grad_norm": 0.7277505397796631,
      "learning_rate": 3.441649742227777e-05,
      "loss": 1.4006,
      "step": 4200
    },
    {
      "epoch": 0.6600015621338748,
      "grad_norm": 1.0276042222976685,
      "learning_rate": 3.4025933447898763e-05,
      "loss": 1.3833,
      "step": 4225
    },
    {
      "epoch": 0.6639068968210575,
      "grad_norm": 0.7151803970336914,
      "learning_rate": 3.3635369473519764e-05,
      "loss": 1.4063,
      "step": 4250
    },
    {
      "epoch": 0.6678122315082402,
      "grad_norm": 0.7613582611083984,
      "learning_rate": 3.3244805499140765e-05,
      "loss": 1.3904,
      "step": 4275
    },
    {
      "epoch": 0.671717566195423,
      "grad_norm": 0.7099894881248474,
      "learning_rate": 3.285424152476176e-05,
      "loss": 1.3507,
      "step": 4300
    },
    {
      "epoch": 0.6756229008826057,
      "grad_norm": 0.7098227739334106,
      "learning_rate": 3.2463677550382754e-05,
      "loss": 1.3881,
      "step": 4325
    },
    {
      "epoch": 0.6795282355697884,
      "grad_norm": 0.7104899883270264,
      "learning_rate": 3.207311357600375e-05,
      "loss": 1.3913,
      "step": 4350
    },
    {
      "epoch": 0.683433570256971,
      "grad_norm": 0.7885285019874573,
      "learning_rate": 3.168254960162475e-05,
      "loss": 1.4019,
      "step": 4375
    },
    {
      "epoch": 0.6873389049441537,
      "grad_norm": 0.6337634325027466,
      "learning_rate": 3.129198562724574e-05,
      "loss": 1.3853,
      "step": 4400
    },
    {
      "epoch": 0.6912442396313364,
      "grad_norm": 0.6504437327384949,
      "learning_rate": 3.0901421652866744e-05,
      "loss": 1.3544,
      "step": 4425
    },
    {
      "epoch": 0.6951495743185191,
      "grad_norm": 0.7963951826095581,
      "learning_rate": 3.0510857678487738e-05,
      "loss": 1.3272,
      "step": 4450
    },
    {
      "epoch": 0.6990549090057018,
      "grad_norm": 0.7555502653121948,
      "learning_rate": 3.0120293704108732e-05,
      "loss": 1.3928,
      "step": 4475
    },
    {
      "epoch": 0.7029602436928845,
      "grad_norm": 1.0637465715408325,
      "learning_rate": 2.9729729729729733e-05,
      "loss": 1.3604,
      "step": 4500
    },
    {
      "epoch": 0.7068655783800671,
      "grad_norm": 0.9426074028015137,
      "learning_rate": 2.9339165755350727e-05,
      "loss": 1.3297,
      "step": 4525
    },
    {
      "epoch": 0.7107709130672498,
      "grad_norm": 0.7872856259346008,
      "learning_rate": 2.8948601780971725e-05,
      "loss": 1.3395,
      "step": 4550
    },
    {
      "epoch": 0.7146762477544325,
      "grad_norm": 0.7172676920890808,
      "learning_rate": 2.855803780659272e-05,
      "loss": 1.3647,
      "step": 4575
    },
    {
      "epoch": 0.7185815824416153,
      "grad_norm": 0.7403597235679626,
      "learning_rate": 2.816747383221372e-05,
      "loss": 1.3398,
      "step": 4600
    },
    {
      "epoch": 0.722486917128798,
      "grad_norm": 0.7226228713989258,
      "learning_rate": 2.7776909857834714e-05,
      "loss": 1.3733,
      "step": 4625
    },
    {
      "epoch": 0.7263922518159807,
      "grad_norm": 1.1710747480392456,
      "learning_rate": 2.7386345883455712e-05,
      "loss": 1.3405,
      "step": 4650
    },
    {
      "epoch": 0.7302975865031633,
      "grad_norm": 1.2863526344299316,
      "learning_rate": 2.6995781909076706e-05,
      "loss": 1.4175,
      "step": 4675
    },
    {
      "epoch": 0.734202921190346,
      "grad_norm": 1.0372915267944336,
      "learning_rate": 2.6605217934697707e-05,
      "loss": 1.4226,
      "step": 4700
    },
    {
      "epoch": 0.7381082558775287,
      "grad_norm": 0.8038696050643921,
      "learning_rate": 2.62146539603187e-05,
      "loss": 1.3905,
      "step": 4725
    },
    {
      "epoch": 0.7420135905647114,
      "grad_norm": 0.739514946937561,
      "learning_rate": 2.58240899859397e-05,
      "loss": 1.3712,
      "step": 4750
    },
    {
      "epoch": 0.7459189252518941,
      "grad_norm": 0.894993007183075,
      "learning_rate": 2.5433526011560693e-05,
      "loss": 1.4259,
      "step": 4775
    },
    {
      "epoch": 0.7498242599390768,
      "grad_norm": 1.2273099422454834,
      "learning_rate": 2.5042962037181694e-05,
      "loss": 1.4285,
      "step": 4800
    },
    {
      "epoch": 0.7537295946262594,
      "grad_norm": 0.7948921322822571,
      "learning_rate": 2.465239806280269e-05,
      "loss": 1.3426,
      "step": 4825
    },
    {
      "epoch": 0.7576349293134421,
      "grad_norm": 1.1094671487808228,
      "learning_rate": 2.4261834088423685e-05,
      "loss": 1.3318,
      "step": 4850
    },
    {
      "epoch": 0.7615402640006248,
      "grad_norm": 0.8157749772071838,
      "learning_rate": 2.387127011404468e-05,
      "loss": 1.3405,
      "step": 4875
    },
    {
      "epoch": 0.7654455986878076,
      "grad_norm": 0.7799833416938782,
      "learning_rate": 2.3480706139665677e-05,
      "loss": 1.3339,
      "step": 4900
    },
    {
      "epoch": 0.7693509333749903,
      "grad_norm": 0.8015526533126831,
      "learning_rate": 2.3090142165286675e-05,
      "loss": 1.2953,
      "step": 4925
    },
    {
      "epoch": 0.773256268062173,
      "grad_norm": 0.858633816242218,
      "learning_rate": 2.2699578190907672e-05,
      "loss": 1.3411,
      "step": 4950
    },
    {
      "epoch": 0.7771616027493556,
      "grad_norm": 1.0478750467300415,
      "learning_rate": 2.2309014216528666e-05,
      "loss": 1.3921,
      "step": 4975
    },
    {
      "epoch": 0.7810669374365383,
      "grad_norm": 1.0121499300003052,
      "learning_rate": 2.1918450242149667e-05,
      "loss": 1.3156,
      "step": 5000
    },
    {
      "epoch": 0.7810669374365383,
      "eval_loss": 1.371067762374878,
      "eval_runtime": 1621.4957,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 5000
    },
    {
      "epoch": 0.784972272123721,
      "grad_norm": 1.0243319272994995,
      "learning_rate": 2.152788626777066e-05,
      "loss": 1.3745,
      "step": 5025
    },
    {
      "epoch": 0.7888776068109037,
      "grad_norm": 0.8362109065055847,
      "learning_rate": 2.113732229339166e-05,
      "loss": 1.3795,
      "step": 5050
    },
    {
      "epoch": 0.7927829414980864,
      "grad_norm": 0.6398807764053345,
      "learning_rate": 2.0746758319012653e-05,
      "loss": 1.4155,
      "step": 5075
    },
    {
      "epoch": 0.796688276185269,
      "grad_norm": 0.7267706990242004,
      "learning_rate": 2.0356194344633654e-05,
      "loss": 1.336,
      "step": 5100
    },
    {
      "epoch": 0.8005936108724517,
      "grad_norm": 0.7052307724952698,
      "learning_rate": 1.996563037025465e-05,
      "loss": 1.347,
      "step": 5125
    },
    {
      "epoch": 0.8044989455596344,
      "grad_norm": 0.75350421667099,
      "learning_rate": 1.9575066395875646e-05,
      "loss": 1.3944,
      "step": 5150
    },
    {
      "epoch": 0.8084042802468171,
      "grad_norm": 0.8300211429595947,
      "learning_rate": 1.9184502421496643e-05,
      "loss": 1.3492,
      "step": 5175
    },
    {
      "epoch": 0.8123096149339999,
      "grad_norm": 0.7403693199157715,
      "learning_rate": 1.879393844711764e-05,
      "loss": 1.3726,
      "step": 5200
    },
    {
      "epoch": 0.8162149496211826,
      "grad_norm": 1.0091534852981567,
      "learning_rate": 1.8403374472738635e-05,
      "loss": 1.3142,
      "step": 5225
    },
    {
      "epoch": 0.8201202843083653,
      "grad_norm": 0.7685067653656006,
      "learning_rate": 1.8012810498359633e-05,
      "loss": 1.3977,
      "step": 5250
    },
    {
      "epoch": 0.8240256189955479,
      "grad_norm": 0.7387269735336304,
      "learning_rate": 1.762224652398063e-05,
      "loss": 1.4009,
      "step": 5275
    },
    {
      "epoch": 0.8279309536827306,
      "grad_norm": 0.7391129732131958,
      "learning_rate": 1.7231682549601624e-05,
      "loss": 1.394,
      "step": 5300
    },
    {
      "epoch": 0.8318362883699133,
      "grad_norm": 0.7902172207832336,
      "learning_rate": 1.6841118575222622e-05,
      "loss": 1.3487,
      "step": 5325
    },
    {
      "epoch": 0.835741623057096,
      "grad_norm": 0.8157474994659424,
      "learning_rate": 1.645055460084362e-05,
      "loss": 1.3735,
      "step": 5350
    },
    {
      "epoch": 0.8396469577442787,
      "grad_norm": 0.7818217873573303,
      "learning_rate": 1.6059990626464617e-05,
      "loss": 1.403,
      "step": 5375
    },
    {
      "epoch": 0.8435522924314613,
      "grad_norm": 0.9697117805480957,
      "learning_rate": 1.566942665208561e-05,
      "loss": 1.3657,
      "step": 5400
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.6215644478797913,
      "learning_rate": 1.527886267770661e-05,
      "loss": 1.418,
      "step": 5425
    },
    {
      "epoch": 0.8513629618058267,
      "grad_norm": 0.8901612162590027,
      "learning_rate": 1.4888298703327605e-05,
      "loss": 1.3525,
      "step": 5450
    },
    {
      "epoch": 0.8552682964930095,
      "grad_norm": 0.8169065117835999,
      "learning_rate": 1.4497734728948604e-05,
      "loss": 1.4214,
      "step": 5475
    },
    {
      "epoch": 0.8591736311801922,
      "grad_norm": 0.8597555756568909,
      "learning_rate": 1.4107170754569598e-05,
      "loss": 1.3949,
      "step": 5500
    },
    {
      "epoch": 0.8630789658673749,
      "grad_norm": 0.7627319097518921,
      "learning_rate": 1.3716606780190597e-05,
      "loss": 1.3135,
      "step": 5525
    },
    {
      "epoch": 0.8669843005545576,
      "grad_norm": 0.7136194705963135,
      "learning_rate": 1.3326042805811592e-05,
      "loss": 1.3606,
      "step": 5550
    },
    {
      "epoch": 0.8708896352417402,
      "grad_norm": 0.963046133518219,
      "learning_rate": 1.293547883143259e-05,
      "loss": 1.3821,
      "step": 5575
    },
    {
      "epoch": 0.8747949699289229,
      "grad_norm": 0.9594541788101196,
      "learning_rate": 1.2544914857053585e-05,
      "loss": 1.3539,
      "step": 5600
    },
    {
      "epoch": 0.8787003046161056,
      "grad_norm": 0.7747042775154114,
      "learning_rate": 1.2154350882674583e-05,
      "loss": 1.3584,
      "step": 5625
    },
    {
      "epoch": 0.8826056393032883,
      "grad_norm": 0.540209949016571,
      "learning_rate": 1.176378690829558e-05,
      "loss": 1.3629,
      "step": 5650
    },
    {
      "epoch": 0.886510973990471,
      "grad_norm": 1.0184369087219238,
      "learning_rate": 1.1373222933916576e-05,
      "loss": 1.3523,
      "step": 5675
    },
    {
      "epoch": 0.8904163086776536,
      "grad_norm": 1.009919285774231,
      "learning_rate": 1.0982658959537573e-05,
      "loss": 1.4035,
      "step": 5700
    },
    {
      "epoch": 0.8943216433648363,
      "grad_norm": 0.9293586015701294,
      "learning_rate": 1.059209498515857e-05,
      "loss": 1.387,
      "step": 5725
    },
    {
      "epoch": 0.898226978052019,
      "grad_norm": 0.6847692728042603,
      "learning_rate": 1.0201531010779567e-05,
      "loss": 1.3935,
      "step": 5750
    },
    {
      "epoch": 0.9021323127392018,
      "grad_norm": 1.1162265539169312,
      "learning_rate": 9.810967036400563e-06,
      "loss": 1.3962,
      "step": 5775
    },
    {
      "epoch": 0.9060376474263845,
      "grad_norm": 0.820128858089447,
      "learning_rate": 9.42040306202156e-06,
      "loss": 1.3766,
      "step": 5800
    },
    {
      "epoch": 0.9099429821135672,
      "grad_norm": 0.9112349152565002,
      "learning_rate": 9.029839087642556e-06,
      "loss": 1.3687,
      "step": 5825
    },
    {
      "epoch": 0.9138483168007498,
      "grad_norm": 0.7499094605445862,
      "learning_rate": 8.639275113263554e-06,
      "loss": 1.3931,
      "step": 5850
    },
    {
      "epoch": 0.9177536514879325,
      "grad_norm": 0.779123067855835,
      "learning_rate": 8.24871113888455e-06,
      "loss": 1.3834,
      "step": 5875
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 0.8808546662330627,
      "learning_rate": 7.858147164505545e-06,
      "loss": 1.3434,
      "step": 5900
    },
    {
      "epoch": 0.9255643208622979,
      "grad_norm": 0.7188853025436401,
      "learning_rate": 7.467583190126542e-06,
      "loss": 1.3711,
      "step": 5925
    },
    {
      "epoch": 0.9294696555494806,
      "grad_norm": 1.1590969562530518,
      "learning_rate": 7.077019215747539e-06,
      "loss": 1.3808,
      "step": 5950
    },
    {
      "epoch": 0.9333749902366633,
      "grad_norm": 0.7779844403266907,
      "learning_rate": 6.686455241368536e-06,
      "loss": 1.3926,
      "step": 5975
    },
    {
      "epoch": 0.9372803249238459,
      "grad_norm": 0.8251484036445618,
      "learning_rate": 6.295891266989533e-06,
      "loss": 1.3898,
      "step": 6000
    },
    {
      "epoch": 0.9372803249238459,
      "eval_loss": 1.3691012859344482,
      "eval_runtime": 1621.6313,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 6000
    },
    {
      "epoch": 0.9411856596110286,
      "grad_norm": 0.8516352772712708,
      "learning_rate": 5.90532729261053e-06,
      "loss": 1.3566,
      "step": 6025
    },
    {
      "epoch": 0.9450909942982113,
      "grad_norm": 0.9251545071601868,
      "learning_rate": 5.5147633182315265e-06,
      "loss": 1.3733,
      "step": 6050
    },
    {
      "epoch": 0.9489963289853941,
      "grad_norm": 0.843480110168457,
      "learning_rate": 5.124199343852523e-06,
      "loss": 1.4116,
      "step": 6075
    },
    {
      "epoch": 0.9529016636725768,
      "grad_norm": 0.9397046566009521,
      "learning_rate": 4.73363536947352e-06,
      "loss": 1.3677,
      "step": 6100
    },
    {
      "epoch": 0.9568069983597595,
      "grad_norm": 0.8314614295959473,
      "learning_rate": 4.343071395094517e-06,
      "loss": 1.3056,
      "step": 6125
    },
    {
      "epoch": 0.9607123330469421,
      "grad_norm": 0.7589595913887024,
      "learning_rate": 3.952507420715513e-06,
      "loss": 1.3952,
      "step": 6150
    },
    {
      "epoch": 0.9646176677341248,
      "grad_norm": 0.8266384601593018,
      "learning_rate": 3.5619434463365105e-06,
      "loss": 1.4275,
      "step": 6175
    },
    {
      "epoch": 0.9685230024213075,
      "grad_norm": 0.8750735521316528,
      "learning_rate": 3.1713794719575072e-06,
      "loss": 1.3525,
      "step": 6200
    },
    {
      "epoch": 0.9724283371084902,
      "grad_norm": 0.7303192019462585,
      "learning_rate": 2.7808154975785035e-06,
      "loss": 1.4298,
      "step": 6225
    },
    {
      "epoch": 0.9763336717956729,
      "grad_norm": 0.6123300790786743,
      "learning_rate": 2.3902515231995002e-06,
      "loss": 1.383,
      "step": 6250
    },
    {
      "epoch": 0.9802390064828556,
      "grad_norm": 0.8566604852676392,
      "learning_rate": 1.999687548820497e-06,
      "loss": 1.3823,
      "step": 6275
    },
    {
      "epoch": 0.9841443411700382,
      "grad_norm": 0.9160458445549011,
      "learning_rate": 1.6091235744414936e-06,
      "loss": 1.4217,
      "step": 6300
    },
    {
      "epoch": 0.9880496758572209,
      "grad_norm": 0.762948215007782,
      "learning_rate": 1.2185596000624903e-06,
      "loss": 1.3899,
      "step": 6325
    },
    {
      "epoch": 0.9919550105444036,
      "grad_norm": 0.8542826175689697,
      "learning_rate": 8.279956256834869e-07,
      "loss": 1.3563,
      "step": 6350
    },
    {
      "epoch": 0.9958603452315864,
      "grad_norm": 0.8672225475311279,
      "learning_rate": 4.3743165130448375e-07,
      "loss": 1.3055,
      "step": 6375
    },
    {
      "epoch": 0.9997656799187691,
      "grad_norm": 0.8037919402122498,
      "learning_rate": 4.6867676925480397e-08,
      "loss": 1.3534,
      "step": 6400
    },
    {
      "epoch": 1.0037491212996954,
      "grad_norm": 0.826476514339447,
      "learning_rate": 7.491407592563662e-05,
      "loss": 1.3865,
      "step": 6425
    },
    {
      "epoch": 1.007654455986878,
      "grad_norm": 0.9432327747344971,
      "learning_rate": 7.481643493204186e-05,
      "loss": 1.3946,
      "step": 6450
    },
    {
      "epoch": 1.0115597906740608,
      "grad_norm": 0.982694685459137,
      "learning_rate": 7.472269957819092e-05,
      "loss": 1.3321,
      "step": 6475
    },
    {
      "epoch": 1.0154651253612434,
      "grad_norm": 0.7818358540534973,
      "learning_rate": 7.462505858459617e-05,
      "loss": 1.3501,
      "step": 6500
    },
    {
      "epoch": 1.0193704600484261,
      "grad_norm": 0.9747583270072937,
      "learning_rate": 7.452741759100141e-05,
      "loss": 1.3367,
      "step": 6525
    },
    {
      "epoch": 1.0232757947356088,
      "grad_norm": 1.0833646059036255,
      "learning_rate": 7.442977659740666e-05,
      "loss": 1.346,
      "step": 6550
    },
    {
      "epoch": 1.0271811294227915,
      "grad_norm": 0.8493674397468567,
      "learning_rate": 7.43321356038119e-05,
      "loss": 1.3775,
      "step": 6575
    },
    {
      "epoch": 1.0310864641099742,
      "grad_norm": 0.6470551490783691,
      "learning_rate": 7.423449461021716e-05,
      "loss": 1.4065,
      "step": 6600
    },
    {
      "epoch": 1.0349917987971569,
      "grad_norm": 1.0185261964797974,
      "learning_rate": 7.41368536166224e-05,
      "loss": 1.3181,
      "step": 6625
    },
    {
      "epoch": 1.0388971334843395,
      "grad_norm": 0.8133153319358826,
      "learning_rate": 7.403921262302765e-05,
      "loss": 1.3429,
      "step": 6650
    },
    {
      "epoch": 1.0428024681715222,
      "grad_norm": 0.9767525792121887,
      "learning_rate": 7.39415716294329e-05,
      "loss": 1.3691,
      "step": 6675
    },
    {
      "epoch": 1.046707802858705,
      "grad_norm": 1.0633299350738525,
      "learning_rate": 7.384393063583816e-05,
      "loss": 1.3778,
      "step": 6700
    },
    {
      "epoch": 1.0506131375458876,
      "grad_norm": 0.9497751593589783,
      "learning_rate": 7.37462896422434e-05,
      "loss": 1.3886,
      "step": 6725
    },
    {
      "epoch": 1.0545184722330703,
      "grad_norm": 0.7641226649284363,
      "learning_rate": 7.364864864864865e-05,
      "loss": 1.3439,
      "step": 6750
    },
    {
      "epoch": 1.0584238069202532,
      "grad_norm": 1.0509138107299805,
      "learning_rate": 7.35510076550539e-05,
      "loss": 1.3767,
      "step": 6775
    },
    {
      "epoch": 1.0623291416074359,
      "grad_norm": 1.1366339921951294,
      "learning_rate": 7.345336666145916e-05,
      "loss": 1.306,
      "step": 6800
    },
    {
      "epoch": 1.0662344762946185,
      "grad_norm": 0.7490823268890381,
      "learning_rate": 7.33557256678644e-05,
      "loss": 1.4165,
      "step": 6825
    },
    {
      "epoch": 1.0701398109818012,
      "grad_norm": 0.6644013524055481,
      "learning_rate": 7.325808467426964e-05,
      "loss": 1.3921,
      "step": 6850
    },
    {
      "epoch": 1.074045145668984,
      "grad_norm": 0.9066840410232544,
      "learning_rate": 7.316044368067489e-05,
      "loss": 1.4062,
      "step": 6875
    },
    {
      "epoch": 1.0779504803561666,
      "grad_norm": 0.8762468695640564,
      "learning_rate": 7.306280268708015e-05,
      "loss": 1.3227,
      "step": 6900
    },
    {
      "epoch": 1.0818558150433493,
      "grad_norm": 0.9282339215278625,
      "learning_rate": 7.29651616934854e-05,
      "loss": 1.363,
      "step": 6925
    },
    {
      "epoch": 1.085761149730532,
      "grad_norm": 0.6422094106674194,
      "learning_rate": 7.286752069989064e-05,
      "loss": 1.3374,
      "step": 6950
    },
    {
      "epoch": 1.0896664844177146,
      "grad_norm": 0.5498624444007874,
      "learning_rate": 7.27698797062959e-05,
      "loss": 1.4027,
      "step": 6975
    },
    {
      "epoch": 1.0935718191048973,
      "grad_norm": 0.8136439919471741,
      "learning_rate": 7.267223871270115e-05,
      "loss": 1.3625,
      "step": 7000
    },
    {
      "epoch": 1.0935718191048973,
      "eval_loss": 1.3712836503982544,
      "eval_runtime": 1634.2173,
      "eval_samples_per_second": 6.267,
      "eval_steps_per_second": 6.267,
      "step": 7000
    },
    {
      "epoch": 1.09747715379208,
      "grad_norm": 0.6871637105941772,
      "learning_rate": 7.25745977191064e-05,
      "loss": 1.436,
      "step": 7025
    },
    {
      "epoch": 1.1013824884792627,
      "grad_norm": 0.8191506266593933,
      "learning_rate": 7.247695672551164e-05,
      "loss": 1.3494,
      "step": 7050
    },
    {
      "epoch": 1.1052878231664454,
      "grad_norm": 0.8758462071418762,
      "learning_rate": 7.23793157319169e-05,
      "loss": 1.3738,
      "step": 7075
    },
    {
      "epoch": 1.109193157853628,
      "grad_norm": 0.7861376404762268,
      "learning_rate": 7.228167473832214e-05,
      "loss": 1.3999,
      "step": 7100
    },
    {
      "epoch": 1.1130984925408107,
      "grad_norm": 1.6929030418395996,
      "learning_rate": 7.218403374472739e-05,
      "loss": 1.3396,
      "step": 7125
    },
    {
      "epoch": 1.1170038272279934,
      "grad_norm": 0.6532300114631653,
      "learning_rate": 7.208639275113264e-05,
      "loss": 1.3813,
      "step": 7150
    },
    {
      "epoch": 1.120909161915176,
      "grad_norm": 0.6423124074935913,
      "learning_rate": 7.198875175753788e-05,
      "loss": 1.3279,
      "step": 7175
    },
    {
      "epoch": 1.1248144966023588,
      "grad_norm": 0.653894305229187,
      "learning_rate": 7.189111076394314e-05,
      "loss": 1.4054,
      "step": 7200
    },
    {
      "epoch": 1.1287198312895415,
      "grad_norm": 0.668275773525238,
      "learning_rate": 7.179346977034839e-05,
      "loss": 1.3701,
      "step": 7225
    },
    {
      "epoch": 1.1326251659767241,
      "grad_norm": 0.7459421753883362,
      "learning_rate": 7.169582877675364e-05,
      "loss": 1.3487,
      "step": 7250
    },
    {
      "epoch": 1.1365305006639068,
      "grad_norm": 0.8038095831871033,
      "learning_rate": 7.159818778315888e-05,
      "loss": 1.4723,
      "step": 7275
    },
    {
      "epoch": 1.1404358353510895,
      "grad_norm": 0.7304537892341614,
      "learning_rate": 7.150054678956414e-05,
      "loss": 1.4164,
      "step": 7300
    },
    {
      "epoch": 1.1443411700382722,
      "grad_norm": 0.6513001918792725,
      "learning_rate": 7.140290579596939e-05,
      "loss": 1.3327,
      "step": 7325
    },
    {
      "epoch": 1.148246504725455,
      "grad_norm": 1.1853796243667603,
      "learning_rate": 7.130526480237463e-05,
      "loss": 1.3854,
      "step": 7350
    },
    {
      "epoch": 1.1521518394126375,
      "grad_norm": 0.8133282661437988,
      "learning_rate": 7.120762380877987e-05,
      "loss": 1.3534,
      "step": 7375
    },
    {
      "epoch": 1.1560571740998205,
      "grad_norm": 0.7639807462692261,
      "learning_rate": 7.110998281518512e-05,
      "loss": 1.3909,
      "step": 7400
    },
    {
      "epoch": 1.1599625087870031,
      "grad_norm": 0.929000973701477,
      "learning_rate": 7.101234182159038e-05,
      "loss": 1.3816,
      "step": 7425
    },
    {
      "epoch": 1.1638678434741858,
      "grad_norm": 0.5327014327049255,
      "learning_rate": 7.091470082799563e-05,
      "loss": 1.3922,
      "step": 7450
    },
    {
      "epoch": 1.1677731781613685,
      "grad_norm": 1.1107865571975708,
      "learning_rate": 7.081705983440089e-05,
      "loss": 1.3218,
      "step": 7475
    },
    {
      "epoch": 1.1716785128485512,
      "grad_norm": 0.8491135239601135,
      "learning_rate": 7.071941884080613e-05,
      "loss": 1.3523,
      "step": 7500
    },
    {
      "epoch": 1.1755838475357339,
      "grad_norm": 0.7545779943466187,
      "learning_rate": 7.062177784721138e-05,
      "loss": 1.3989,
      "step": 7525
    },
    {
      "epoch": 1.1794891822229165,
      "grad_norm": 0.6979825496673584,
      "learning_rate": 7.052413685361663e-05,
      "loss": 1.3562,
      "step": 7550
    },
    {
      "epoch": 1.1833945169100992,
      "grad_norm": 0.775160551071167,
      "learning_rate": 7.042649586002189e-05,
      "loss": 1.4045,
      "step": 7575
    },
    {
      "epoch": 1.187299851597282,
      "grad_norm": 0.6832802891731262,
      "learning_rate": 7.032885486642713e-05,
      "loss": 1.3483,
      "step": 7600
    },
    {
      "epoch": 1.1912051862844646,
      "grad_norm": 0.601177990436554,
      "learning_rate": 7.023121387283237e-05,
      "loss": 1.3271,
      "step": 7625
    },
    {
      "epoch": 1.1951105209716473,
      "grad_norm": 0.6512954831123352,
      "learning_rate": 7.013357287923762e-05,
      "loss": 1.3729,
      "step": 7650
    },
    {
      "epoch": 1.19901585565883,
      "grad_norm": 0.8090227246284485,
      "learning_rate": 7.003593188564287e-05,
      "loss": 1.357,
      "step": 7675
    },
    {
      "epoch": 1.2029211903460126,
      "grad_norm": 0.745160698890686,
      "learning_rate": 6.993829089204811e-05,
      "loss": 1.4114,
      "step": 7700
    },
    {
      "epoch": 1.2068265250331953,
      "grad_norm": 0.9759581685066223,
      "learning_rate": 6.984064989845337e-05,
      "loss": 1.3834,
      "step": 7725
    },
    {
      "epoch": 1.210731859720378,
      "grad_norm": 0.6594054102897644,
      "learning_rate": 6.974300890485862e-05,
      "loss": 1.391,
      "step": 7750
    },
    {
      "epoch": 1.2146371944075607,
      "grad_norm": 0.845685601234436,
      "learning_rate": 6.964536791126387e-05,
      "loss": 1.4352,
      "step": 7775
    },
    {
      "epoch": 1.2185425290947434,
      "grad_norm": 1.0141022205352783,
      "learning_rate": 6.954772691766911e-05,
      "loss": 1.2975,
      "step": 7800
    },
    {
      "epoch": 1.222447863781926,
      "grad_norm": 1.0377135276794434,
      "learning_rate": 6.945008592407437e-05,
      "loss": 1.3642,
      "step": 7825
    },
    {
      "epoch": 1.2263531984691087,
      "grad_norm": 1.0361521244049072,
      "learning_rate": 6.935244493047962e-05,
      "loss": 1.382,
      "step": 7850
    },
    {
      "epoch": 1.2302585331562914,
      "grad_norm": 1.0126973390579224,
      "learning_rate": 6.925480393688486e-05,
      "loss": 1.3799,
      "step": 7875
    },
    {
      "epoch": 1.234163867843474,
      "grad_norm": 0.9690948128700256,
      "learning_rate": 6.915716294329012e-05,
      "loss": 1.3985,
      "step": 7900
    },
    {
      "epoch": 1.238069202530657,
      "grad_norm": 0.6522526741027832,
      "learning_rate": 6.905952194969536e-05,
      "loss": 1.3575,
      "step": 7925
    },
    {
      "epoch": 1.2419745372178395,
      "grad_norm": 0.9931288957595825,
      "learning_rate": 6.896188095610061e-05,
      "loss": 1.3407,
      "step": 7950
    },
    {
      "epoch": 1.2458798719050224,
      "grad_norm": 0.7055680751800537,
      "learning_rate": 6.886423996250586e-05,
      "loss": 1.3875,
      "step": 7975
    },
    {
      "epoch": 1.249785206592205,
      "grad_norm": 0.8442485332489014,
      "learning_rate": 6.876659896891112e-05,
      "loss": 1.3636,
      "step": 8000
    },
    {
      "epoch": 1.249785206592205,
      "eval_loss": 1.369206190109253,
      "eval_runtime": 1634.4216,
      "eval_samples_per_second": 6.266,
      "eval_steps_per_second": 6.266,
      "step": 8000
    },
    {
      "epoch": 1.2536905412793877,
      "grad_norm": 0.8141821622848511,
      "learning_rate": 6.866895797531636e-05,
      "loss": 1.352,
      "step": 8025
    },
    {
      "epoch": 1.2575958759665704,
      "grad_norm": 0.9480127096176147,
      "learning_rate": 6.857131698172161e-05,
      "loss": 1.4302,
      "step": 8050
    },
    {
      "epoch": 1.261501210653753,
      "grad_norm": 0.7328153848648071,
      "learning_rate": 6.847367598812686e-05,
      "loss": 1.3471,
      "step": 8075
    },
    {
      "epoch": 1.2654065453409358,
      "grad_norm": 1.0076953172683716,
      "learning_rate": 6.837603499453212e-05,
      "loss": 1.2896,
      "step": 8100
    },
    {
      "epoch": 1.2693118800281185,
      "grad_norm": 1.0877987146377563,
      "learning_rate": 6.827839400093736e-05,
      "loss": 1.3243,
      "step": 8125
    },
    {
      "epoch": 1.2732172147153011,
      "grad_norm": 0.8529407382011414,
      "learning_rate": 6.81807530073426e-05,
      "loss": 1.4164,
      "step": 8150
    },
    {
      "epoch": 1.2771225494024838,
      "grad_norm": 0.8677666187286377,
      "learning_rate": 6.808311201374785e-05,
      "loss": 1.3268,
      "step": 8175
    },
    {
      "epoch": 1.2810278840896665,
      "grad_norm": 1.0463528633117676,
      "learning_rate": 6.79854710201531e-05,
      "loss": 1.3718,
      "step": 8200
    },
    {
      "epoch": 1.2849332187768492,
      "grad_norm": 0.6416590213775635,
      "learning_rate": 6.788783002655836e-05,
      "loss": 1.3419,
      "step": 8225
    },
    {
      "epoch": 1.2888385534640319,
      "grad_norm": 0.8291686773300171,
      "learning_rate": 6.77901890329636e-05,
      "loss": 1.331,
      "step": 8250
    },
    {
      "epoch": 1.2927438881512145,
      "grad_norm": 0.8016397953033447,
      "learning_rate": 6.769254803936885e-05,
      "loss": 1.3243,
      "step": 8275
    },
    {
      "epoch": 1.2966492228383972,
      "grad_norm": 1.1671720743179321,
      "learning_rate": 6.75949070457741e-05,
      "loss": 1.3948,
      "step": 8300
    },
    {
      "epoch": 1.30055455752558,
      "grad_norm": 0.7608175277709961,
      "learning_rate": 6.749726605217936e-05,
      "loss": 1.3855,
      "step": 8325
    },
    {
      "epoch": 1.3044598922127626,
      "grad_norm": 1.5472832918167114,
      "learning_rate": 6.73996250585846e-05,
      "loss": 1.3912,
      "step": 8350
    },
    {
      "epoch": 1.3083652268999453,
      "grad_norm": 0.9188940525054932,
      "learning_rate": 6.730198406498985e-05,
      "loss": 1.3168,
      "step": 8375
    },
    {
      "epoch": 1.312270561587128,
      "grad_norm": 0.8308167457580566,
      "learning_rate": 6.720434307139509e-05,
      "loss": 1.371,
      "step": 8400
    },
    {
      "epoch": 1.3161758962743106,
      "grad_norm": 0.9710763096809387,
      "learning_rate": 6.710670207780035e-05,
      "loss": 1.2853,
      "step": 8425
    },
    {
      "epoch": 1.3200812309614933,
      "grad_norm": 0.9789024591445923,
      "learning_rate": 6.700906108420559e-05,
      "loss": 1.3626,
      "step": 8450
    },
    {
      "epoch": 1.323986565648676,
      "grad_norm": 0.865369439125061,
      "learning_rate": 6.691142009061084e-05,
      "loss": 1.3331,
      "step": 8475
    },
    {
      "epoch": 1.327891900335859,
      "grad_norm": 0.6146112084388733,
      "learning_rate": 6.68137790970161e-05,
      "loss": 1.359,
      "step": 8500
    },
    {
      "epoch": 1.3317972350230414,
      "grad_norm": 0.5943289995193481,
      "learning_rate": 6.672004374316513e-05,
      "loss": 1.3507,
      "step": 8525
    },
    {
      "epoch": 1.3357025697102243,
      "grad_norm": 0.9272064566612244,
      "learning_rate": 6.662240274957037e-05,
      "loss": 1.3623,
      "step": 8550
    },
    {
      "epoch": 1.3396079043974067,
      "grad_norm": 0.6243643164634705,
      "learning_rate": 6.652476175597563e-05,
      "loss": 1.3879,
      "step": 8575
    },
    {
      "epoch": 1.3435132390845896,
      "grad_norm": 0.744561493396759,
      "learning_rate": 6.642712076238088e-05,
      "loss": 1.3828,
      "step": 8600
    },
    {
      "epoch": 1.3474185737717723,
      "grad_norm": 0.7397298216819763,
      "learning_rate": 6.632947976878614e-05,
      "loss": 1.38,
      "step": 8625
    },
    {
      "epoch": 1.351323908458955,
      "grad_norm": 0.6475093364715576,
      "learning_rate": 6.623183877519138e-05,
      "loss": 1.3509,
      "step": 8650
    },
    {
      "epoch": 1.3552292431461377,
      "grad_norm": 0.8012126684188843,
      "learning_rate": 6.613419778159663e-05,
      "loss": 1.3691,
      "step": 8675
    },
    {
      "epoch": 1.3591345778333204,
      "grad_norm": 0.6896969676017761,
      "learning_rate": 6.603655678800188e-05,
      "loss": 1.2855,
      "step": 8700
    },
    {
      "epoch": 1.363039912520503,
      "grad_norm": 0.9543899893760681,
      "learning_rate": 6.593891579440714e-05,
      "loss": 1.3325,
      "step": 8725
    },
    {
      "epoch": 1.3669452472076857,
      "grad_norm": 0.7190353870391846,
      "learning_rate": 6.584127480081238e-05,
      "loss": 1.3722,
      "step": 8750
    },
    {
      "epoch": 1.3708505818948684,
      "grad_norm": 0.7913508415222168,
      "learning_rate": 6.574363380721763e-05,
      "loss": 1.3992,
      "step": 8775
    },
    {
      "epoch": 1.374755916582051,
      "grad_norm": 0.8860772252082825,
      "learning_rate": 6.564599281362287e-05,
      "loss": 1.3808,
      "step": 8800
    },
    {
      "epoch": 1.3786612512692338,
      "grad_norm": 0.8574299812316895,
      "learning_rate": 6.554835182002812e-05,
      "loss": 1.2686,
      "step": 8825
    },
    {
      "epoch": 1.3825665859564165,
      "grad_norm": 0.7567448019981384,
      "learning_rate": 6.545071082643336e-05,
      "loss": 1.2791,
      "step": 8850
    },
    {
      "epoch": 1.3864719206435991,
      "grad_norm": 0.6631556749343872,
      "learning_rate": 6.535306983283862e-05,
      "loss": 1.4176,
      "step": 8875
    },
    {
      "epoch": 1.3903772553307818,
      "grad_norm": 0.8510225415229797,
      "learning_rate": 6.525542883924387e-05,
      "loss": 1.3921,
      "step": 8900
    },
    {
      "epoch": 1.3942825900179645,
      "grad_norm": 0.6551876068115234,
      "learning_rate": 6.515778784564913e-05,
      "loss": 1.2743,
      "step": 8925
    },
    {
      "epoch": 1.3981879247051472,
      "grad_norm": 0.8922395706176758,
      "learning_rate": 6.506014685205437e-05,
      "loss": 1.3467,
      "step": 8950
    },
    {
      "epoch": 1.4020932593923299,
      "grad_norm": 1.200325846672058,
      "learning_rate": 6.496250585845962e-05,
      "loss": 1.3316,
      "step": 8975
    },
    {
      "epoch": 1.4059985940795126,
      "grad_norm": 0.9003533124923706,
      "learning_rate": 6.486486486486487e-05,
      "loss": 1.3586,
      "step": 9000
    },
    {
      "epoch": 1.4059985940795126,
      "eval_loss": 1.3649587631225586,
      "eval_runtime": 1634.1389,
      "eval_samples_per_second": 6.268,
      "eval_steps_per_second": 6.268,
      "step": 9000
    },
    {
      "epoch": 1.4099039287666952,
      "grad_norm": 0.7240356206893921,
      "learning_rate": 6.476722387127013e-05,
      "loss": 1.2956,
      "step": 9025
    },
    {
      "epoch": 1.413809263453878,
      "grad_norm": 1.309023380279541,
      "learning_rate": 6.466958287767537e-05,
      "loss": 1.3779,
      "step": 9050
    },
    {
      "epoch": 1.4177145981410608,
      "grad_norm": 0.7921628355979919,
      "learning_rate": 6.45719418840806e-05,
      "loss": 1.2669,
      "step": 9075
    },
    {
      "epoch": 1.4216199328282433,
      "grad_norm": 0.7225480079650879,
      "learning_rate": 6.447430089048586e-05,
      "loss": 1.3671,
      "step": 9100
    },
    {
      "epoch": 1.4255252675154262,
      "grad_norm": 1.1047474145889282,
      "learning_rate": 6.437665989689111e-05,
      "loss": 1.3851,
      "step": 9125
    },
    {
      "epoch": 1.4294306022026086,
      "grad_norm": 0.9978737831115723,
      "learning_rate": 6.427901890329637e-05,
      "loss": 1.3417,
      "step": 9150
    },
    {
      "epoch": 1.4333359368897916,
      "grad_norm": 0.7221362590789795,
      "learning_rate": 6.418137790970161e-05,
      "loss": 1.3123,
      "step": 9175
    },
    {
      "epoch": 1.437241271576974,
      "grad_norm": 0.7195819616317749,
      "learning_rate": 6.408373691610686e-05,
      "loss": 1.3229,
      "step": 9200
    },
    {
      "epoch": 1.441146606264157,
      "grad_norm": 0.8682713508605957,
      "learning_rate": 6.398609592251211e-05,
      "loss": 1.3759,
      "step": 9225
    },
    {
      "epoch": 1.4450519409513396,
      "grad_norm": 0.6528059244155884,
      "learning_rate": 6.388845492891737e-05,
      "loss": 1.3658,
      "step": 9250
    },
    {
      "epoch": 1.4489572756385223,
      "grad_norm": 0.7115724086761475,
      "learning_rate": 6.379081393532261e-05,
      "loss": 1.3539,
      "step": 9275
    },
    {
      "epoch": 1.452862610325705,
      "grad_norm": 0.6947727203369141,
      "learning_rate": 6.369317294172786e-05,
      "loss": 1.3274,
      "step": 9300
    },
    {
      "epoch": 1.4567679450128876,
      "grad_norm": 0.7703093886375427,
      "learning_rate": 6.35955319481331e-05,
      "loss": 1.3245,
      "step": 9325
    },
    {
      "epoch": 1.4606732797000703,
      "grad_norm": 0.7850073575973511,
      "learning_rate": 6.349789095453836e-05,
      "loss": 1.3695,
      "step": 9350
    },
    {
      "epoch": 1.464578614387253,
      "grad_norm": 0.7219585180282593,
      "learning_rate": 6.340024996094361e-05,
      "loss": 1.3696,
      "step": 9375
    },
    {
      "epoch": 1.4684839490744357,
      "grad_norm": 0.9624717235565186,
      "learning_rate": 6.330260896734885e-05,
      "loss": 1.3849,
      "step": 9400
    },
    {
      "epoch": 1.4723892837616184,
      "grad_norm": 0.713996410369873,
      "learning_rate": 6.32049679737541e-05,
      "loss": 1.3071,
      "step": 9425
    },
    {
      "epoch": 1.476294618448801,
      "grad_norm": 0.6346928477287292,
      "learning_rate": 6.310732698015936e-05,
      "loss": 1.407,
      "step": 9450
    },
    {
      "epoch": 1.4801999531359837,
      "grad_norm": 0.7286780476570129,
      "learning_rate": 6.300968598656461e-05,
      "loss": 1.3955,
      "step": 9475
    },
    {
      "epoch": 1.4841052878231664,
      "grad_norm": 0.7447071075439453,
      "learning_rate": 6.291204499296985e-05,
      "loss": 1.31,
      "step": 9500
    },
    {
      "epoch": 1.488010622510349,
      "grad_norm": 0.8580664396286011,
      "learning_rate": 6.28144039993751e-05,
      "loss": 1.348,
      "step": 9525
    },
    {
      "epoch": 1.4919159571975318,
      "grad_norm": 0.8237919211387634,
      "learning_rate": 6.271676300578036e-05,
      "loss": 1.376,
      "step": 9550
    },
    {
      "epoch": 1.4958212918847145,
      "grad_norm": 0.7300108671188354,
      "learning_rate": 6.26191220121856e-05,
      "loss": 1.2586,
      "step": 9575
    },
    {
      "epoch": 1.4997266265718971,
      "grad_norm": 0.7839226722717285,
      "learning_rate": 6.252148101859084e-05,
      "loss": 1.3262,
      "step": 9600
    },
    {
      "epoch": 1.5036319612590798,
      "grad_norm": 0.7655742168426514,
      "learning_rate": 6.242384002499609e-05,
      "loss": 1.3684,
      "step": 9625
    },
    {
      "epoch": 1.5075372959462627,
      "grad_norm": 0.7352942824363708,
      "learning_rate": 6.232619903140134e-05,
      "loss": 1.3102,
      "step": 9650
    },
    {
      "epoch": 1.5114426306334452,
      "grad_norm": 0.7664439082145691,
      "learning_rate": 6.22285580378066e-05,
      "loss": 1.3106,
      "step": 9675
    },
    {
      "epoch": 1.515347965320628,
      "grad_norm": 0.8649623394012451,
      "learning_rate": 6.213091704421184e-05,
      "loss": 1.3588,
      "step": 9700
    },
    {
      "epoch": 1.5192533000078106,
      "grad_norm": 0.8835758566856384,
      "learning_rate": 6.203327605061709e-05,
      "loss": 1.3729,
      "step": 9725
    },
    {
      "epoch": 1.5231586346949935,
      "grad_norm": 0.8498286008834839,
      "learning_rate": 6.193563505702235e-05,
      "loss": 1.3573,
      "step": 9750
    },
    {
      "epoch": 1.527063969382176,
      "grad_norm": 0.518770694732666,
      "learning_rate": 6.18379940634276e-05,
      "loss": 1.3269,
      "step": 9775
    },
    {
      "epoch": 1.5309693040693588,
      "grad_norm": 0.6482419371604919,
      "learning_rate": 6.174035306983284e-05,
      "loss": 1.3432,
      "step": 9800
    },
    {
      "epoch": 1.5348746387565413,
      "grad_norm": 0.8815557956695557,
      "learning_rate": 6.164271207623809e-05,
      "loss": 1.3201,
      "step": 9825
    },
    {
      "epoch": 1.5387799734437242,
      "grad_norm": 0.6976563930511475,
      "learning_rate": 6.154507108264333e-05,
      "loss": 1.3439,
      "step": 9850
    },
    {
      "epoch": 1.5426853081309069,
      "grad_norm": 0.9021669030189514,
      "learning_rate": 6.144743008904859e-05,
      "loss": 1.3324,
      "step": 9875
    },
    {
      "epoch": 1.5465906428180896,
      "grad_norm": 0.9769601225852966,
      "learning_rate": 6.134978909545384e-05,
      "loss": 1.3546,
      "step": 9900
    },
    {
      "epoch": 1.5504959775052722,
      "grad_norm": 1.0468862056732178,
      "learning_rate": 6.125214810185908e-05,
      "loss": 1.3582,
      "step": 9925
    },
    {
      "epoch": 1.554401312192455,
      "grad_norm": 0.7685632109642029,
      "learning_rate": 6.115450710826433e-05,
      "loss": 1.3734,
      "step": 9950
    },
    {
      "epoch": 1.5583066468796376,
      "grad_norm": 0.7127953171730042,
      "learning_rate": 6.105686611466959e-05,
      "loss": 1.3371,
      "step": 9975
    },
    {
      "epoch": 1.5622119815668203,
      "grad_norm": 0.735394299030304,
      "learning_rate": 6.0959225121074834e-05,
      "loss": 1.3566,
      "step": 10000
    },
    {
      "epoch": 1.5622119815668203,
      "eval_loss": 1.364108920097351,
      "eval_runtime": 1641.5016,
      "eval_samples_per_second": 6.239,
      "eval_steps_per_second": 6.239,
      "step": 10000
    },
    {
      "epoch": 1.566117316254003,
      "grad_norm": 1.0336960554122925,
      "learning_rate": 6.086158412748009e-05,
      "loss": 1.3889,
      "step": 10025
    },
    {
      "epoch": 1.5700226509411856,
      "grad_norm": 0.9717611074447632,
      "learning_rate": 6.0763943133885335e-05,
      "loss": 1.384,
      "step": 10050
    },
    {
      "epoch": 1.5739279856283683,
      "grad_norm": 0.6737681031227112,
      "learning_rate": 6.066630214029059e-05,
      "loss": 1.3391,
      "step": 10075
    },
    {
      "epoch": 1.577833320315551,
      "grad_norm": 0.7138047218322754,
      "learning_rate": 6.056866114669583e-05,
      "loss": 1.3737,
      "step": 10100
    },
    {
      "epoch": 1.5817386550027337,
      "grad_norm": 0.8504524230957031,
      "learning_rate": 6.0471020153101075e-05,
      "loss": 1.353,
      "step": 10125
    },
    {
      "epoch": 1.5856439896899164,
      "grad_norm": 0.9791404008865356,
      "learning_rate": 6.037337915950633e-05,
      "loss": 1.3136,
      "step": 10150
    },
    {
      "epoch": 1.5895493243770993,
      "grad_norm": 0.9580011963844299,
      "learning_rate": 6.0275738165911576e-05,
      "loss": 1.3457,
      "step": 10175
    },
    {
      "epoch": 1.5934546590642817,
      "grad_norm": 0.652380108833313,
      "learning_rate": 6.017809717231683e-05,
      "loss": 1.3699,
      "step": 10200
    },
    {
      "epoch": 1.5973599937514646,
      "grad_norm": 0.7859220504760742,
      "learning_rate": 6.0080456178722076e-05,
      "loss": 1.3332,
      "step": 10225
    },
    {
      "epoch": 1.601265328438647,
      "grad_norm": 0.8810251355171204,
      "learning_rate": 5.998281518512733e-05,
      "loss": 1.3123,
      "step": 10250
    },
    {
      "epoch": 1.60517066312583,
      "grad_norm": 0.791767418384552,
      "learning_rate": 5.988517419153258e-05,
      "loss": 1.4239,
      "step": 10275
    },
    {
      "epoch": 1.6090759978130125,
      "grad_norm": 0.7632609605789185,
      "learning_rate": 5.978753319793783e-05,
      "loss": 1.3725,
      "step": 10300
    },
    {
      "epoch": 1.6129813325001954,
      "grad_norm": 0.7978947162628174,
      "learning_rate": 5.968989220434308e-05,
      "loss": 1.3469,
      "step": 10325
    },
    {
      "epoch": 1.6168866671873778,
      "grad_norm": 0.6841965913772583,
      "learning_rate": 5.959225121074833e-05,
      "loss": 1.3253,
      "step": 10350
    },
    {
      "epoch": 1.6207920018745607,
      "grad_norm": 2.093449115753174,
      "learning_rate": 5.949461021715357e-05,
      "loss": 1.3366,
      "step": 10375
    },
    {
      "epoch": 1.6246973365617432,
      "grad_norm": 0.9258047342300415,
      "learning_rate": 5.939696922355882e-05,
      "loss": 1.3435,
      "step": 10400
    },
    {
      "epoch": 1.628602671248926,
      "grad_norm": 1.30410635471344,
      "learning_rate": 5.929932822996407e-05,
      "loss": 1.3092,
      "step": 10425
    },
    {
      "epoch": 1.6325080059361086,
      "grad_norm": 0.6484313011169434,
      "learning_rate": 5.920168723636932e-05,
      "loss": 1.3306,
      "step": 10450
    },
    {
      "epoch": 1.6364133406232915,
      "grad_norm": 0.7532194256782532,
      "learning_rate": 5.910404624277457e-05,
      "loss": 1.3879,
      "step": 10475
    },
    {
      "epoch": 1.6403186753104742,
      "grad_norm": 0.8537195324897766,
      "learning_rate": 5.900640524917982e-05,
      "loss": 1.3696,
      "step": 10500
    },
    {
      "epoch": 1.6442240099976568,
      "grad_norm": 0.9194633960723877,
      "learning_rate": 5.890876425558507e-05,
      "loss": 1.4162,
      "step": 10525
    },
    {
      "epoch": 1.6481293446848395,
      "grad_norm": 0.8305969834327698,
      "learning_rate": 5.881112326199032e-05,
      "loss": 1.3667,
      "step": 10550
    },
    {
      "epoch": 1.6520346793720222,
      "grad_norm": 1.0881606340408325,
      "learning_rate": 5.871348226839557e-05,
      "loss": 1.3894,
      "step": 10575
    },
    {
      "epoch": 1.6559400140592049,
      "grad_norm": 0.9575119018554688,
      "learning_rate": 5.861584127480082e-05,
      "loss": 1.4001,
      "step": 10600
    },
    {
      "epoch": 1.6598453487463876,
      "grad_norm": 0.5831546783447266,
      "learning_rate": 5.851820028120606e-05,
      "loss": 1.3394,
      "step": 10625
    },
    {
      "epoch": 1.6637506834335702,
      "grad_norm": 0.7994945049285889,
      "learning_rate": 5.842055928761131e-05,
      "loss": 1.4081,
      "step": 10650
    },
    {
      "epoch": 1.667656018120753,
      "grad_norm": 1.273805856704712,
      "learning_rate": 5.832291829401656e-05,
      "loss": 1.3291,
      "step": 10675
    },
    {
      "epoch": 1.6715613528079356,
      "grad_norm": 0.7565019130706787,
      "learning_rate": 5.822527730042181e-05,
      "loss": 1.3341,
      "step": 10700
    },
    {
      "epoch": 1.6754666874951183,
      "grad_norm": 0.8795378804206848,
      "learning_rate": 5.812763630682706e-05,
      "loss": 1.383,
      "step": 10725
    },
    {
      "epoch": 1.679372022182301,
      "grad_norm": 0.7607576847076416,
      "learning_rate": 5.802999531323231e-05,
      "loss": 1.3052,
      "step": 10750
    },
    {
      "epoch": 1.6832773568694837,
      "grad_norm": 0.6597704291343689,
      "learning_rate": 5.793235431963756e-05,
      "loss": 1.3097,
      "step": 10775
    },
    {
      "epoch": 1.6871826915566666,
      "grad_norm": 0.631804883480072,
      "learning_rate": 5.783471332604281e-05,
      "loss": 1.3873,
      "step": 10800
    },
    {
      "epoch": 1.691088026243849,
      "grad_norm": 0.8984586000442505,
      "learning_rate": 5.773707233244806e-05,
      "loss": 1.3576,
      "step": 10825
    },
    {
      "epoch": 1.694993360931032,
      "grad_norm": 0.6577986478805542,
      "learning_rate": 5.763943133885331e-05,
      "loss": 1.3518,
      "step": 10850
    },
    {
      "epoch": 1.6988986956182144,
      "grad_norm": 0.6625407338142395,
      "learning_rate": 5.754179034525856e-05,
      "loss": 1.3909,
      "step": 10875
    },
    {
      "epoch": 1.7028040303053973,
      "grad_norm": 1.0003132820129395,
      "learning_rate": 5.74441493516638e-05,
      "loss": 1.3487,
      "step": 10900
    },
    {
      "epoch": 1.7067093649925797,
      "grad_norm": 0.9038766622543335,
      "learning_rate": 5.734650835806905e-05,
      "loss": 1.3209,
      "step": 10925
    },
    {
      "epoch": 1.7106146996797627,
      "grad_norm": 0.8501367568969727,
      "learning_rate": 5.72488673644743e-05,
      "loss": 1.405,
      "step": 10950
    },
    {
      "epoch": 1.7145200343669451,
      "grad_norm": 0.7649689316749573,
      "learning_rate": 5.715122637087955e-05,
      "loss": 1.3757,
      "step": 10975
    },
    {
      "epoch": 1.718425369054128,
      "grad_norm": 0.9240680932998657,
      "learning_rate": 5.70535853772848e-05,
      "loss": 1.3672,
      "step": 11000
    },
    {
      "epoch": 1.718425369054128,
      "eval_loss": 1.3619933128356934,
      "eval_runtime": 1673.6579,
      "eval_samples_per_second": 6.12,
      "eval_steps_per_second": 6.12,
      "step": 11000
    },
    {
      "epoch": 1.7223307037413105,
      "grad_norm": 0.6878304481506348,
      "learning_rate": 5.695594438369005e-05,
      "loss": 1.3532,
      "step": 11025
    },
    {
      "epoch": 1.7262360384284934,
      "grad_norm": 1.092368483543396,
      "learning_rate": 5.6858303390095304e-05,
      "loss": 1.3128,
      "step": 11050
    },
    {
      "epoch": 1.730141373115676,
      "grad_norm": 0.841469943523407,
      "learning_rate": 5.676066239650055e-05,
      "loss": 1.3235,
      "step": 11075
    },
    {
      "epoch": 1.7340467078028587,
      "grad_norm": 0.8239331841468811,
      "learning_rate": 5.6663021402905804e-05,
      "loss": 1.3939,
      "step": 11100
    },
    {
      "epoch": 1.7379520424900414,
      "grad_norm": 0.8255379796028137,
      "learning_rate": 5.656538040931105e-05,
      "loss": 1.3487,
      "step": 11125
    },
    {
      "epoch": 1.741857377177224,
      "grad_norm": 0.7424173355102539,
      "learning_rate": 5.646773941571629e-05,
      "loss": 1.399,
      "step": 11150
    },
    {
      "epoch": 1.7457627118644068,
      "grad_norm": 0.9819462299346924,
      "learning_rate": 5.6370098422121545e-05,
      "loss": 1.3494,
      "step": 11175
    },
    {
      "epoch": 1.7496680465515895,
      "grad_norm": 0.819744884967804,
      "learning_rate": 5.627245742852679e-05,
      "loss": 1.3693,
      "step": 11200
    },
    {
      "epoch": 1.7535733812387722,
      "grad_norm": 0.960800290107727,
      "learning_rate": 5.6174816434932045e-05,
      "loss": 1.3403,
      "step": 11225
    },
    {
      "epoch": 1.7574787159259548,
      "grad_norm": 1.08053457736969,
      "learning_rate": 5.607717544133729e-05,
      "loss": 1.2821,
      "step": 11250
    },
    {
      "epoch": 1.7613840506131375,
      "grad_norm": 0.99693763256073,
      "learning_rate": 5.5979534447742546e-05,
      "loss": 1.3208,
      "step": 11275
    },
    {
      "epoch": 1.7652893853003202,
      "grad_norm": 0.9643491506576538,
      "learning_rate": 5.588189345414779e-05,
      "loss": 1.3431,
      "step": 11300
    },
    {
      "epoch": 1.7691947199875029,
      "grad_norm": 0.8187214136123657,
      "learning_rate": 5.5784252460553046e-05,
      "loss": 1.3162,
      "step": 11325
    },
    {
      "epoch": 1.7731000546746856,
      "grad_norm": 0.726246178150177,
      "learning_rate": 5.568661146695829e-05,
      "loss": 1.3547,
      "step": 11350
    },
    {
      "epoch": 1.7770053893618685,
      "grad_norm": 0.885657012462616,
      "learning_rate": 5.5588970473363547e-05,
      "loss": 1.3544,
      "step": 11375
    },
    {
      "epoch": 1.780910724049051,
      "grad_norm": 0.9122483134269714,
      "learning_rate": 5.5491329479768787e-05,
      "loss": 1.3377,
      "step": 11400
    },
    {
      "epoch": 1.7848160587362338,
      "grad_norm": 0.5902431607246399,
      "learning_rate": 5.5393688486174033e-05,
      "loss": 1.3914,
      "step": 11425
    },
    {
      "epoch": 1.7887213934234163,
      "grad_norm": 1.063346266746521,
      "learning_rate": 5.529604749257929e-05,
      "loss": 1.3844,
      "step": 11450
    },
    {
      "epoch": 1.7926267281105992,
      "grad_norm": 0.6201026439666748,
      "learning_rate": 5.5198406498984534e-05,
      "loss": 1.3404,
      "step": 11475
    },
    {
      "epoch": 1.7965320627977817,
      "grad_norm": 1.2140604257583618,
      "learning_rate": 5.510076550538979e-05,
      "loss": 1.3395,
      "step": 11500
    },
    {
      "epoch": 1.8004373974849646,
      "grad_norm": 0.8478405475616455,
      "learning_rate": 5.5003124511795034e-05,
      "loss": 1.327,
      "step": 11525
    },
    {
      "epoch": 1.804342732172147,
      "grad_norm": 0.9936119914054871,
      "learning_rate": 5.490548351820029e-05,
      "loss": 1.3605,
      "step": 11550
    },
    {
      "epoch": 1.80824806685933,
      "grad_norm": 0.767670750617981,
      "learning_rate": 5.4807842524605535e-05,
      "loss": 1.3885,
      "step": 11575
    },
    {
      "epoch": 1.8121534015465124,
      "grad_norm": 0.8203369975090027,
      "learning_rate": 5.471020153101079e-05,
      "loss": 1.3426,
      "step": 11600
    },
    {
      "epoch": 1.8160587362336953,
      "grad_norm": 0.7723694443702698,
      "learning_rate": 5.4612560537416035e-05,
      "loss": 1.3002,
      "step": 11625
    },
    {
      "epoch": 1.819964070920878,
      "grad_norm": 0.769467830657959,
      "learning_rate": 5.451491954382129e-05,
      "loss": 1.3392,
      "step": 11650
    },
    {
      "epoch": 1.8238694056080607,
      "grad_norm": 1.0142529010772705,
      "learning_rate": 5.441727855022652e-05,
      "loss": 1.3768,
      "step": 11675
    },
    {
      "epoch": 1.8277747402952433,
      "grad_norm": 1.2035634517669678,
      "learning_rate": 5.4319637556631776e-05,
      "loss": 1.3212,
      "step": 11700
    },
    {
      "epoch": 1.831680074982426,
      "grad_norm": 0.7025572657585144,
      "learning_rate": 5.422199656303702e-05,
      "loss": 1.3823,
      "step": 11725
    },
    {
      "epoch": 1.8355854096696087,
      "grad_norm": 0.8222755789756775,
      "learning_rate": 5.4124355569442276e-05,
      "loss": 1.3496,
      "step": 11750
    },
    {
      "epoch": 1.8394907443567914,
      "grad_norm": 0.8046228885650635,
      "learning_rate": 5.402671457584752e-05,
      "loss": 1.414,
      "step": 11775
    },
    {
      "epoch": 1.843396079043974,
      "grad_norm": 0.8065323829650879,
      "learning_rate": 5.392907358225278e-05,
      "loss": 1.394,
      "step": 11800
    },
    {
      "epoch": 1.8473014137311567,
      "grad_norm": 0.705103874206543,
      "learning_rate": 5.3831432588658024e-05,
      "loss": 1.3084,
      "step": 11825
    },
    {
      "epoch": 1.8512067484183394,
      "grad_norm": 0.8992977738380432,
      "learning_rate": 5.373379159506328e-05,
      "loss": 1.3588,
      "step": 11850
    },
    {
      "epoch": 1.8551120831055221,
      "grad_norm": 0.992720901966095,
      "learning_rate": 5.3636150601468524e-05,
      "loss": 1.3106,
      "step": 11875
    },
    {
      "epoch": 1.8590174177927048,
      "grad_norm": 0.7058011889457703,
      "learning_rate": 5.353850960787378e-05,
      "loss": 1.3128,
      "step": 11900
    },
    {
      "epoch": 1.8629227524798875,
      "grad_norm": 0.9871295690536499,
      "learning_rate": 5.344086861427902e-05,
      "loss": 1.3465,
      "step": 11925
    },
    {
      "epoch": 1.8668280871670704,
      "grad_norm": 0.7670223116874695,
      "learning_rate": 5.3343227620684265e-05,
      "loss": 1.3465,
      "step": 11950
    },
    {
      "epoch": 1.8707334218542528,
      "grad_norm": 1.4455609321594238,
      "learning_rate": 5.324558662708952e-05,
      "loss": 1.409,
      "step": 11975
    },
    {
      "epoch": 1.8746387565414357,
      "grad_norm": 0.843940019607544,
      "learning_rate": 5.3147945633494765e-05,
      "loss": 1.3446,
      "step": 12000
    },
    {
      "epoch": 1.8746387565414357,
      "eval_loss": 1.3589731454849243,
      "eval_runtime": 1680.1198,
      "eval_samples_per_second": 6.096,
      "eval_steps_per_second": 6.096,
      "step": 12000
    },
    {
      "epoch": 1.8785440912286182,
      "grad_norm": 0.7286854386329651,
      "learning_rate": 5.305030463990002e-05,
      "loss": 1.2998,
      "step": 12025
    },
    {
      "epoch": 1.8824494259158011,
      "grad_norm": 0.876259982585907,
      "learning_rate": 5.2952663646305266e-05,
      "loss": 1.3718,
      "step": 12050
    },
    {
      "epoch": 1.8863547606029836,
      "grad_norm": 0.8706088662147522,
      "learning_rate": 5.285502265271052e-05,
      "loss": 1.3831,
      "step": 12075
    },
    {
      "epoch": 1.8902600952901665,
      "grad_norm": 1.0221946239471436,
      "learning_rate": 5.2757381659115766e-05,
      "loss": 1.3616,
      "step": 12100
    },
    {
      "epoch": 1.894165429977349,
      "grad_norm": 0.724025309085846,
      "learning_rate": 5.265974066552102e-05,
      "loss": 1.3548,
      "step": 12125
    },
    {
      "epoch": 1.8980707646645318,
      "grad_norm": 0.7790807485580444,
      "learning_rate": 5.2562099671926267e-05,
      "loss": 1.3895,
      "step": 12150
    },
    {
      "epoch": 1.9019760993517143,
      "grad_norm": 1.163106083869934,
      "learning_rate": 5.246445867833152e-05,
      "loss": 1.3846,
      "step": 12175
    },
    {
      "epoch": 1.9058814340388972,
      "grad_norm": 0.7226018905639648,
      "learning_rate": 5.236681768473676e-05,
      "loss": 1.3084,
      "step": 12200
    },
    {
      "epoch": 1.9097867687260797,
      "grad_norm": 0.6894704699516296,
      "learning_rate": 5.226917669114201e-05,
      "loss": 1.3114,
      "step": 12225
    },
    {
      "epoch": 1.9136921034132626,
      "grad_norm": 0.7018880844116211,
      "learning_rate": 5.217153569754726e-05,
      "loss": 1.3367,
      "step": 12250
    },
    {
      "epoch": 1.9175974381004453,
      "grad_norm": 1.1130802631378174,
      "learning_rate": 5.207389470395251e-05,
      "loss": 1.3588,
      "step": 12275
    },
    {
      "epoch": 1.921502772787628,
      "grad_norm": 0.8616214990615845,
      "learning_rate": 5.197625371035776e-05,
      "loss": 1.3374,
      "step": 12300
    },
    {
      "epoch": 1.9254081074748106,
      "grad_norm": 1.0426561832427979,
      "learning_rate": 5.187861271676301e-05,
      "loss": 1.3253,
      "step": 12325
    },
    {
      "epoch": 1.9293134421619933,
      "grad_norm": 0.6884651184082031,
      "learning_rate": 5.178097172316826e-05,
      "loss": 1.3387,
      "step": 12350
    },
    {
      "epoch": 1.933218776849176,
      "grad_norm": 0.8176444172859192,
      "learning_rate": 5.168333072957351e-05,
      "loss": 1.3634,
      "step": 12375
    },
    {
      "epoch": 1.9371241115363587,
      "grad_norm": 0.6953847408294678,
      "learning_rate": 5.158568973597876e-05,
      "loss": 1.3438,
      "step": 12400
    },
    {
      "epoch": 1.9410294462235413,
      "grad_norm": 1.708151936531067,
      "learning_rate": 5.148804874238401e-05,
      "loss": 1.2752,
      "step": 12425
    },
    {
      "epoch": 1.944934780910724,
      "grad_norm": 0.7255861163139343,
      "learning_rate": 5.139040774878925e-05,
      "loss": 1.3679,
      "step": 12450
    },
    {
      "epoch": 1.9488401155979067,
      "grad_norm": 0.6945902109146118,
      "learning_rate": 5.1292766755194496e-05,
      "loss": 1.3806,
      "step": 12475
    },
    {
      "epoch": 1.9527454502850894,
      "grad_norm": 0.7466607689857483,
      "learning_rate": 5.119512576159975e-05,
      "loss": 1.2858,
      "step": 12500
    },
    {
      "epoch": 1.956650784972272,
      "grad_norm": 0.6845008134841919,
      "learning_rate": 5.1097484768004996e-05,
      "loss": 1.2775,
      "step": 12525
    },
    {
      "epoch": 1.9605561196594548,
      "grad_norm": 0.7795363664627075,
      "learning_rate": 5.099984377441025e-05,
      "loss": 1.3295,
      "step": 12550
    },
    {
      "epoch": 1.9644614543466377,
      "grad_norm": 1.1081613302230835,
      "learning_rate": 5.09022027808155e-05,
      "loss": 1.32,
      "step": 12575
    },
    {
      "epoch": 1.9683667890338201,
      "grad_norm": 0.5897329449653625,
      "learning_rate": 5.080456178722075e-05,
      "loss": 1.3982,
      "step": 12600
    },
    {
      "epoch": 1.972272123721003,
      "grad_norm": 0.7627431750297546,
      "learning_rate": 5.0706920793626e-05,
      "loss": 1.3793,
      "step": 12625
    },
    {
      "epoch": 1.9761774584081855,
      "grad_norm": 0.777382493019104,
      "learning_rate": 5.060927980003125e-05,
      "loss": 1.3978,
      "step": 12650
    },
    {
      "epoch": 1.9800827930953684,
      "grad_norm": 0.7570546865463257,
      "learning_rate": 5.05116388064365e-05,
      "loss": 1.4417,
      "step": 12675
    },
    {
      "epoch": 1.9839881277825508,
      "grad_norm": 0.6211270093917847,
      "learning_rate": 5.041399781284175e-05,
      "loss": 1.3567,
      "step": 12700
    },
    {
      "epoch": 1.9878934624697338,
      "grad_norm": 1.323318600654602,
      "learning_rate": 5.031635681924699e-05,
      "loss": 1.331,
      "step": 12725
    },
    {
      "epoch": 1.9917987971569162,
      "grad_norm": 0.6921694874763489,
      "learning_rate": 5.021871582565224e-05,
      "loss": 1.3436,
      "step": 12750
    },
    {
      "epoch": 1.9957041318440991,
      "grad_norm": 0.6609841585159302,
      "learning_rate": 5.012107483205749e-05,
      "loss": 1.3136,
      "step": 12775
    },
    {
      "epoch": 1.9996094665312816,
      "grad_norm": 0.7500146627426147,
      "learning_rate": 5.002343383846274e-05,
      "loss": 1.3087,
      "step": 12800
    }
  ],
  "logging_steps": 25,
  "max_steps": 25604,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.31452524374682e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
