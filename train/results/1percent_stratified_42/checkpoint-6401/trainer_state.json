{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999218933062564,
  "eval_steps": 1000,
  "global_step": 6401,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0039053346871826917,
      "grad_norm": 3.2465217113494873,
      "learning_rate": 9.9609436025621e-05,
      "loss": 2.1021,
      "step": 25
    },
    {
      "epoch": 0.007810669374365383,
      "grad_norm": 1.1683964729309082,
      "learning_rate": 9.921887205124199e-05,
      "loss": 1.6778,
      "step": 50
    },
    {
      "epoch": 0.011716004061548074,
      "grad_norm": 1.0458828210830688,
      "learning_rate": 9.8828308076863e-05,
      "loss": 1.6162,
      "step": 75
    },
    {
      "epoch": 0.015621338748730767,
      "grad_norm": 1.1215345859527588,
      "learning_rate": 9.843774410248398e-05,
      "loss": 1.5214,
      "step": 100
    },
    {
      "epoch": 0.01952667343591346,
      "grad_norm": 0.8124238848686218,
      "learning_rate": 9.804718012810498e-05,
      "loss": 1.551,
      "step": 125
    },
    {
      "epoch": 0.02343200812309615,
      "grad_norm": 1.1576467752456665,
      "learning_rate": 9.765661615372598e-05,
      "loss": 1.5233,
      "step": 150
    },
    {
      "epoch": 0.02733734281027884,
      "grad_norm": 0.9178279042243958,
      "learning_rate": 9.726605217934698e-05,
      "loss": 1.4985,
      "step": 175
    },
    {
      "epoch": 0.031242677497461534,
      "grad_norm": 0.9064067602157593,
      "learning_rate": 9.687548820496799e-05,
      "loss": 1.5261,
      "step": 200
    },
    {
      "epoch": 0.03514801218464422,
      "grad_norm": 0.9114634394645691,
      "learning_rate": 9.648492423058899e-05,
      "loss": 1.4715,
      "step": 225
    },
    {
      "epoch": 0.03905334687182692,
      "grad_norm": 1.2622907161712646,
      "learning_rate": 9.609436025620997e-05,
      "loss": 1.5396,
      "step": 250
    },
    {
      "epoch": 0.04295868155900961,
      "grad_norm": 1.2203083038330078,
      "learning_rate": 9.570379628183097e-05,
      "loss": 1.4599,
      "step": 275
    },
    {
      "epoch": 0.0468640162461923,
      "grad_norm": 1.0415164232254028,
      "learning_rate": 9.531323230745196e-05,
      "loss": 1.4784,
      "step": 300
    },
    {
      "epoch": 0.05076935093337499,
      "grad_norm": 1.1780155897140503,
      "learning_rate": 9.492266833307296e-05,
      "loss": 1.4008,
      "step": 325
    },
    {
      "epoch": 0.05467468562055768,
      "grad_norm": 0.9165364503860474,
      "learning_rate": 9.453210435869396e-05,
      "loss": 1.38,
      "step": 350
    },
    {
      "epoch": 0.05858002030774037,
      "grad_norm": 1.247885823249817,
      "learning_rate": 9.414154038431495e-05,
      "loss": 1.4829,
      "step": 375
    },
    {
      "epoch": 0.06248535499492307,
      "grad_norm": 0.8763705492019653,
      "learning_rate": 9.375097640993595e-05,
      "loss": 1.4248,
      "step": 400
    },
    {
      "epoch": 0.06639068968210575,
      "grad_norm": 1.141935110092163,
      "learning_rate": 9.336041243555694e-05,
      "loss": 1.4143,
      "step": 425
    },
    {
      "epoch": 0.07029602436928845,
      "grad_norm": 0.7177324891090393,
      "learning_rate": 9.296984846117794e-05,
      "loss": 1.4389,
      "step": 450
    },
    {
      "epoch": 0.07420135905647114,
      "grad_norm": 0.8669571876525879,
      "learning_rate": 9.257928448679894e-05,
      "loss": 1.391,
      "step": 475
    },
    {
      "epoch": 0.07810669374365384,
      "grad_norm": 1.1431673765182495,
      "learning_rate": 9.218872051241993e-05,
      "loss": 1.427,
      "step": 500
    },
    {
      "epoch": 0.08201202843083652,
      "grad_norm": 0.8612999320030212,
      "learning_rate": 9.179815653804093e-05,
      "loss": 1.4743,
      "step": 525
    },
    {
      "epoch": 0.08591736311801922,
      "grad_norm": 0.7818436622619629,
      "learning_rate": 9.140759256366193e-05,
      "loss": 1.4884,
      "step": 550
    },
    {
      "epoch": 0.08982269780520191,
      "grad_norm": 0.7049092650413513,
      "learning_rate": 9.101702858928293e-05,
      "loss": 1.4361,
      "step": 575
    },
    {
      "epoch": 0.0937280324923846,
      "grad_norm": 0.9018144011497498,
      "learning_rate": 9.062646461490393e-05,
      "loss": 1.4553,
      "step": 600
    },
    {
      "epoch": 0.09763336717956729,
      "grad_norm": 1.1254284381866455,
      "learning_rate": 9.023590064052492e-05,
      "loss": 1.4594,
      "step": 625
    },
    {
      "epoch": 0.10153870186674999,
      "grad_norm": 0.8887649178504944,
      "learning_rate": 8.984533666614592e-05,
      "loss": 1.5094,
      "step": 650
    },
    {
      "epoch": 0.10544403655393267,
      "grad_norm": 0.8469434380531311,
      "learning_rate": 8.945477269176692e-05,
      "loss": 1.4282,
      "step": 675
    },
    {
      "epoch": 0.10934937124111536,
      "grad_norm": 0.8114902973175049,
      "learning_rate": 8.906420871738791e-05,
      "loss": 1.4451,
      "step": 700
    },
    {
      "epoch": 0.11325470592829806,
      "grad_norm": 1.1834198236465454,
      "learning_rate": 8.867364474300891e-05,
      "loss": 1.4714,
      "step": 725
    },
    {
      "epoch": 0.11716004061548074,
      "grad_norm": 0.8823350667953491,
      "learning_rate": 8.828308076862991e-05,
      "loss": 1.4202,
      "step": 750
    },
    {
      "epoch": 0.12106537530266344,
      "grad_norm": 0.7953850030899048,
      "learning_rate": 8.78925167942509e-05,
      "loss": 1.4129,
      "step": 775
    },
    {
      "epoch": 0.12497070998984613,
      "grad_norm": 0.7873246073722839,
      "learning_rate": 8.75019528198719e-05,
      "loss": 1.4156,
      "step": 800
    },
    {
      "epoch": 0.12887604467702882,
      "grad_norm": 0.6885635852813721,
      "learning_rate": 8.711138884549289e-05,
      "loss": 1.4368,
      "step": 825
    },
    {
      "epoch": 0.1327813793642115,
      "grad_norm": 1.1447787284851074,
      "learning_rate": 8.672082487111389e-05,
      "loss": 1.4678,
      "step": 850
    },
    {
      "epoch": 0.1366867140513942,
      "grad_norm": 0.9177465438842773,
      "learning_rate": 8.633026089673489e-05,
      "loss": 1.3658,
      "step": 875
    },
    {
      "epoch": 0.1405920487385769,
      "grad_norm": 1.0802029371261597,
      "learning_rate": 8.593969692235589e-05,
      "loss": 1.3807,
      "step": 900
    },
    {
      "epoch": 0.1444973834257596,
      "grad_norm": 0.7436348795890808,
      "learning_rate": 8.554913294797689e-05,
      "loss": 1.4801,
      "step": 925
    },
    {
      "epoch": 0.14840271811294228,
      "grad_norm": 0.8422478437423706,
      "learning_rate": 8.515856897359788e-05,
      "loss": 1.4181,
      "step": 950
    },
    {
      "epoch": 0.15230805280012497,
      "grad_norm": 0.714457631111145,
      "learning_rate": 8.476800499921888e-05,
      "loss": 1.425,
      "step": 975
    },
    {
      "epoch": 0.15621338748730768,
      "grad_norm": 0.7346399426460266,
      "learning_rate": 8.437744102483988e-05,
      "loss": 1.4406,
      "step": 1000
    },
    {
      "epoch": 0.15621338748730768,
      "eval_loss": 1.4085553884506226,
      "eval_runtime": 1621.4977,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 1000
    },
    {
      "epoch": 0.16011872217449036,
      "grad_norm": 0.7755522131919861,
      "learning_rate": 8.398687705046087e-05,
      "loss": 1.497,
      "step": 1025
    },
    {
      "epoch": 0.16402405686167304,
      "grad_norm": 0.7198747992515564,
      "learning_rate": 8.359631307608187e-05,
      "loss": 1.3876,
      "step": 1050
    },
    {
      "epoch": 0.16792939154885575,
      "grad_norm": 0.7547372579574585,
      "learning_rate": 8.320574910170287e-05,
      "loss": 1.4114,
      "step": 1075
    },
    {
      "epoch": 0.17183472623603843,
      "grad_norm": 0.7939823269844055,
      "learning_rate": 8.281518512732386e-05,
      "loss": 1.3696,
      "step": 1100
    },
    {
      "epoch": 0.17574006092322111,
      "grad_norm": 0.880377471446991,
      "learning_rate": 8.242462115294486e-05,
      "loss": 1.4274,
      "step": 1125
    },
    {
      "epoch": 0.17964539561040382,
      "grad_norm": 1.1362334489822388,
      "learning_rate": 8.203405717856584e-05,
      "loss": 1.4381,
      "step": 1150
    },
    {
      "epoch": 0.1835507302975865,
      "grad_norm": 1.0400172472000122,
      "learning_rate": 8.164349320418685e-05,
      "loss": 1.3768,
      "step": 1175
    },
    {
      "epoch": 0.1874560649847692,
      "grad_norm": 0.9381090402603149,
      "learning_rate": 8.125292922980785e-05,
      "loss": 1.3723,
      "step": 1200
    },
    {
      "epoch": 0.1913613996719519,
      "grad_norm": 0.6042956113815308,
      "learning_rate": 8.086236525542883e-05,
      "loss": 1.4514,
      "step": 1225
    },
    {
      "epoch": 0.19526673435913458,
      "grad_norm": 0.8863415122032166,
      "learning_rate": 8.047180128104984e-05,
      "loss": 1.4024,
      "step": 1250
    },
    {
      "epoch": 0.19917206904631726,
      "grad_norm": 0.8462222814559937,
      "learning_rate": 8.008123730667084e-05,
      "loss": 1.443,
      "step": 1275
    },
    {
      "epoch": 0.20307740373349997,
      "grad_norm": 0.6853643655776978,
      "learning_rate": 7.969067333229184e-05,
      "loss": 1.3688,
      "step": 1300
    },
    {
      "epoch": 0.20698273842068265,
      "grad_norm": 1.452087163925171,
      "learning_rate": 7.930010935791284e-05,
      "loss": 1.3644,
      "step": 1325
    },
    {
      "epoch": 0.21088807310786534,
      "grad_norm": 0.9469685554504395,
      "learning_rate": 7.890954538353383e-05,
      "loss": 1.4085,
      "step": 1350
    },
    {
      "epoch": 0.21479340779504805,
      "grad_norm": 0.8635916709899902,
      "learning_rate": 7.851898140915483e-05,
      "loss": 1.4282,
      "step": 1375
    },
    {
      "epoch": 0.21869874248223073,
      "grad_norm": 0.819979727268219,
      "learning_rate": 7.812841743477583e-05,
      "loss": 1.4151,
      "step": 1400
    },
    {
      "epoch": 0.2226040771694134,
      "grad_norm": 0.6791641116142273,
      "learning_rate": 7.773785346039681e-05,
      "loss": 1.4202,
      "step": 1425
    },
    {
      "epoch": 0.22650941185659612,
      "grad_norm": 0.9602513909339905,
      "learning_rate": 7.734728948601782e-05,
      "loss": 1.3821,
      "step": 1450
    },
    {
      "epoch": 0.2304147465437788,
      "grad_norm": 0.9818315505981445,
      "learning_rate": 7.69567255116388e-05,
      "loss": 1.4221,
      "step": 1475
    },
    {
      "epoch": 0.23432008123096149,
      "grad_norm": 0.883847177028656,
      "learning_rate": 7.65661615372598e-05,
      "loss": 1.3867,
      "step": 1500
    },
    {
      "epoch": 0.2382254159181442,
      "grad_norm": 0.8888888955116272,
      "learning_rate": 7.61755975628808e-05,
      "loss": 1.4057,
      "step": 1525
    },
    {
      "epoch": 0.24213075060532688,
      "grad_norm": 0.791121780872345,
      "learning_rate": 7.578503358850179e-05,
      "loss": 1.3807,
      "step": 1550
    },
    {
      "epoch": 0.24603608529250956,
      "grad_norm": 0.6994274854660034,
      "learning_rate": 7.539446961412279e-05,
      "loss": 1.3847,
      "step": 1575
    },
    {
      "epoch": 0.24994141997969227,
      "grad_norm": 0.8135121464729309,
      "learning_rate": 7.50039056397438e-05,
      "loss": 1.4215,
      "step": 1600
    },
    {
      "epoch": 0.25384675466687495,
      "grad_norm": 0.6589803099632263,
      "learning_rate": 7.46133416653648e-05,
      "loss": 1.3883,
      "step": 1625
    },
    {
      "epoch": 0.25775208935405763,
      "grad_norm": 0.7393799424171448,
      "learning_rate": 7.42227776909858e-05,
      "loss": 1.4246,
      "step": 1650
    },
    {
      "epoch": 0.2616574240412403,
      "grad_norm": 0.8831437230110168,
      "learning_rate": 7.383221371660678e-05,
      "loss": 1.3648,
      "step": 1675
    },
    {
      "epoch": 0.265562758728423,
      "grad_norm": 0.920042097568512,
      "learning_rate": 7.344164974222778e-05,
      "loss": 1.3967,
      "step": 1700
    },
    {
      "epoch": 0.26946809341560574,
      "grad_norm": 0.885888934135437,
      "learning_rate": 7.305108576784879e-05,
      "loss": 1.3872,
      "step": 1725
    },
    {
      "epoch": 0.2733734281027884,
      "grad_norm": 1.0735024213790894,
      "learning_rate": 7.266052179346977e-05,
      "loss": 1.3957,
      "step": 1750
    },
    {
      "epoch": 0.2772787627899711,
      "grad_norm": 0.9115954637527466,
      "learning_rate": 7.226995781909077e-05,
      "loss": 1.3945,
      "step": 1775
    },
    {
      "epoch": 0.2811840974771538,
      "grad_norm": 0.8568029403686523,
      "learning_rate": 7.187939384471176e-05,
      "loss": 1.3863,
      "step": 1800
    },
    {
      "epoch": 0.28508943216433646,
      "grad_norm": 0.6662747263908386,
      "learning_rate": 7.148882987033276e-05,
      "loss": 1.4811,
      "step": 1825
    },
    {
      "epoch": 0.2889947668515192,
      "grad_norm": 1.1174888610839844,
      "learning_rate": 7.109826589595376e-05,
      "loss": 1.3925,
      "step": 1850
    },
    {
      "epoch": 0.2929001015387019,
      "grad_norm": 0.8547325730323792,
      "learning_rate": 7.070770192157475e-05,
      "loss": 1.3573,
      "step": 1875
    },
    {
      "epoch": 0.29680543622588457,
      "grad_norm": 0.8674880266189575,
      "learning_rate": 7.031713794719575e-05,
      "loss": 1.3931,
      "step": 1900
    },
    {
      "epoch": 0.30071077091306725,
      "grad_norm": 0.9799916744232178,
      "learning_rate": 6.992657397281675e-05,
      "loss": 1.435,
      "step": 1925
    },
    {
      "epoch": 0.30461610560024993,
      "grad_norm": 0.8731327056884766,
      "learning_rate": 6.953600999843774e-05,
      "loss": 1.4106,
      "step": 1950
    },
    {
      "epoch": 0.3085214402874326,
      "grad_norm": 0.9855532646179199,
      "learning_rate": 6.914544602405874e-05,
      "loss": 1.443,
      "step": 1975
    },
    {
      "epoch": 0.31242677497461535,
      "grad_norm": 1.0308401584625244,
      "learning_rate": 6.875488204967974e-05,
      "loss": 1.3588,
      "step": 2000
    },
    {
      "epoch": 0.31242677497461535,
      "eval_loss": 1.3906242847442627,
      "eval_runtime": 1621.4924,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 2000
    },
    {
      "epoch": 0.31633210966179803,
      "grad_norm": 0.7043284177780151,
      "learning_rate": 6.836431807530074e-05,
      "loss": 1.4098,
      "step": 2025
    },
    {
      "epoch": 0.3202374443489807,
      "grad_norm": 1.2149544954299927,
      "learning_rate": 6.797375410092174e-05,
      "loss": 1.3782,
      "step": 2050
    },
    {
      "epoch": 0.3241427790361634,
      "grad_norm": 0.6752206683158875,
      "learning_rate": 6.758319012654273e-05,
      "loss": 1.3926,
      "step": 2075
    },
    {
      "epoch": 0.3280481137233461,
      "grad_norm": 0.8697562217712402,
      "learning_rate": 6.719262615216373e-05,
      "loss": 1.4171,
      "step": 2100
    },
    {
      "epoch": 0.33195344841052876,
      "grad_norm": 0.8683820962905884,
      "learning_rate": 6.680206217778472e-05,
      "loss": 1.3641,
      "step": 2125
    },
    {
      "epoch": 0.3358587830977115,
      "grad_norm": 0.9228382110595703,
      "learning_rate": 6.641149820340572e-05,
      "loss": 1.3736,
      "step": 2150
    },
    {
      "epoch": 0.3397641177848942,
      "grad_norm": 0.7752336859703064,
      "learning_rate": 6.602093422902672e-05,
      "loss": 1.386,
      "step": 2175
    },
    {
      "epoch": 0.34366945247207686,
      "grad_norm": 0.7451473474502563,
      "learning_rate": 6.563037025464771e-05,
      "loss": 1.431,
      "step": 2200
    },
    {
      "epoch": 0.34757478715925955,
      "grad_norm": 0.9055505990982056,
      "learning_rate": 6.523980628026871e-05,
      "loss": 1.4389,
      "step": 2225
    },
    {
      "epoch": 0.35148012184644223,
      "grad_norm": 0.9343944787979126,
      "learning_rate": 6.484924230588971e-05,
      "loss": 1.373,
      "step": 2250
    },
    {
      "epoch": 0.3553854565336249,
      "grad_norm": 0.8370698094367981,
      "learning_rate": 6.44586783315107e-05,
      "loss": 1.4104,
      "step": 2275
    },
    {
      "epoch": 0.35929079122080765,
      "grad_norm": 0.6486676931381226,
      "learning_rate": 6.40681143571317e-05,
      "loss": 1.4103,
      "step": 2300
    },
    {
      "epoch": 0.36319612590799033,
      "grad_norm": 1.0935900211334229,
      "learning_rate": 6.369317294172786e-05,
      "loss": 1.4174,
      "step": 2325
    },
    {
      "epoch": 0.367101460595173,
      "grad_norm": 0.8440026640892029,
      "learning_rate": 6.330260896734885e-05,
      "loss": 1.3951,
      "step": 2350
    },
    {
      "epoch": 0.3710067952823557,
      "grad_norm": 0.8636385202407837,
      "learning_rate": 6.291204499296985e-05,
      "loss": 1.3864,
      "step": 2375
    },
    {
      "epoch": 0.3749121299695384,
      "grad_norm": 1.0544004440307617,
      "learning_rate": 6.252148101859084e-05,
      "loss": 1.4254,
      "step": 2400
    },
    {
      "epoch": 0.37881746465672106,
      "grad_norm": 1.2913252115249634,
      "learning_rate": 6.213091704421184e-05,
      "loss": 1.4154,
      "step": 2425
    },
    {
      "epoch": 0.3827227993439038,
      "grad_norm": 0.9033505916595459,
      "learning_rate": 6.174035306983284e-05,
      "loss": 1.4078,
      "step": 2450
    },
    {
      "epoch": 0.3866281340310865,
      "grad_norm": 1.5760395526885986,
      "learning_rate": 6.134978909545384e-05,
      "loss": 1.4163,
      "step": 2475
    },
    {
      "epoch": 0.39053346871826916,
      "grad_norm": 0.8405604958534241,
      "learning_rate": 6.0959225121074834e-05,
      "loss": 1.3473,
      "step": 2500
    },
    {
      "epoch": 0.39443880340545184,
      "grad_norm": 1.1086634397506714,
      "learning_rate": 6.056866114669583e-05,
      "loss": 1.3528,
      "step": 2525
    },
    {
      "epoch": 0.3983441380926345,
      "grad_norm": 0.8433387875556946,
      "learning_rate": 6.017809717231683e-05,
      "loss": 1.448,
      "step": 2550
    },
    {
      "epoch": 0.4022494727798172,
      "grad_norm": 0.8500542640686035,
      "learning_rate": 5.978753319793783e-05,
      "loss": 1.4054,
      "step": 2575
    },
    {
      "epoch": 0.40615480746699995,
      "grad_norm": 0.860120415687561,
      "learning_rate": 5.939696922355882e-05,
      "loss": 1.4298,
      "step": 2600
    },
    {
      "epoch": 0.4100601421541826,
      "grad_norm": 0.688825249671936,
      "learning_rate": 5.900640524917982e-05,
      "loss": 1.385,
      "step": 2625
    },
    {
      "epoch": 0.4139654768413653,
      "grad_norm": 0.8465675115585327,
      "learning_rate": 5.861584127480082e-05,
      "loss": 1.3763,
      "step": 2650
    },
    {
      "epoch": 0.417870811528548,
      "grad_norm": 1.2347468137741089,
      "learning_rate": 5.822527730042181e-05,
      "loss": 1.3925,
      "step": 2675
    },
    {
      "epoch": 0.4217761462157307,
      "grad_norm": 1.2148834466934204,
      "learning_rate": 5.783471332604281e-05,
      "loss": 1.3894,
      "step": 2700
    },
    {
      "epoch": 0.42568148090291336,
      "grad_norm": 0.8276163339614868,
      "learning_rate": 5.74441493516638e-05,
      "loss": 1.3941,
      "step": 2725
    },
    {
      "epoch": 0.4295868155900961,
      "grad_norm": 0.7274352312088013,
      "learning_rate": 5.70535853772848e-05,
      "loss": 1.4233,
      "step": 2750
    },
    {
      "epoch": 0.4334921502772788,
      "grad_norm": 0.8085888624191284,
      "learning_rate": 5.6663021402905804e-05,
      "loss": 1.3764,
      "step": 2775
    },
    {
      "epoch": 0.43739748496446146,
      "grad_norm": 0.8890697956085205,
      "learning_rate": 5.627245742852679e-05,
      "loss": 1.3698,
      "step": 2800
    },
    {
      "epoch": 0.44130281965164414,
      "grad_norm": 0.7871195077896118,
      "learning_rate": 5.588189345414779e-05,
      "loss": 1.4277,
      "step": 2825
    },
    {
      "epoch": 0.4452081543388268,
      "grad_norm": 0.7770936489105225,
      "learning_rate": 5.5491329479768787e-05,
      "loss": 1.3841,
      "step": 2850
    },
    {
      "epoch": 0.4491134890260095,
      "grad_norm": 0.7169707417488098,
      "learning_rate": 5.510076550538979e-05,
      "loss": 1.4128,
      "step": 2875
    },
    {
      "epoch": 0.45301882371319224,
      "grad_norm": 0.824567437171936,
      "learning_rate": 5.471020153101079e-05,
      "loss": 1.39,
      "step": 2900
    },
    {
      "epoch": 0.4569241584003749,
      "grad_norm": 0.7587940096855164,
      "learning_rate": 5.4319637556631776e-05,
      "loss": 1.3886,
      "step": 2925
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 0.9113674759864807,
      "learning_rate": 5.392907358225278e-05,
      "loss": 1.3662,
      "step": 2950
    },
    {
      "epoch": 0.4647348277747403,
      "grad_norm": 0.7056671380996704,
      "learning_rate": 5.353850960787378e-05,
      "loss": 1.3772,
      "step": 2975
    },
    {
      "epoch": 0.46864016246192297,
      "grad_norm": 1.3100237846374512,
      "learning_rate": 5.3147945633494765e-05,
      "loss": 1.3781,
      "step": 3000
    },
    {
      "epoch": 0.46864016246192297,
      "eval_loss": 1.3806625604629517,
      "eval_runtime": 1621.5533,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 3000
    },
    {
      "epoch": 0.47254549714910565,
      "grad_norm": 0.9259299635887146,
      "learning_rate": 5.2757381659115766e-05,
      "loss": 1.3941,
      "step": 3025
    },
    {
      "epoch": 0.4764508318362884,
      "grad_norm": 1.0350550413131714,
      "learning_rate": 5.236681768473676e-05,
      "loss": 1.3685,
      "step": 3050
    },
    {
      "epoch": 0.4803561665234711,
      "grad_norm": 0.7242240309715271,
      "learning_rate": 5.197625371035776e-05,
      "loss": 1.4776,
      "step": 3075
    },
    {
      "epoch": 0.48426150121065376,
      "grad_norm": 1.0832544565200806,
      "learning_rate": 5.158568973597876e-05,
      "loss": 1.4344,
      "step": 3100
    },
    {
      "epoch": 0.48816683589783644,
      "grad_norm": 0.7072556018829346,
      "learning_rate": 5.119512576159975e-05,
      "loss": 1.3611,
      "step": 3125
    },
    {
      "epoch": 0.4920721705850191,
      "grad_norm": 0.7741387486457825,
      "learning_rate": 5.080456178722075e-05,
      "loss": 1.3342,
      "step": 3150
    },
    {
      "epoch": 0.4959775052722018,
      "grad_norm": 0.7482285499572754,
      "learning_rate": 5.041399781284175e-05,
      "loss": 1.3706,
      "step": 3175
    },
    {
      "epoch": 0.49988283995938454,
      "grad_norm": 0.9397870302200317,
      "learning_rate": 5.002343383846274e-05,
      "loss": 1.3911,
      "step": 3200
    },
    {
      "epoch": 0.5037881746465672,
      "grad_norm": 1.3380074501037598,
      "learning_rate": 4.963286986408374e-05,
      "loss": 1.3817,
      "step": 3225
    },
    {
      "epoch": 0.5076935093337499,
      "grad_norm": 1.1256049871444702,
      "learning_rate": 4.924230588970474e-05,
      "loss": 1.3473,
      "step": 3250
    },
    {
      "epoch": 0.5115988440209326,
      "grad_norm": 0.8798999786376953,
      "learning_rate": 4.8851741915325735e-05,
      "loss": 1.4274,
      "step": 3275
    },
    {
      "epoch": 0.5155041787081153,
      "grad_norm": 0.7999401092529297,
      "learning_rate": 4.846117794094673e-05,
      "loss": 1.4047,
      "step": 3300
    },
    {
      "epoch": 0.519409513395298,
      "grad_norm": 0.6698806285858154,
      "learning_rate": 4.807061396656772e-05,
      "loss": 1.35,
      "step": 3325
    },
    {
      "epoch": 0.5233148480824806,
      "grad_norm": 0.8130303621292114,
      "learning_rate": 4.7680049992188724e-05,
      "loss": 1.4038,
      "step": 3350
    },
    {
      "epoch": 0.5272201827696633,
      "grad_norm": 1.296355128288269,
      "learning_rate": 4.728948601780972e-05,
      "loss": 1.3506,
      "step": 3375
    },
    {
      "epoch": 0.531125517456846,
      "grad_norm": 0.9970064759254456,
      "learning_rate": 4.689892204343071e-05,
      "loss": 1.4195,
      "step": 3400
    },
    {
      "epoch": 0.5350308521440288,
      "grad_norm": 0.8253654837608337,
      "learning_rate": 4.6508358069051713e-05,
      "loss": 1.3936,
      "step": 3425
    },
    {
      "epoch": 0.5389361868312115,
      "grad_norm": 1.8508747816085815,
      "learning_rate": 4.6117794094672714e-05,
      "loss": 1.4283,
      "step": 3450
    },
    {
      "epoch": 0.5428415215183942,
      "grad_norm": 0.7999590635299683,
      "learning_rate": 4.572723012029371e-05,
      "loss": 1.327,
      "step": 3475
    },
    {
      "epoch": 0.5467468562055768,
      "grad_norm": 0.7973755598068237,
      "learning_rate": 4.53366661459147e-05,
      "loss": 1.3583,
      "step": 3500
    },
    {
      "epoch": 0.5506521908927595,
      "grad_norm": 0.8767470121383667,
      "learning_rate": 4.49461021715357e-05,
      "loss": 1.4173,
      "step": 3525
    },
    {
      "epoch": 0.5545575255799422,
      "grad_norm": 0.8256537318229675,
      "learning_rate": 4.45555381971567e-05,
      "loss": 1.3849,
      "step": 3550
    },
    {
      "epoch": 0.5584628602671249,
      "grad_norm": 0.7352432012557983,
      "learning_rate": 4.416497422277769e-05,
      "loss": 1.3562,
      "step": 3575
    },
    {
      "epoch": 0.5623681949543076,
      "grad_norm": 0.7893133163452148,
      "learning_rate": 4.3774410248398686e-05,
      "loss": 1.3458,
      "step": 3600
    },
    {
      "epoch": 0.5662735296414902,
      "grad_norm": 0.6675043106079102,
      "learning_rate": 4.338384627401969e-05,
      "loss": 1.3503,
      "step": 3625
    },
    {
      "epoch": 0.5701788643286729,
      "grad_norm": 0.7892453670501709,
      "learning_rate": 4.299328229964069e-05,
      "loss": 1.4059,
      "step": 3650
    },
    {
      "epoch": 0.5740841990158556,
      "grad_norm": 1.0979344844818115,
      "learning_rate": 4.260271832526168e-05,
      "loss": 1.4222,
      "step": 3675
    },
    {
      "epoch": 0.5779895337030384,
      "grad_norm": 1.1182317733764648,
      "learning_rate": 4.2212154350882676e-05,
      "loss": 1.3518,
      "step": 3700
    },
    {
      "epoch": 0.5818948683902211,
      "grad_norm": 0.7349278330802917,
      "learning_rate": 4.182159037650367e-05,
      "loss": 1.3484,
      "step": 3725
    },
    {
      "epoch": 0.5858002030774038,
      "grad_norm": 0.9451165199279785,
      "learning_rate": 4.1431026402124665e-05,
      "loss": 1.3595,
      "step": 3750
    },
    {
      "epoch": 0.5897055377645865,
      "grad_norm": 0.8639544248580933,
      "learning_rate": 4.1040462427745666e-05,
      "loss": 1.3577,
      "step": 3775
    },
    {
      "epoch": 0.5936108724517691,
      "grad_norm": 0.7390472888946533,
      "learning_rate": 4.0649898453366667e-05,
      "loss": 1.3573,
      "step": 3800
    },
    {
      "epoch": 0.5975162071389518,
      "grad_norm": 0.9243931770324707,
      "learning_rate": 4.025933447898766e-05,
      "loss": 1.3918,
      "step": 3825
    },
    {
      "epoch": 0.6014215418261345,
      "grad_norm": 0.7551735043525696,
      "learning_rate": 3.9868770504608655e-05,
      "loss": 1.3817,
      "step": 3850
    },
    {
      "epoch": 0.6053268765133172,
      "grad_norm": 1.2113673686981201,
      "learning_rate": 3.9478206530229656e-05,
      "loss": 1.3977,
      "step": 3875
    },
    {
      "epoch": 0.6092322112004999,
      "grad_norm": 0.9740294814109802,
      "learning_rate": 3.908764255585065e-05,
      "loss": 1.3481,
      "step": 3900
    },
    {
      "epoch": 0.6131375458876825,
      "grad_norm": 0.6352384686470032,
      "learning_rate": 3.8697078581471644e-05,
      "loss": 1.3798,
      "step": 3925
    },
    {
      "epoch": 0.6170428805748652,
      "grad_norm": 0.992870569229126,
      "learning_rate": 3.830651460709264e-05,
      "loss": 1.4388,
      "step": 3950
    },
    {
      "epoch": 0.6209482152620479,
      "grad_norm": 0.7837244272232056,
      "learning_rate": 3.791595063271364e-05,
      "loss": 1.4264,
      "step": 3975
    },
    {
      "epoch": 0.6248535499492307,
      "grad_norm": 0.6938894391059875,
      "learning_rate": 3.752538665833464e-05,
      "loss": 1.3434,
      "step": 4000
    },
    {
      "epoch": 0.6248535499492307,
      "eval_loss": 1.374707818031311,
      "eval_runtime": 1621.4987,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 4000
    },
    {
      "epoch": 0.6287588846364134,
      "grad_norm": 0.7759961485862732,
      "learning_rate": 3.7134822683955634e-05,
      "loss": 1.3547,
      "step": 4025
    },
    {
      "epoch": 0.6326642193235961,
      "grad_norm": 1.0880918502807617,
      "learning_rate": 3.674425870957663e-05,
      "loss": 1.3858,
      "step": 4050
    },
    {
      "epoch": 0.6365695540107787,
      "grad_norm": 0.7066709995269775,
      "learning_rate": 3.635369473519763e-05,
      "loss": 1.3205,
      "step": 4075
    },
    {
      "epoch": 0.6404748886979614,
      "grad_norm": 0.9959076642990112,
      "learning_rate": 3.5963130760818624e-05,
      "loss": 1.4053,
      "step": 4100
    },
    {
      "epoch": 0.6443802233851441,
      "grad_norm": 0.7303863763809204,
      "learning_rate": 3.557256678643962e-05,
      "loss": 1.3596,
      "step": 4125
    },
    {
      "epoch": 0.6482855580723268,
      "grad_norm": 0.9452314376831055,
      "learning_rate": 3.5197625371035774e-05,
      "loss": 1.3883,
      "step": 4150
    },
    {
      "epoch": 0.6521908927595095,
      "grad_norm": 0.63216233253479,
      "learning_rate": 3.4807061396656775e-05,
      "loss": 1.3509,
      "step": 4175
    },
    {
      "epoch": 0.6560962274466922,
      "grad_norm": 0.7277505397796631,
      "learning_rate": 3.441649742227777e-05,
      "loss": 1.4006,
      "step": 4200
    },
    {
      "epoch": 0.6600015621338748,
      "grad_norm": 1.0276042222976685,
      "learning_rate": 3.4025933447898763e-05,
      "loss": 1.3833,
      "step": 4225
    },
    {
      "epoch": 0.6639068968210575,
      "grad_norm": 0.7151803970336914,
      "learning_rate": 3.3635369473519764e-05,
      "loss": 1.4063,
      "step": 4250
    },
    {
      "epoch": 0.6678122315082402,
      "grad_norm": 0.7613582611083984,
      "learning_rate": 3.3244805499140765e-05,
      "loss": 1.3904,
      "step": 4275
    },
    {
      "epoch": 0.671717566195423,
      "grad_norm": 0.7099894881248474,
      "learning_rate": 3.285424152476176e-05,
      "loss": 1.3507,
      "step": 4300
    },
    {
      "epoch": 0.6756229008826057,
      "grad_norm": 0.7098227739334106,
      "learning_rate": 3.2463677550382754e-05,
      "loss": 1.3881,
      "step": 4325
    },
    {
      "epoch": 0.6795282355697884,
      "grad_norm": 0.7104899883270264,
      "learning_rate": 3.207311357600375e-05,
      "loss": 1.3913,
      "step": 4350
    },
    {
      "epoch": 0.683433570256971,
      "grad_norm": 0.7885285019874573,
      "learning_rate": 3.168254960162475e-05,
      "loss": 1.4019,
      "step": 4375
    },
    {
      "epoch": 0.6873389049441537,
      "grad_norm": 0.6337634325027466,
      "learning_rate": 3.129198562724574e-05,
      "loss": 1.3853,
      "step": 4400
    },
    {
      "epoch": 0.6912442396313364,
      "grad_norm": 0.6504437327384949,
      "learning_rate": 3.0901421652866744e-05,
      "loss": 1.3544,
      "step": 4425
    },
    {
      "epoch": 0.6951495743185191,
      "grad_norm": 0.7963951826095581,
      "learning_rate": 3.0510857678487738e-05,
      "loss": 1.3272,
      "step": 4450
    },
    {
      "epoch": 0.6990549090057018,
      "grad_norm": 0.7555502653121948,
      "learning_rate": 3.0120293704108732e-05,
      "loss": 1.3928,
      "step": 4475
    },
    {
      "epoch": 0.7029602436928845,
      "grad_norm": 1.0637465715408325,
      "learning_rate": 2.9729729729729733e-05,
      "loss": 1.3604,
      "step": 4500
    },
    {
      "epoch": 0.7068655783800671,
      "grad_norm": 0.9426074028015137,
      "learning_rate": 2.9339165755350727e-05,
      "loss": 1.3297,
      "step": 4525
    },
    {
      "epoch": 0.7107709130672498,
      "grad_norm": 0.7872856259346008,
      "learning_rate": 2.8948601780971725e-05,
      "loss": 1.3395,
      "step": 4550
    },
    {
      "epoch": 0.7146762477544325,
      "grad_norm": 0.7172676920890808,
      "learning_rate": 2.855803780659272e-05,
      "loss": 1.3647,
      "step": 4575
    },
    {
      "epoch": 0.7185815824416153,
      "grad_norm": 0.7403597235679626,
      "learning_rate": 2.816747383221372e-05,
      "loss": 1.3398,
      "step": 4600
    },
    {
      "epoch": 0.722486917128798,
      "grad_norm": 0.7226228713989258,
      "learning_rate": 2.7776909857834714e-05,
      "loss": 1.3733,
      "step": 4625
    },
    {
      "epoch": 0.7263922518159807,
      "grad_norm": 1.1710747480392456,
      "learning_rate": 2.7386345883455712e-05,
      "loss": 1.3405,
      "step": 4650
    },
    {
      "epoch": 0.7302975865031633,
      "grad_norm": 1.2863526344299316,
      "learning_rate": 2.6995781909076706e-05,
      "loss": 1.4175,
      "step": 4675
    },
    {
      "epoch": 0.734202921190346,
      "grad_norm": 1.0372915267944336,
      "learning_rate": 2.6605217934697707e-05,
      "loss": 1.4226,
      "step": 4700
    },
    {
      "epoch": 0.7381082558775287,
      "grad_norm": 0.8038696050643921,
      "learning_rate": 2.62146539603187e-05,
      "loss": 1.3905,
      "step": 4725
    },
    {
      "epoch": 0.7420135905647114,
      "grad_norm": 0.739514946937561,
      "learning_rate": 2.58240899859397e-05,
      "loss": 1.3712,
      "step": 4750
    },
    {
      "epoch": 0.7459189252518941,
      "grad_norm": 0.894993007183075,
      "learning_rate": 2.5433526011560693e-05,
      "loss": 1.4259,
      "step": 4775
    },
    {
      "epoch": 0.7498242599390768,
      "grad_norm": 1.2273099422454834,
      "learning_rate": 2.5042962037181694e-05,
      "loss": 1.4285,
      "step": 4800
    },
    {
      "epoch": 0.7537295946262594,
      "grad_norm": 0.7948921322822571,
      "learning_rate": 2.465239806280269e-05,
      "loss": 1.3426,
      "step": 4825
    },
    {
      "epoch": 0.7576349293134421,
      "grad_norm": 1.1094671487808228,
      "learning_rate": 2.4261834088423685e-05,
      "loss": 1.3318,
      "step": 4850
    },
    {
      "epoch": 0.7615402640006248,
      "grad_norm": 0.8157749772071838,
      "learning_rate": 2.387127011404468e-05,
      "loss": 1.3405,
      "step": 4875
    },
    {
      "epoch": 0.7654455986878076,
      "grad_norm": 0.7799833416938782,
      "learning_rate": 2.3480706139665677e-05,
      "loss": 1.3339,
      "step": 4900
    },
    {
      "epoch": 0.7693509333749903,
      "grad_norm": 0.8015526533126831,
      "learning_rate": 2.3090142165286675e-05,
      "loss": 1.2953,
      "step": 4925
    },
    {
      "epoch": 0.773256268062173,
      "grad_norm": 0.858633816242218,
      "learning_rate": 2.2699578190907672e-05,
      "loss": 1.3411,
      "step": 4950
    },
    {
      "epoch": 0.7771616027493556,
      "grad_norm": 1.0478750467300415,
      "learning_rate": 2.2309014216528666e-05,
      "loss": 1.3921,
      "step": 4975
    },
    {
      "epoch": 0.7810669374365383,
      "grad_norm": 1.0121499300003052,
      "learning_rate": 2.1918450242149667e-05,
      "loss": 1.3156,
      "step": 5000
    },
    {
      "epoch": 0.7810669374365383,
      "eval_loss": 1.371067762374878,
      "eval_runtime": 1621.4957,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 5000
    },
    {
      "epoch": 0.784972272123721,
      "grad_norm": 1.0243319272994995,
      "learning_rate": 2.152788626777066e-05,
      "loss": 1.3745,
      "step": 5025
    },
    {
      "epoch": 0.7888776068109037,
      "grad_norm": 0.8362109065055847,
      "learning_rate": 2.113732229339166e-05,
      "loss": 1.3795,
      "step": 5050
    },
    {
      "epoch": 0.7927829414980864,
      "grad_norm": 0.6398807764053345,
      "learning_rate": 2.0746758319012653e-05,
      "loss": 1.4155,
      "step": 5075
    },
    {
      "epoch": 0.796688276185269,
      "grad_norm": 0.7267706990242004,
      "learning_rate": 2.0356194344633654e-05,
      "loss": 1.336,
      "step": 5100
    },
    {
      "epoch": 0.8005936108724517,
      "grad_norm": 0.7052307724952698,
      "learning_rate": 1.996563037025465e-05,
      "loss": 1.347,
      "step": 5125
    },
    {
      "epoch": 0.8044989455596344,
      "grad_norm": 0.75350421667099,
      "learning_rate": 1.9575066395875646e-05,
      "loss": 1.3944,
      "step": 5150
    },
    {
      "epoch": 0.8084042802468171,
      "grad_norm": 0.8300211429595947,
      "learning_rate": 1.9184502421496643e-05,
      "loss": 1.3492,
      "step": 5175
    },
    {
      "epoch": 0.8123096149339999,
      "grad_norm": 0.7403693199157715,
      "learning_rate": 1.879393844711764e-05,
      "loss": 1.3726,
      "step": 5200
    },
    {
      "epoch": 0.8162149496211826,
      "grad_norm": 1.0091534852981567,
      "learning_rate": 1.8403374472738635e-05,
      "loss": 1.3142,
      "step": 5225
    },
    {
      "epoch": 0.8201202843083653,
      "grad_norm": 0.7685067653656006,
      "learning_rate": 1.8012810498359633e-05,
      "loss": 1.3977,
      "step": 5250
    },
    {
      "epoch": 0.8240256189955479,
      "grad_norm": 0.7387269735336304,
      "learning_rate": 1.762224652398063e-05,
      "loss": 1.4009,
      "step": 5275
    },
    {
      "epoch": 0.8279309536827306,
      "grad_norm": 0.7391129732131958,
      "learning_rate": 1.7231682549601624e-05,
      "loss": 1.394,
      "step": 5300
    },
    {
      "epoch": 0.8318362883699133,
      "grad_norm": 0.7902172207832336,
      "learning_rate": 1.6841118575222622e-05,
      "loss": 1.3487,
      "step": 5325
    },
    {
      "epoch": 0.835741623057096,
      "grad_norm": 0.8157474994659424,
      "learning_rate": 1.645055460084362e-05,
      "loss": 1.3735,
      "step": 5350
    },
    {
      "epoch": 0.8396469577442787,
      "grad_norm": 0.7818217873573303,
      "learning_rate": 1.6059990626464617e-05,
      "loss": 1.403,
      "step": 5375
    },
    {
      "epoch": 0.8435522924314613,
      "grad_norm": 0.9697117805480957,
      "learning_rate": 1.566942665208561e-05,
      "loss": 1.3657,
      "step": 5400
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.6215644478797913,
      "learning_rate": 1.527886267770661e-05,
      "loss": 1.418,
      "step": 5425
    },
    {
      "epoch": 0.8513629618058267,
      "grad_norm": 0.8901612162590027,
      "learning_rate": 1.4888298703327605e-05,
      "loss": 1.3525,
      "step": 5450
    },
    {
      "epoch": 0.8552682964930095,
      "grad_norm": 0.8169065117835999,
      "learning_rate": 1.4497734728948604e-05,
      "loss": 1.4214,
      "step": 5475
    },
    {
      "epoch": 0.8591736311801922,
      "grad_norm": 0.8597555756568909,
      "learning_rate": 1.4107170754569598e-05,
      "loss": 1.3949,
      "step": 5500
    },
    {
      "epoch": 0.8630789658673749,
      "grad_norm": 0.7627319097518921,
      "learning_rate": 1.3716606780190597e-05,
      "loss": 1.3135,
      "step": 5525
    },
    {
      "epoch": 0.8669843005545576,
      "grad_norm": 0.7136194705963135,
      "learning_rate": 1.3326042805811592e-05,
      "loss": 1.3606,
      "step": 5550
    },
    {
      "epoch": 0.8708896352417402,
      "grad_norm": 0.963046133518219,
      "learning_rate": 1.293547883143259e-05,
      "loss": 1.3821,
      "step": 5575
    },
    {
      "epoch": 0.8747949699289229,
      "grad_norm": 0.9594541788101196,
      "learning_rate": 1.2544914857053585e-05,
      "loss": 1.3539,
      "step": 5600
    },
    {
      "epoch": 0.8787003046161056,
      "grad_norm": 0.7747042775154114,
      "learning_rate": 1.2154350882674583e-05,
      "loss": 1.3584,
      "step": 5625
    },
    {
      "epoch": 0.8826056393032883,
      "grad_norm": 0.540209949016571,
      "learning_rate": 1.176378690829558e-05,
      "loss": 1.3629,
      "step": 5650
    },
    {
      "epoch": 0.886510973990471,
      "grad_norm": 1.0184369087219238,
      "learning_rate": 1.1373222933916576e-05,
      "loss": 1.3523,
      "step": 5675
    },
    {
      "epoch": 0.8904163086776536,
      "grad_norm": 1.009919285774231,
      "learning_rate": 1.0982658959537573e-05,
      "loss": 1.4035,
      "step": 5700
    },
    {
      "epoch": 0.8943216433648363,
      "grad_norm": 0.9293586015701294,
      "learning_rate": 1.059209498515857e-05,
      "loss": 1.387,
      "step": 5725
    },
    {
      "epoch": 0.898226978052019,
      "grad_norm": 0.6847692728042603,
      "learning_rate": 1.0201531010779567e-05,
      "loss": 1.3935,
      "step": 5750
    },
    {
      "epoch": 0.9021323127392018,
      "grad_norm": 1.1162265539169312,
      "learning_rate": 9.810967036400563e-06,
      "loss": 1.3962,
      "step": 5775
    },
    {
      "epoch": 0.9060376474263845,
      "grad_norm": 0.820128858089447,
      "learning_rate": 9.42040306202156e-06,
      "loss": 1.3766,
      "step": 5800
    },
    {
      "epoch": 0.9099429821135672,
      "grad_norm": 0.9112349152565002,
      "learning_rate": 9.029839087642556e-06,
      "loss": 1.3687,
      "step": 5825
    },
    {
      "epoch": 0.9138483168007498,
      "grad_norm": 0.7499094605445862,
      "learning_rate": 8.639275113263554e-06,
      "loss": 1.3931,
      "step": 5850
    },
    {
      "epoch": 0.9177536514879325,
      "grad_norm": 0.779123067855835,
      "learning_rate": 8.24871113888455e-06,
      "loss": 1.3834,
      "step": 5875
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 0.8808546662330627,
      "learning_rate": 7.858147164505545e-06,
      "loss": 1.3434,
      "step": 5900
    },
    {
      "epoch": 0.9255643208622979,
      "grad_norm": 0.7188853025436401,
      "learning_rate": 7.467583190126542e-06,
      "loss": 1.3711,
      "step": 5925
    },
    {
      "epoch": 0.9294696555494806,
      "grad_norm": 1.1590969562530518,
      "learning_rate": 7.077019215747539e-06,
      "loss": 1.3808,
      "step": 5950
    },
    {
      "epoch": 0.9333749902366633,
      "grad_norm": 0.7779844403266907,
      "learning_rate": 6.686455241368536e-06,
      "loss": 1.3926,
      "step": 5975
    },
    {
      "epoch": 0.9372803249238459,
      "grad_norm": 0.8251484036445618,
      "learning_rate": 6.295891266989533e-06,
      "loss": 1.3898,
      "step": 6000
    },
    {
      "epoch": 0.9372803249238459,
      "eval_loss": 1.3691012859344482,
      "eval_runtime": 1621.6313,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 6000
    },
    {
      "epoch": 0.9411856596110286,
      "grad_norm": 0.8516352772712708,
      "learning_rate": 5.90532729261053e-06,
      "loss": 1.3566,
      "step": 6025
    },
    {
      "epoch": 0.9450909942982113,
      "grad_norm": 0.9251545071601868,
      "learning_rate": 5.5147633182315265e-06,
      "loss": 1.3733,
      "step": 6050
    },
    {
      "epoch": 0.9489963289853941,
      "grad_norm": 0.843480110168457,
      "learning_rate": 5.124199343852523e-06,
      "loss": 1.4116,
      "step": 6075
    },
    {
      "epoch": 0.9529016636725768,
      "grad_norm": 0.9397046566009521,
      "learning_rate": 4.73363536947352e-06,
      "loss": 1.3677,
      "step": 6100
    },
    {
      "epoch": 0.9568069983597595,
      "grad_norm": 0.8314614295959473,
      "learning_rate": 4.343071395094517e-06,
      "loss": 1.3056,
      "step": 6125
    },
    {
      "epoch": 0.9607123330469421,
      "grad_norm": 0.7589595913887024,
      "learning_rate": 3.952507420715513e-06,
      "loss": 1.3952,
      "step": 6150
    },
    {
      "epoch": 0.9646176677341248,
      "grad_norm": 0.8266384601593018,
      "learning_rate": 3.5619434463365105e-06,
      "loss": 1.4275,
      "step": 6175
    },
    {
      "epoch": 0.9685230024213075,
      "grad_norm": 0.8750735521316528,
      "learning_rate": 3.1713794719575072e-06,
      "loss": 1.3525,
      "step": 6200
    },
    {
      "epoch": 0.9724283371084902,
      "grad_norm": 0.7303192019462585,
      "learning_rate": 2.7808154975785035e-06,
      "loss": 1.4298,
      "step": 6225
    },
    {
      "epoch": 0.9763336717956729,
      "grad_norm": 0.6123300790786743,
      "learning_rate": 2.3902515231995002e-06,
      "loss": 1.383,
      "step": 6250
    },
    {
      "epoch": 0.9802390064828556,
      "grad_norm": 0.8566604852676392,
      "learning_rate": 1.999687548820497e-06,
      "loss": 1.3823,
      "step": 6275
    },
    {
      "epoch": 0.9841443411700382,
      "grad_norm": 0.9160458445549011,
      "learning_rate": 1.6091235744414936e-06,
      "loss": 1.4217,
      "step": 6300
    },
    {
      "epoch": 0.9880496758572209,
      "grad_norm": 0.762948215007782,
      "learning_rate": 1.2185596000624903e-06,
      "loss": 1.3899,
      "step": 6325
    },
    {
      "epoch": 0.9919550105444036,
      "grad_norm": 0.8542826175689697,
      "learning_rate": 8.279956256834869e-07,
      "loss": 1.3563,
      "step": 6350
    },
    {
      "epoch": 0.9958603452315864,
      "grad_norm": 0.8672225475311279,
      "learning_rate": 4.3743165130448375e-07,
      "loss": 1.3055,
      "step": 6375
    },
    {
      "epoch": 0.9997656799187691,
      "grad_norm": 0.8037919402122498,
      "learning_rate": 4.6867676925480397e-08,
      "loss": 1.3534,
      "step": 6400
    }
  ],
  "logging_steps": 25,
  "max_steps": 6401,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.572369762378097e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
