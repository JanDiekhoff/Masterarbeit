{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.9997656799187693,
  "eval_steps": 1000,
  "global_step": 25604,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0039053346871826917,
      "grad_norm": 3.2465217113494873,
      "learning_rate": 9.9609436025621e-05,
      "loss": 2.1021,
      "step": 25
    },
    {
      "epoch": 0.007810669374365383,
      "grad_norm": 1.1683964729309082,
      "learning_rate": 9.921887205124199e-05,
      "loss": 1.6778,
      "step": 50
    },
    {
      "epoch": 0.011716004061548074,
      "grad_norm": 1.0458828210830688,
      "learning_rate": 9.8828308076863e-05,
      "loss": 1.6162,
      "step": 75
    },
    {
      "epoch": 0.015621338748730767,
      "grad_norm": 1.1215345859527588,
      "learning_rate": 9.843774410248398e-05,
      "loss": 1.5214,
      "step": 100
    },
    {
      "epoch": 0.01952667343591346,
      "grad_norm": 0.8124238848686218,
      "learning_rate": 9.804718012810498e-05,
      "loss": 1.551,
      "step": 125
    },
    {
      "epoch": 0.02343200812309615,
      "grad_norm": 1.1576467752456665,
      "learning_rate": 9.765661615372598e-05,
      "loss": 1.5233,
      "step": 150
    },
    {
      "epoch": 0.02733734281027884,
      "grad_norm": 0.9178279042243958,
      "learning_rate": 9.726605217934698e-05,
      "loss": 1.4985,
      "step": 175
    },
    {
      "epoch": 0.031242677497461534,
      "grad_norm": 0.9064067602157593,
      "learning_rate": 9.687548820496799e-05,
      "loss": 1.5261,
      "step": 200
    },
    {
      "epoch": 0.03514801218464422,
      "grad_norm": 0.9114634394645691,
      "learning_rate": 9.648492423058899e-05,
      "loss": 1.4715,
      "step": 225
    },
    {
      "epoch": 0.03905334687182692,
      "grad_norm": 1.2622907161712646,
      "learning_rate": 9.609436025620997e-05,
      "loss": 1.5396,
      "step": 250
    },
    {
      "epoch": 0.04295868155900961,
      "grad_norm": 1.2203083038330078,
      "learning_rate": 9.570379628183097e-05,
      "loss": 1.4599,
      "step": 275
    },
    {
      "epoch": 0.0468640162461923,
      "grad_norm": 1.0415164232254028,
      "learning_rate": 9.531323230745196e-05,
      "loss": 1.4784,
      "step": 300
    },
    {
      "epoch": 0.05076935093337499,
      "grad_norm": 1.1780155897140503,
      "learning_rate": 9.492266833307296e-05,
      "loss": 1.4008,
      "step": 325
    },
    {
      "epoch": 0.05467468562055768,
      "grad_norm": 0.9165364503860474,
      "learning_rate": 9.453210435869396e-05,
      "loss": 1.38,
      "step": 350
    },
    {
      "epoch": 0.05858002030774037,
      "grad_norm": 1.247885823249817,
      "learning_rate": 9.414154038431495e-05,
      "loss": 1.4829,
      "step": 375
    },
    {
      "epoch": 0.06248535499492307,
      "grad_norm": 0.8763705492019653,
      "learning_rate": 9.375097640993595e-05,
      "loss": 1.4248,
      "step": 400
    },
    {
      "epoch": 0.06639068968210575,
      "grad_norm": 1.141935110092163,
      "learning_rate": 9.336041243555694e-05,
      "loss": 1.4143,
      "step": 425
    },
    {
      "epoch": 0.07029602436928845,
      "grad_norm": 0.7177324891090393,
      "learning_rate": 9.296984846117794e-05,
      "loss": 1.4389,
      "step": 450
    },
    {
      "epoch": 0.07420135905647114,
      "grad_norm": 0.8669571876525879,
      "learning_rate": 9.257928448679894e-05,
      "loss": 1.391,
      "step": 475
    },
    {
      "epoch": 0.07810669374365384,
      "grad_norm": 1.1431673765182495,
      "learning_rate": 9.218872051241993e-05,
      "loss": 1.427,
      "step": 500
    },
    {
      "epoch": 0.08201202843083652,
      "grad_norm": 0.8612999320030212,
      "learning_rate": 9.179815653804093e-05,
      "loss": 1.4743,
      "step": 525
    },
    {
      "epoch": 0.08591736311801922,
      "grad_norm": 0.7818436622619629,
      "learning_rate": 9.140759256366193e-05,
      "loss": 1.4884,
      "step": 550
    },
    {
      "epoch": 0.08982269780520191,
      "grad_norm": 0.7049092650413513,
      "learning_rate": 9.101702858928293e-05,
      "loss": 1.4361,
      "step": 575
    },
    {
      "epoch": 0.0937280324923846,
      "grad_norm": 0.9018144011497498,
      "learning_rate": 9.062646461490393e-05,
      "loss": 1.4553,
      "step": 600
    },
    {
      "epoch": 0.09763336717956729,
      "grad_norm": 1.1254284381866455,
      "learning_rate": 9.023590064052492e-05,
      "loss": 1.4594,
      "step": 625
    },
    {
      "epoch": 0.10153870186674999,
      "grad_norm": 0.8887649178504944,
      "learning_rate": 8.984533666614592e-05,
      "loss": 1.5094,
      "step": 650
    },
    {
      "epoch": 0.10544403655393267,
      "grad_norm": 0.8469434380531311,
      "learning_rate": 8.945477269176692e-05,
      "loss": 1.4282,
      "step": 675
    },
    {
      "epoch": 0.10934937124111536,
      "grad_norm": 0.8114902973175049,
      "learning_rate": 8.906420871738791e-05,
      "loss": 1.4451,
      "step": 700
    },
    {
      "epoch": 0.11325470592829806,
      "grad_norm": 1.1834198236465454,
      "learning_rate": 8.867364474300891e-05,
      "loss": 1.4714,
      "step": 725
    },
    {
      "epoch": 0.11716004061548074,
      "grad_norm": 0.8823350667953491,
      "learning_rate": 8.828308076862991e-05,
      "loss": 1.4202,
      "step": 750
    },
    {
      "epoch": 0.12106537530266344,
      "grad_norm": 0.7953850030899048,
      "learning_rate": 8.78925167942509e-05,
      "loss": 1.4129,
      "step": 775
    },
    {
      "epoch": 0.12497070998984613,
      "grad_norm": 0.7873246073722839,
      "learning_rate": 8.75019528198719e-05,
      "loss": 1.4156,
      "step": 800
    },
    {
      "epoch": 0.12887604467702882,
      "grad_norm": 0.6885635852813721,
      "learning_rate": 8.711138884549289e-05,
      "loss": 1.4368,
      "step": 825
    },
    {
      "epoch": 0.1327813793642115,
      "grad_norm": 1.1447787284851074,
      "learning_rate": 8.672082487111389e-05,
      "loss": 1.4678,
      "step": 850
    },
    {
      "epoch": 0.1366867140513942,
      "grad_norm": 0.9177465438842773,
      "learning_rate": 8.633026089673489e-05,
      "loss": 1.3658,
      "step": 875
    },
    {
      "epoch": 0.1405920487385769,
      "grad_norm": 1.0802029371261597,
      "learning_rate": 8.593969692235589e-05,
      "loss": 1.3807,
      "step": 900
    },
    {
      "epoch": 0.1444973834257596,
      "grad_norm": 0.7436348795890808,
      "learning_rate": 8.554913294797689e-05,
      "loss": 1.4801,
      "step": 925
    },
    {
      "epoch": 0.14840271811294228,
      "grad_norm": 0.8422478437423706,
      "learning_rate": 8.515856897359788e-05,
      "loss": 1.4181,
      "step": 950
    },
    {
      "epoch": 0.15230805280012497,
      "grad_norm": 0.714457631111145,
      "learning_rate": 8.476800499921888e-05,
      "loss": 1.425,
      "step": 975
    },
    {
      "epoch": 0.15621338748730768,
      "grad_norm": 0.7346399426460266,
      "learning_rate": 8.437744102483988e-05,
      "loss": 1.4406,
      "step": 1000
    },
    {
      "epoch": 0.15621338748730768,
      "eval_loss": 1.4085553884506226,
      "eval_runtime": 1621.4977,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 1000
    },
    {
      "epoch": 0.16011872217449036,
      "grad_norm": 0.7755522131919861,
      "learning_rate": 8.398687705046087e-05,
      "loss": 1.497,
      "step": 1025
    },
    {
      "epoch": 0.16402405686167304,
      "grad_norm": 0.7198747992515564,
      "learning_rate": 8.359631307608187e-05,
      "loss": 1.3876,
      "step": 1050
    },
    {
      "epoch": 0.16792939154885575,
      "grad_norm": 0.7547372579574585,
      "learning_rate": 8.320574910170287e-05,
      "loss": 1.4114,
      "step": 1075
    },
    {
      "epoch": 0.17183472623603843,
      "grad_norm": 0.7939823269844055,
      "learning_rate": 8.281518512732386e-05,
      "loss": 1.3696,
      "step": 1100
    },
    {
      "epoch": 0.17574006092322111,
      "grad_norm": 0.880377471446991,
      "learning_rate": 8.242462115294486e-05,
      "loss": 1.4274,
      "step": 1125
    },
    {
      "epoch": 0.17964539561040382,
      "grad_norm": 1.1362334489822388,
      "learning_rate": 8.203405717856584e-05,
      "loss": 1.4381,
      "step": 1150
    },
    {
      "epoch": 0.1835507302975865,
      "grad_norm": 1.0400172472000122,
      "learning_rate": 8.164349320418685e-05,
      "loss": 1.3768,
      "step": 1175
    },
    {
      "epoch": 0.1874560649847692,
      "grad_norm": 0.9381090402603149,
      "learning_rate": 8.125292922980785e-05,
      "loss": 1.3723,
      "step": 1200
    },
    {
      "epoch": 0.1913613996719519,
      "grad_norm": 0.6042956113815308,
      "learning_rate": 8.086236525542883e-05,
      "loss": 1.4514,
      "step": 1225
    },
    {
      "epoch": 0.19526673435913458,
      "grad_norm": 0.8863415122032166,
      "learning_rate": 8.047180128104984e-05,
      "loss": 1.4024,
      "step": 1250
    },
    {
      "epoch": 0.19917206904631726,
      "grad_norm": 0.8462222814559937,
      "learning_rate": 8.008123730667084e-05,
      "loss": 1.443,
      "step": 1275
    },
    {
      "epoch": 0.20307740373349997,
      "grad_norm": 0.6853643655776978,
      "learning_rate": 7.969067333229184e-05,
      "loss": 1.3688,
      "step": 1300
    },
    {
      "epoch": 0.20698273842068265,
      "grad_norm": 1.452087163925171,
      "learning_rate": 7.930010935791284e-05,
      "loss": 1.3644,
      "step": 1325
    },
    {
      "epoch": 0.21088807310786534,
      "grad_norm": 0.9469685554504395,
      "learning_rate": 7.890954538353383e-05,
      "loss": 1.4085,
      "step": 1350
    },
    {
      "epoch": 0.21479340779504805,
      "grad_norm": 0.8635916709899902,
      "learning_rate": 7.851898140915483e-05,
      "loss": 1.4282,
      "step": 1375
    },
    {
      "epoch": 0.21869874248223073,
      "grad_norm": 0.819979727268219,
      "learning_rate": 7.812841743477583e-05,
      "loss": 1.4151,
      "step": 1400
    },
    {
      "epoch": 0.2226040771694134,
      "grad_norm": 0.6791641116142273,
      "learning_rate": 7.773785346039681e-05,
      "loss": 1.4202,
      "step": 1425
    },
    {
      "epoch": 0.22650941185659612,
      "grad_norm": 0.9602513909339905,
      "learning_rate": 7.734728948601782e-05,
      "loss": 1.3821,
      "step": 1450
    },
    {
      "epoch": 0.2304147465437788,
      "grad_norm": 0.9818315505981445,
      "learning_rate": 7.69567255116388e-05,
      "loss": 1.4221,
      "step": 1475
    },
    {
      "epoch": 0.23432008123096149,
      "grad_norm": 0.883847177028656,
      "learning_rate": 7.65661615372598e-05,
      "loss": 1.3867,
      "step": 1500
    },
    {
      "epoch": 0.2382254159181442,
      "grad_norm": 0.8888888955116272,
      "learning_rate": 7.61755975628808e-05,
      "loss": 1.4057,
      "step": 1525
    },
    {
      "epoch": 0.24213075060532688,
      "grad_norm": 0.791121780872345,
      "learning_rate": 7.578503358850179e-05,
      "loss": 1.3807,
      "step": 1550
    },
    {
      "epoch": 0.24603608529250956,
      "grad_norm": 0.6994274854660034,
      "learning_rate": 7.539446961412279e-05,
      "loss": 1.3847,
      "step": 1575
    },
    {
      "epoch": 0.24994141997969227,
      "grad_norm": 0.8135121464729309,
      "learning_rate": 7.50039056397438e-05,
      "loss": 1.4215,
      "step": 1600
    },
    {
      "epoch": 0.25384675466687495,
      "grad_norm": 0.6589803099632263,
      "learning_rate": 7.46133416653648e-05,
      "loss": 1.3883,
      "step": 1625
    },
    {
      "epoch": 0.25775208935405763,
      "grad_norm": 0.7393799424171448,
      "learning_rate": 7.42227776909858e-05,
      "loss": 1.4246,
      "step": 1650
    },
    {
      "epoch": 0.2616574240412403,
      "grad_norm": 0.8831437230110168,
      "learning_rate": 7.383221371660678e-05,
      "loss": 1.3648,
      "step": 1675
    },
    {
      "epoch": 0.265562758728423,
      "grad_norm": 0.920042097568512,
      "learning_rate": 7.344164974222778e-05,
      "loss": 1.3967,
      "step": 1700
    },
    {
      "epoch": 0.26946809341560574,
      "grad_norm": 0.885888934135437,
      "learning_rate": 7.305108576784879e-05,
      "loss": 1.3872,
      "step": 1725
    },
    {
      "epoch": 0.2733734281027884,
      "grad_norm": 1.0735024213790894,
      "learning_rate": 7.266052179346977e-05,
      "loss": 1.3957,
      "step": 1750
    },
    {
      "epoch": 0.2772787627899711,
      "grad_norm": 0.9115954637527466,
      "learning_rate": 7.226995781909077e-05,
      "loss": 1.3945,
      "step": 1775
    },
    {
      "epoch": 0.2811840974771538,
      "grad_norm": 0.8568029403686523,
      "learning_rate": 7.187939384471176e-05,
      "loss": 1.3863,
      "step": 1800
    },
    {
      "epoch": 0.28508943216433646,
      "grad_norm": 0.6662747263908386,
      "learning_rate": 7.148882987033276e-05,
      "loss": 1.4811,
      "step": 1825
    },
    {
      "epoch": 0.2889947668515192,
      "grad_norm": 1.1174888610839844,
      "learning_rate": 7.109826589595376e-05,
      "loss": 1.3925,
      "step": 1850
    },
    {
      "epoch": 0.2929001015387019,
      "grad_norm": 0.8547325730323792,
      "learning_rate": 7.070770192157475e-05,
      "loss": 1.3573,
      "step": 1875
    },
    {
      "epoch": 0.29680543622588457,
      "grad_norm": 0.8674880266189575,
      "learning_rate": 7.031713794719575e-05,
      "loss": 1.3931,
      "step": 1900
    },
    {
      "epoch": 0.30071077091306725,
      "grad_norm": 0.9799916744232178,
      "learning_rate": 6.992657397281675e-05,
      "loss": 1.435,
      "step": 1925
    },
    {
      "epoch": 0.30461610560024993,
      "grad_norm": 0.8731327056884766,
      "learning_rate": 6.953600999843774e-05,
      "loss": 1.4106,
      "step": 1950
    },
    {
      "epoch": 0.3085214402874326,
      "grad_norm": 0.9855532646179199,
      "learning_rate": 6.914544602405874e-05,
      "loss": 1.443,
      "step": 1975
    },
    {
      "epoch": 0.31242677497461535,
      "grad_norm": 1.0308401584625244,
      "learning_rate": 6.875488204967974e-05,
      "loss": 1.3588,
      "step": 2000
    },
    {
      "epoch": 0.31242677497461535,
      "eval_loss": 1.3906242847442627,
      "eval_runtime": 1621.4924,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 2000
    },
    {
      "epoch": 0.31633210966179803,
      "grad_norm": 0.7043284177780151,
      "learning_rate": 6.836431807530074e-05,
      "loss": 1.4098,
      "step": 2025
    },
    {
      "epoch": 0.3202374443489807,
      "grad_norm": 1.2149544954299927,
      "learning_rate": 6.797375410092174e-05,
      "loss": 1.3782,
      "step": 2050
    },
    {
      "epoch": 0.3241427790361634,
      "grad_norm": 0.6752206683158875,
      "learning_rate": 6.758319012654273e-05,
      "loss": 1.3926,
      "step": 2075
    },
    {
      "epoch": 0.3280481137233461,
      "grad_norm": 0.8697562217712402,
      "learning_rate": 6.719262615216373e-05,
      "loss": 1.4171,
      "step": 2100
    },
    {
      "epoch": 0.33195344841052876,
      "grad_norm": 0.8683820962905884,
      "learning_rate": 6.680206217778472e-05,
      "loss": 1.3641,
      "step": 2125
    },
    {
      "epoch": 0.3358587830977115,
      "grad_norm": 0.9228382110595703,
      "learning_rate": 6.641149820340572e-05,
      "loss": 1.3736,
      "step": 2150
    },
    {
      "epoch": 0.3397641177848942,
      "grad_norm": 0.7752336859703064,
      "learning_rate": 6.602093422902672e-05,
      "loss": 1.386,
      "step": 2175
    },
    {
      "epoch": 0.34366945247207686,
      "grad_norm": 0.7451473474502563,
      "learning_rate": 6.563037025464771e-05,
      "loss": 1.431,
      "step": 2200
    },
    {
      "epoch": 0.34757478715925955,
      "grad_norm": 0.9055505990982056,
      "learning_rate": 6.523980628026871e-05,
      "loss": 1.4389,
      "step": 2225
    },
    {
      "epoch": 0.35148012184644223,
      "grad_norm": 0.9343944787979126,
      "learning_rate": 6.484924230588971e-05,
      "loss": 1.373,
      "step": 2250
    },
    {
      "epoch": 0.3553854565336249,
      "grad_norm": 0.8370698094367981,
      "learning_rate": 6.44586783315107e-05,
      "loss": 1.4104,
      "step": 2275
    },
    {
      "epoch": 0.35929079122080765,
      "grad_norm": 0.6486676931381226,
      "learning_rate": 6.40681143571317e-05,
      "loss": 1.4103,
      "step": 2300
    },
    {
      "epoch": 0.36319612590799033,
      "grad_norm": 1.0935900211334229,
      "learning_rate": 6.369317294172786e-05,
      "loss": 1.4174,
      "step": 2325
    },
    {
      "epoch": 0.367101460595173,
      "grad_norm": 0.8440026640892029,
      "learning_rate": 6.330260896734885e-05,
      "loss": 1.3951,
      "step": 2350
    },
    {
      "epoch": 0.3710067952823557,
      "grad_norm": 0.8636385202407837,
      "learning_rate": 6.291204499296985e-05,
      "loss": 1.3864,
      "step": 2375
    },
    {
      "epoch": 0.3749121299695384,
      "grad_norm": 1.0544004440307617,
      "learning_rate": 6.252148101859084e-05,
      "loss": 1.4254,
      "step": 2400
    },
    {
      "epoch": 0.37881746465672106,
      "grad_norm": 1.2913252115249634,
      "learning_rate": 6.213091704421184e-05,
      "loss": 1.4154,
      "step": 2425
    },
    {
      "epoch": 0.3827227993439038,
      "grad_norm": 0.9033505916595459,
      "learning_rate": 6.174035306983284e-05,
      "loss": 1.4078,
      "step": 2450
    },
    {
      "epoch": 0.3866281340310865,
      "grad_norm": 1.5760395526885986,
      "learning_rate": 6.134978909545384e-05,
      "loss": 1.4163,
      "step": 2475
    },
    {
      "epoch": 0.39053346871826916,
      "grad_norm": 0.8405604958534241,
      "learning_rate": 6.0959225121074834e-05,
      "loss": 1.3473,
      "step": 2500
    },
    {
      "epoch": 0.39443880340545184,
      "grad_norm": 1.1086634397506714,
      "learning_rate": 6.056866114669583e-05,
      "loss": 1.3528,
      "step": 2525
    },
    {
      "epoch": 0.3983441380926345,
      "grad_norm": 0.8433387875556946,
      "learning_rate": 6.017809717231683e-05,
      "loss": 1.448,
      "step": 2550
    },
    {
      "epoch": 0.4022494727798172,
      "grad_norm": 0.8500542640686035,
      "learning_rate": 5.978753319793783e-05,
      "loss": 1.4054,
      "step": 2575
    },
    {
      "epoch": 0.40615480746699995,
      "grad_norm": 0.860120415687561,
      "learning_rate": 5.939696922355882e-05,
      "loss": 1.4298,
      "step": 2600
    },
    {
      "epoch": 0.4100601421541826,
      "grad_norm": 0.688825249671936,
      "learning_rate": 5.900640524917982e-05,
      "loss": 1.385,
      "step": 2625
    },
    {
      "epoch": 0.4139654768413653,
      "grad_norm": 0.8465675115585327,
      "learning_rate": 5.861584127480082e-05,
      "loss": 1.3763,
      "step": 2650
    },
    {
      "epoch": 0.417870811528548,
      "grad_norm": 1.2347468137741089,
      "learning_rate": 5.822527730042181e-05,
      "loss": 1.3925,
      "step": 2675
    },
    {
      "epoch": 0.4217761462157307,
      "grad_norm": 1.2148834466934204,
      "learning_rate": 5.783471332604281e-05,
      "loss": 1.3894,
      "step": 2700
    },
    {
      "epoch": 0.42568148090291336,
      "grad_norm": 0.8276163339614868,
      "learning_rate": 5.74441493516638e-05,
      "loss": 1.3941,
      "step": 2725
    },
    {
      "epoch": 0.4295868155900961,
      "grad_norm": 0.7274352312088013,
      "learning_rate": 5.70535853772848e-05,
      "loss": 1.4233,
      "step": 2750
    },
    {
      "epoch": 0.4334921502772788,
      "grad_norm": 0.8085888624191284,
      "learning_rate": 5.6663021402905804e-05,
      "loss": 1.3764,
      "step": 2775
    },
    {
      "epoch": 0.43739748496446146,
      "grad_norm": 0.8890697956085205,
      "learning_rate": 5.627245742852679e-05,
      "loss": 1.3698,
      "step": 2800
    },
    {
      "epoch": 0.44130281965164414,
      "grad_norm": 0.7871195077896118,
      "learning_rate": 5.588189345414779e-05,
      "loss": 1.4277,
      "step": 2825
    },
    {
      "epoch": 0.4452081543388268,
      "grad_norm": 0.7770936489105225,
      "learning_rate": 5.5491329479768787e-05,
      "loss": 1.3841,
      "step": 2850
    },
    {
      "epoch": 0.4491134890260095,
      "grad_norm": 0.7169707417488098,
      "learning_rate": 5.510076550538979e-05,
      "loss": 1.4128,
      "step": 2875
    },
    {
      "epoch": 0.45301882371319224,
      "grad_norm": 0.824567437171936,
      "learning_rate": 5.471020153101079e-05,
      "loss": 1.39,
      "step": 2900
    },
    {
      "epoch": 0.4569241584003749,
      "grad_norm": 0.7587940096855164,
      "learning_rate": 5.4319637556631776e-05,
      "loss": 1.3886,
      "step": 2925
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 0.9113674759864807,
      "learning_rate": 5.392907358225278e-05,
      "loss": 1.3662,
      "step": 2950
    },
    {
      "epoch": 0.4647348277747403,
      "grad_norm": 0.7056671380996704,
      "learning_rate": 5.353850960787378e-05,
      "loss": 1.3772,
      "step": 2975
    },
    {
      "epoch": 0.46864016246192297,
      "grad_norm": 1.3100237846374512,
      "learning_rate": 5.3147945633494765e-05,
      "loss": 1.3781,
      "step": 3000
    },
    {
      "epoch": 0.46864016246192297,
      "eval_loss": 1.3806625604629517,
      "eval_runtime": 1621.5533,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 3000
    },
    {
      "epoch": 0.47254549714910565,
      "grad_norm": 0.9259299635887146,
      "learning_rate": 5.2757381659115766e-05,
      "loss": 1.3941,
      "step": 3025
    },
    {
      "epoch": 0.4764508318362884,
      "grad_norm": 1.0350550413131714,
      "learning_rate": 5.236681768473676e-05,
      "loss": 1.3685,
      "step": 3050
    },
    {
      "epoch": 0.4803561665234711,
      "grad_norm": 0.7242240309715271,
      "learning_rate": 5.197625371035776e-05,
      "loss": 1.4776,
      "step": 3075
    },
    {
      "epoch": 0.48426150121065376,
      "grad_norm": 1.0832544565200806,
      "learning_rate": 5.158568973597876e-05,
      "loss": 1.4344,
      "step": 3100
    },
    {
      "epoch": 0.48816683589783644,
      "grad_norm": 0.7072556018829346,
      "learning_rate": 5.119512576159975e-05,
      "loss": 1.3611,
      "step": 3125
    },
    {
      "epoch": 0.4920721705850191,
      "grad_norm": 0.7741387486457825,
      "learning_rate": 5.080456178722075e-05,
      "loss": 1.3342,
      "step": 3150
    },
    {
      "epoch": 0.4959775052722018,
      "grad_norm": 0.7482285499572754,
      "learning_rate": 5.041399781284175e-05,
      "loss": 1.3706,
      "step": 3175
    },
    {
      "epoch": 0.49988283995938454,
      "grad_norm": 0.9397870302200317,
      "learning_rate": 5.002343383846274e-05,
      "loss": 1.3911,
      "step": 3200
    },
    {
      "epoch": 0.5037881746465672,
      "grad_norm": 1.3380074501037598,
      "learning_rate": 4.963286986408374e-05,
      "loss": 1.3817,
      "step": 3225
    },
    {
      "epoch": 0.5076935093337499,
      "grad_norm": 1.1256049871444702,
      "learning_rate": 4.924230588970474e-05,
      "loss": 1.3473,
      "step": 3250
    },
    {
      "epoch": 0.5115988440209326,
      "grad_norm": 0.8798999786376953,
      "learning_rate": 4.8851741915325735e-05,
      "loss": 1.4274,
      "step": 3275
    },
    {
      "epoch": 0.5155041787081153,
      "grad_norm": 0.7999401092529297,
      "learning_rate": 4.846117794094673e-05,
      "loss": 1.4047,
      "step": 3300
    },
    {
      "epoch": 0.519409513395298,
      "grad_norm": 0.6698806285858154,
      "learning_rate": 4.807061396656772e-05,
      "loss": 1.35,
      "step": 3325
    },
    {
      "epoch": 0.5233148480824806,
      "grad_norm": 0.8130303621292114,
      "learning_rate": 4.7680049992188724e-05,
      "loss": 1.4038,
      "step": 3350
    },
    {
      "epoch": 0.5272201827696633,
      "grad_norm": 1.296355128288269,
      "learning_rate": 4.728948601780972e-05,
      "loss": 1.3506,
      "step": 3375
    },
    {
      "epoch": 0.531125517456846,
      "grad_norm": 0.9970064759254456,
      "learning_rate": 4.689892204343071e-05,
      "loss": 1.4195,
      "step": 3400
    },
    {
      "epoch": 0.5350308521440288,
      "grad_norm": 0.8253654837608337,
      "learning_rate": 4.6508358069051713e-05,
      "loss": 1.3936,
      "step": 3425
    },
    {
      "epoch": 0.5389361868312115,
      "grad_norm": 1.8508747816085815,
      "learning_rate": 4.6117794094672714e-05,
      "loss": 1.4283,
      "step": 3450
    },
    {
      "epoch": 0.5428415215183942,
      "grad_norm": 0.7999590635299683,
      "learning_rate": 4.572723012029371e-05,
      "loss": 1.327,
      "step": 3475
    },
    {
      "epoch": 0.5467468562055768,
      "grad_norm": 0.7973755598068237,
      "learning_rate": 4.53366661459147e-05,
      "loss": 1.3583,
      "step": 3500
    },
    {
      "epoch": 0.5506521908927595,
      "grad_norm": 0.8767470121383667,
      "learning_rate": 4.49461021715357e-05,
      "loss": 1.4173,
      "step": 3525
    },
    {
      "epoch": 0.5545575255799422,
      "grad_norm": 0.8256537318229675,
      "learning_rate": 4.45555381971567e-05,
      "loss": 1.3849,
      "step": 3550
    },
    {
      "epoch": 0.5584628602671249,
      "grad_norm": 0.7352432012557983,
      "learning_rate": 4.416497422277769e-05,
      "loss": 1.3562,
      "step": 3575
    },
    {
      "epoch": 0.5623681949543076,
      "grad_norm": 0.7893133163452148,
      "learning_rate": 4.3774410248398686e-05,
      "loss": 1.3458,
      "step": 3600
    },
    {
      "epoch": 0.5662735296414902,
      "grad_norm": 0.6675043106079102,
      "learning_rate": 4.338384627401969e-05,
      "loss": 1.3503,
      "step": 3625
    },
    {
      "epoch": 0.5701788643286729,
      "grad_norm": 0.7892453670501709,
      "learning_rate": 4.299328229964069e-05,
      "loss": 1.4059,
      "step": 3650
    },
    {
      "epoch": 0.5740841990158556,
      "grad_norm": 1.0979344844818115,
      "learning_rate": 4.260271832526168e-05,
      "loss": 1.4222,
      "step": 3675
    },
    {
      "epoch": 0.5779895337030384,
      "grad_norm": 1.1182317733764648,
      "learning_rate": 4.2212154350882676e-05,
      "loss": 1.3518,
      "step": 3700
    },
    {
      "epoch": 0.5818948683902211,
      "grad_norm": 0.7349278330802917,
      "learning_rate": 4.182159037650367e-05,
      "loss": 1.3484,
      "step": 3725
    },
    {
      "epoch": 0.5858002030774038,
      "grad_norm": 0.9451165199279785,
      "learning_rate": 4.1431026402124665e-05,
      "loss": 1.3595,
      "step": 3750
    },
    {
      "epoch": 0.5897055377645865,
      "grad_norm": 0.8639544248580933,
      "learning_rate": 4.1040462427745666e-05,
      "loss": 1.3577,
      "step": 3775
    },
    {
      "epoch": 0.5936108724517691,
      "grad_norm": 0.7390472888946533,
      "learning_rate": 4.0649898453366667e-05,
      "loss": 1.3573,
      "step": 3800
    },
    {
      "epoch": 0.5975162071389518,
      "grad_norm": 0.9243931770324707,
      "learning_rate": 4.025933447898766e-05,
      "loss": 1.3918,
      "step": 3825
    },
    {
      "epoch": 0.6014215418261345,
      "grad_norm": 0.7551735043525696,
      "learning_rate": 3.9868770504608655e-05,
      "loss": 1.3817,
      "step": 3850
    },
    {
      "epoch": 0.6053268765133172,
      "grad_norm": 1.2113673686981201,
      "learning_rate": 3.9478206530229656e-05,
      "loss": 1.3977,
      "step": 3875
    },
    {
      "epoch": 0.6092322112004999,
      "grad_norm": 0.9740294814109802,
      "learning_rate": 3.908764255585065e-05,
      "loss": 1.3481,
      "step": 3900
    },
    {
      "epoch": 0.6131375458876825,
      "grad_norm": 0.6352384686470032,
      "learning_rate": 3.8697078581471644e-05,
      "loss": 1.3798,
      "step": 3925
    },
    {
      "epoch": 0.6170428805748652,
      "grad_norm": 0.992870569229126,
      "learning_rate": 3.830651460709264e-05,
      "loss": 1.4388,
      "step": 3950
    },
    {
      "epoch": 0.6209482152620479,
      "grad_norm": 0.7837244272232056,
      "learning_rate": 3.791595063271364e-05,
      "loss": 1.4264,
      "step": 3975
    },
    {
      "epoch": 0.6248535499492307,
      "grad_norm": 0.6938894391059875,
      "learning_rate": 3.752538665833464e-05,
      "loss": 1.3434,
      "step": 4000
    },
    {
      "epoch": 0.6248535499492307,
      "eval_loss": 1.374707818031311,
      "eval_runtime": 1621.4987,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 4000
    },
    {
      "epoch": 0.6287588846364134,
      "grad_norm": 0.7759961485862732,
      "learning_rate": 3.7134822683955634e-05,
      "loss": 1.3547,
      "step": 4025
    },
    {
      "epoch": 0.6326642193235961,
      "grad_norm": 1.0880918502807617,
      "learning_rate": 3.674425870957663e-05,
      "loss": 1.3858,
      "step": 4050
    },
    {
      "epoch": 0.6365695540107787,
      "grad_norm": 0.7066709995269775,
      "learning_rate": 3.635369473519763e-05,
      "loss": 1.3205,
      "step": 4075
    },
    {
      "epoch": 0.6404748886979614,
      "grad_norm": 0.9959076642990112,
      "learning_rate": 3.5963130760818624e-05,
      "loss": 1.4053,
      "step": 4100
    },
    {
      "epoch": 0.6443802233851441,
      "grad_norm": 0.7303863763809204,
      "learning_rate": 3.557256678643962e-05,
      "loss": 1.3596,
      "step": 4125
    },
    {
      "epoch": 0.6482855580723268,
      "grad_norm": 0.9452314376831055,
      "learning_rate": 3.5197625371035774e-05,
      "loss": 1.3883,
      "step": 4150
    },
    {
      "epoch": 0.6521908927595095,
      "grad_norm": 0.63216233253479,
      "learning_rate": 3.4807061396656775e-05,
      "loss": 1.3509,
      "step": 4175
    },
    {
      "epoch": 0.6560962274466922,
      "grad_norm": 0.7277505397796631,
      "learning_rate": 3.441649742227777e-05,
      "loss": 1.4006,
      "step": 4200
    },
    {
      "epoch": 0.6600015621338748,
      "grad_norm": 1.0276042222976685,
      "learning_rate": 3.4025933447898763e-05,
      "loss": 1.3833,
      "step": 4225
    },
    {
      "epoch": 0.6639068968210575,
      "grad_norm": 0.7151803970336914,
      "learning_rate": 3.3635369473519764e-05,
      "loss": 1.4063,
      "step": 4250
    },
    {
      "epoch": 0.6678122315082402,
      "grad_norm": 0.7613582611083984,
      "learning_rate": 3.3244805499140765e-05,
      "loss": 1.3904,
      "step": 4275
    },
    {
      "epoch": 0.671717566195423,
      "grad_norm": 0.7099894881248474,
      "learning_rate": 3.285424152476176e-05,
      "loss": 1.3507,
      "step": 4300
    },
    {
      "epoch": 0.6756229008826057,
      "grad_norm": 0.7098227739334106,
      "learning_rate": 3.2463677550382754e-05,
      "loss": 1.3881,
      "step": 4325
    },
    {
      "epoch": 0.6795282355697884,
      "grad_norm": 0.7104899883270264,
      "learning_rate": 3.207311357600375e-05,
      "loss": 1.3913,
      "step": 4350
    },
    {
      "epoch": 0.683433570256971,
      "grad_norm": 0.7885285019874573,
      "learning_rate": 3.168254960162475e-05,
      "loss": 1.4019,
      "step": 4375
    },
    {
      "epoch": 0.6873389049441537,
      "grad_norm": 0.6337634325027466,
      "learning_rate": 3.129198562724574e-05,
      "loss": 1.3853,
      "step": 4400
    },
    {
      "epoch": 0.6912442396313364,
      "grad_norm": 0.6504437327384949,
      "learning_rate": 3.0901421652866744e-05,
      "loss": 1.3544,
      "step": 4425
    },
    {
      "epoch": 0.6951495743185191,
      "grad_norm": 0.7963951826095581,
      "learning_rate": 3.0510857678487738e-05,
      "loss": 1.3272,
      "step": 4450
    },
    {
      "epoch": 0.6990549090057018,
      "grad_norm": 0.7555502653121948,
      "learning_rate": 3.0120293704108732e-05,
      "loss": 1.3928,
      "step": 4475
    },
    {
      "epoch": 0.7029602436928845,
      "grad_norm": 1.0637465715408325,
      "learning_rate": 2.9729729729729733e-05,
      "loss": 1.3604,
      "step": 4500
    },
    {
      "epoch": 0.7068655783800671,
      "grad_norm": 0.9426074028015137,
      "learning_rate": 2.9339165755350727e-05,
      "loss": 1.3297,
      "step": 4525
    },
    {
      "epoch": 0.7107709130672498,
      "grad_norm": 0.7872856259346008,
      "learning_rate": 2.8948601780971725e-05,
      "loss": 1.3395,
      "step": 4550
    },
    {
      "epoch": 0.7146762477544325,
      "grad_norm": 0.7172676920890808,
      "learning_rate": 2.855803780659272e-05,
      "loss": 1.3647,
      "step": 4575
    },
    {
      "epoch": 0.7185815824416153,
      "grad_norm": 0.7403597235679626,
      "learning_rate": 2.816747383221372e-05,
      "loss": 1.3398,
      "step": 4600
    },
    {
      "epoch": 0.722486917128798,
      "grad_norm": 0.7226228713989258,
      "learning_rate": 2.7776909857834714e-05,
      "loss": 1.3733,
      "step": 4625
    },
    {
      "epoch": 0.7263922518159807,
      "grad_norm": 1.1710747480392456,
      "learning_rate": 2.7386345883455712e-05,
      "loss": 1.3405,
      "step": 4650
    },
    {
      "epoch": 0.7302975865031633,
      "grad_norm": 1.2863526344299316,
      "learning_rate": 2.6995781909076706e-05,
      "loss": 1.4175,
      "step": 4675
    },
    {
      "epoch": 0.734202921190346,
      "grad_norm": 1.0372915267944336,
      "learning_rate": 2.6605217934697707e-05,
      "loss": 1.4226,
      "step": 4700
    },
    {
      "epoch": 0.7381082558775287,
      "grad_norm": 0.8038696050643921,
      "learning_rate": 2.62146539603187e-05,
      "loss": 1.3905,
      "step": 4725
    },
    {
      "epoch": 0.7420135905647114,
      "grad_norm": 0.739514946937561,
      "learning_rate": 2.58240899859397e-05,
      "loss": 1.3712,
      "step": 4750
    },
    {
      "epoch": 0.7459189252518941,
      "grad_norm": 0.894993007183075,
      "learning_rate": 2.5433526011560693e-05,
      "loss": 1.4259,
      "step": 4775
    },
    {
      "epoch": 0.7498242599390768,
      "grad_norm": 1.2273099422454834,
      "learning_rate": 2.5042962037181694e-05,
      "loss": 1.4285,
      "step": 4800
    },
    {
      "epoch": 0.7537295946262594,
      "grad_norm": 0.7948921322822571,
      "learning_rate": 2.465239806280269e-05,
      "loss": 1.3426,
      "step": 4825
    },
    {
      "epoch": 0.7576349293134421,
      "grad_norm": 1.1094671487808228,
      "learning_rate": 2.4261834088423685e-05,
      "loss": 1.3318,
      "step": 4850
    },
    {
      "epoch": 0.7615402640006248,
      "grad_norm": 0.8157749772071838,
      "learning_rate": 2.387127011404468e-05,
      "loss": 1.3405,
      "step": 4875
    },
    {
      "epoch": 0.7654455986878076,
      "grad_norm": 0.7799833416938782,
      "learning_rate": 2.3480706139665677e-05,
      "loss": 1.3339,
      "step": 4900
    },
    {
      "epoch": 0.7693509333749903,
      "grad_norm": 0.8015526533126831,
      "learning_rate": 2.3090142165286675e-05,
      "loss": 1.2953,
      "step": 4925
    },
    {
      "epoch": 0.773256268062173,
      "grad_norm": 0.858633816242218,
      "learning_rate": 2.2699578190907672e-05,
      "loss": 1.3411,
      "step": 4950
    },
    {
      "epoch": 0.7771616027493556,
      "grad_norm": 1.0478750467300415,
      "learning_rate": 2.2309014216528666e-05,
      "loss": 1.3921,
      "step": 4975
    },
    {
      "epoch": 0.7810669374365383,
      "grad_norm": 1.0121499300003052,
      "learning_rate": 2.1918450242149667e-05,
      "loss": 1.3156,
      "step": 5000
    },
    {
      "epoch": 0.7810669374365383,
      "eval_loss": 1.371067762374878,
      "eval_runtime": 1621.4957,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 5000
    },
    {
      "epoch": 0.784972272123721,
      "grad_norm": 1.0243319272994995,
      "learning_rate": 2.152788626777066e-05,
      "loss": 1.3745,
      "step": 5025
    },
    {
      "epoch": 0.7888776068109037,
      "grad_norm": 0.8362109065055847,
      "learning_rate": 2.113732229339166e-05,
      "loss": 1.3795,
      "step": 5050
    },
    {
      "epoch": 0.7927829414980864,
      "grad_norm": 0.6398807764053345,
      "learning_rate": 2.0746758319012653e-05,
      "loss": 1.4155,
      "step": 5075
    },
    {
      "epoch": 0.796688276185269,
      "grad_norm": 0.7267706990242004,
      "learning_rate": 2.0356194344633654e-05,
      "loss": 1.336,
      "step": 5100
    },
    {
      "epoch": 0.8005936108724517,
      "grad_norm": 0.7052307724952698,
      "learning_rate": 1.996563037025465e-05,
      "loss": 1.347,
      "step": 5125
    },
    {
      "epoch": 0.8044989455596344,
      "grad_norm": 0.75350421667099,
      "learning_rate": 1.9575066395875646e-05,
      "loss": 1.3944,
      "step": 5150
    },
    {
      "epoch": 0.8084042802468171,
      "grad_norm": 0.8300211429595947,
      "learning_rate": 1.9184502421496643e-05,
      "loss": 1.3492,
      "step": 5175
    },
    {
      "epoch": 0.8123096149339999,
      "grad_norm": 0.7403693199157715,
      "learning_rate": 1.879393844711764e-05,
      "loss": 1.3726,
      "step": 5200
    },
    {
      "epoch": 0.8162149496211826,
      "grad_norm": 1.0091534852981567,
      "learning_rate": 1.8403374472738635e-05,
      "loss": 1.3142,
      "step": 5225
    },
    {
      "epoch": 0.8201202843083653,
      "grad_norm": 0.7685067653656006,
      "learning_rate": 1.8012810498359633e-05,
      "loss": 1.3977,
      "step": 5250
    },
    {
      "epoch": 0.8240256189955479,
      "grad_norm": 0.7387269735336304,
      "learning_rate": 1.762224652398063e-05,
      "loss": 1.4009,
      "step": 5275
    },
    {
      "epoch": 0.8279309536827306,
      "grad_norm": 0.7391129732131958,
      "learning_rate": 1.7231682549601624e-05,
      "loss": 1.394,
      "step": 5300
    },
    {
      "epoch": 0.8318362883699133,
      "grad_norm": 0.7902172207832336,
      "learning_rate": 1.6841118575222622e-05,
      "loss": 1.3487,
      "step": 5325
    },
    {
      "epoch": 0.835741623057096,
      "grad_norm": 0.8157474994659424,
      "learning_rate": 1.645055460084362e-05,
      "loss": 1.3735,
      "step": 5350
    },
    {
      "epoch": 0.8396469577442787,
      "grad_norm": 0.7818217873573303,
      "learning_rate": 1.6059990626464617e-05,
      "loss": 1.403,
      "step": 5375
    },
    {
      "epoch": 0.8435522924314613,
      "grad_norm": 0.9697117805480957,
      "learning_rate": 1.566942665208561e-05,
      "loss": 1.3657,
      "step": 5400
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.6215644478797913,
      "learning_rate": 1.527886267770661e-05,
      "loss": 1.418,
      "step": 5425
    },
    {
      "epoch": 0.8513629618058267,
      "grad_norm": 0.8901612162590027,
      "learning_rate": 1.4888298703327605e-05,
      "loss": 1.3525,
      "step": 5450
    },
    {
      "epoch": 0.8552682964930095,
      "grad_norm": 0.8169065117835999,
      "learning_rate": 1.4497734728948604e-05,
      "loss": 1.4214,
      "step": 5475
    },
    {
      "epoch": 0.8591736311801922,
      "grad_norm": 0.8597555756568909,
      "learning_rate": 1.4107170754569598e-05,
      "loss": 1.3949,
      "step": 5500
    },
    {
      "epoch": 0.8630789658673749,
      "grad_norm": 0.7627319097518921,
      "learning_rate": 1.3716606780190597e-05,
      "loss": 1.3135,
      "step": 5525
    },
    {
      "epoch": 0.8669843005545576,
      "grad_norm": 0.7136194705963135,
      "learning_rate": 1.3326042805811592e-05,
      "loss": 1.3606,
      "step": 5550
    },
    {
      "epoch": 0.8708896352417402,
      "grad_norm": 0.963046133518219,
      "learning_rate": 1.293547883143259e-05,
      "loss": 1.3821,
      "step": 5575
    },
    {
      "epoch": 0.8747949699289229,
      "grad_norm": 0.9594541788101196,
      "learning_rate": 1.2544914857053585e-05,
      "loss": 1.3539,
      "step": 5600
    },
    {
      "epoch": 0.8787003046161056,
      "grad_norm": 0.7747042775154114,
      "learning_rate": 1.2154350882674583e-05,
      "loss": 1.3584,
      "step": 5625
    },
    {
      "epoch": 0.8826056393032883,
      "grad_norm": 0.540209949016571,
      "learning_rate": 1.176378690829558e-05,
      "loss": 1.3629,
      "step": 5650
    },
    {
      "epoch": 0.886510973990471,
      "grad_norm": 1.0184369087219238,
      "learning_rate": 1.1373222933916576e-05,
      "loss": 1.3523,
      "step": 5675
    },
    {
      "epoch": 0.8904163086776536,
      "grad_norm": 1.009919285774231,
      "learning_rate": 1.0982658959537573e-05,
      "loss": 1.4035,
      "step": 5700
    },
    {
      "epoch": 0.8943216433648363,
      "grad_norm": 0.9293586015701294,
      "learning_rate": 1.059209498515857e-05,
      "loss": 1.387,
      "step": 5725
    },
    {
      "epoch": 0.898226978052019,
      "grad_norm": 0.6847692728042603,
      "learning_rate": 1.0201531010779567e-05,
      "loss": 1.3935,
      "step": 5750
    },
    {
      "epoch": 0.9021323127392018,
      "grad_norm": 1.1162265539169312,
      "learning_rate": 9.810967036400563e-06,
      "loss": 1.3962,
      "step": 5775
    },
    {
      "epoch": 0.9060376474263845,
      "grad_norm": 0.820128858089447,
      "learning_rate": 9.42040306202156e-06,
      "loss": 1.3766,
      "step": 5800
    },
    {
      "epoch": 0.9099429821135672,
      "grad_norm": 0.9112349152565002,
      "learning_rate": 9.029839087642556e-06,
      "loss": 1.3687,
      "step": 5825
    },
    {
      "epoch": 0.9138483168007498,
      "grad_norm": 0.7499094605445862,
      "learning_rate": 8.639275113263554e-06,
      "loss": 1.3931,
      "step": 5850
    },
    {
      "epoch": 0.9177536514879325,
      "grad_norm": 0.779123067855835,
      "learning_rate": 8.24871113888455e-06,
      "loss": 1.3834,
      "step": 5875
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 0.8808546662330627,
      "learning_rate": 7.858147164505545e-06,
      "loss": 1.3434,
      "step": 5900
    },
    {
      "epoch": 0.9255643208622979,
      "grad_norm": 0.7188853025436401,
      "learning_rate": 7.467583190126542e-06,
      "loss": 1.3711,
      "step": 5925
    },
    {
      "epoch": 0.9294696555494806,
      "grad_norm": 1.1590969562530518,
      "learning_rate": 7.077019215747539e-06,
      "loss": 1.3808,
      "step": 5950
    },
    {
      "epoch": 0.9333749902366633,
      "grad_norm": 0.7779844403266907,
      "learning_rate": 6.686455241368536e-06,
      "loss": 1.3926,
      "step": 5975
    },
    {
      "epoch": 0.9372803249238459,
      "grad_norm": 0.8251484036445618,
      "learning_rate": 6.295891266989533e-06,
      "loss": 1.3898,
      "step": 6000
    },
    {
      "epoch": 0.9372803249238459,
      "eval_loss": 1.3691012859344482,
      "eval_runtime": 1621.6313,
      "eval_samples_per_second": 6.316,
      "eval_steps_per_second": 6.316,
      "step": 6000
    },
    {
      "epoch": 0.9411856596110286,
      "grad_norm": 0.8516352772712708,
      "learning_rate": 5.90532729261053e-06,
      "loss": 1.3566,
      "step": 6025
    },
    {
      "epoch": 0.9450909942982113,
      "grad_norm": 0.9251545071601868,
      "learning_rate": 5.5147633182315265e-06,
      "loss": 1.3733,
      "step": 6050
    },
    {
      "epoch": 0.9489963289853941,
      "grad_norm": 0.843480110168457,
      "learning_rate": 5.124199343852523e-06,
      "loss": 1.4116,
      "step": 6075
    },
    {
      "epoch": 0.9529016636725768,
      "grad_norm": 0.9397046566009521,
      "learning_rate": 4.73363536947352e-06,
      "loss": 1.3677,
      "step": 6100
    },
    {
      "epoch": 0.9568069983597595,
      "grad_norm": 0.8314614295959473,
      "learning_rate": 4.343071395094517e-06,
      "loss": 1.3056,
      "step": 6125
    },
    {
      "epoch": 0.9607123330469421,
      "grad_norm": 0.7589595913887024,
      "learning_rate": 3.952507420715513e-06,
      "loss": 1.3952,
      "step": 6150
    },
    {
      "epoch": 0.9646176677341248,
      "grad_norm": 0.8266384601593018,
      "learning_rate": 3.5619434463365105e-06,
      "loss": 1.4275,
      "step": 6175
    },
    {
      "epoch": 0.9685230024213075,
      "grad_norm": 0.8750735521316528,
      "learning_rate": 3.1713794719575072e-06,
      "loss": 1.3525,
      "step": 6200
    },
    {
      "epoch": 0.9724283371084902,
      "grad_norm": 0.7303192019462585,
      "learning_rate": 2.7808154975785035e-06,
      "loss": 1.4298,
      "step": 6225
    },
    {
      "epoch": 0.9763336717956729,
      "grad_norm": 0.6123300790786743,
      "learning_rate": 2.3902515231995002e-06,
      "loss": 1.383,
      "step": 6250
    },
    {
      "epoch": 0.9802390064828556,
      "grad_norm": 0.8566604852676392,
      "learning_rate": 1.999687548820497e-06,
      "loss": 1.3823,
      "step": 6275
    },
    {
      "epoch": 0.9841443411700382,
      "grad_norm": 0.9160458445549011,
      "learning_rate": 1.6091235744414936e-06,
      "loss": 1.4217,
      "step": 6300
    },
    {
      "epoch": 0.9880496758572209,
      "grad_norm": 0.762948215007782,
      "learning_rate": 1.2185596000624903e-06,
      "loss": 1.3899,
      "step": 6325
    },
    {
      "epoch": 0.9919550105444036,
      "grad_norm": 0.8542826175689697,
      "learning_rate": 8.279956256834869e-07,
      "loss": 1.3563,
      "step": 6350
    },
    {
      "epoch": 0.9958603452315864,
      "grad_norm": 0.8672225475311279,
      "learning_rate": 4.3743165130448375e-07,
      "loss": 1.3055,
      "step": 6375
    },
    {
      "epoch": 0.9997656799187691,
      "grad_norm": 0.8037919402122498,
      "learning_rate": 4.6867676925480397e-08,
      "loss": 1.3534,
      "step": 6400
    },
    {
      "epoch": 1.0037491212996954,
      "grad_norm": 0.826476514339447,
      "learning_rate": 7.491407592563662e-05,
      "loss": 1.3865,
      "step": 6425
    },
    {
      "epoch": 1.007654455986878,
      "grad_norm": 0.9432327747344971,
      "learning_rate": 7.481643493204186e-05,
      "loss": 1.3946,
      "step": 6450
    },
    {
      "epoch": 1.0115597906740608,
      "grad_norm": 0.982694685459137,
      "learning_rate": 7.472269957819092e-05,
      "loss": 1.3321,
      "step": 6475
    },
    {
      "epoch": 1.0154651253612434,
      "grad_norm": 0.7818358540534973,
      "learning_rate": 7.462505858459617e-05,
      "loss": 1.3501,
      "step": 6500
    },
    {
      "epoch": 1.0193704600484261,
      "grad_norm": 0.9747583270072937,
      "learning_rate": 7.452741759100141e-05,
      "loss": 1.3367,
      "step": 6525
    },
    {
      "epoch": 1.0232757947356088,
      "grad_norm": 1.0833646059036255,
      "learning_rate": 7.442977659740666e-05,
      "loss": 1.346,
      "step": 6550
    },
    {
      "epoch": 1.0271811294227915,
      "grad_norm": 0.8493674397468567,
      "learning_rate": 7.43321356038119e-05,
      "loss": 1.3775,
      "step": 6575
    },
    {
      "epoch": 1.0310864641099742,
      "grad_norm": 0.6470551490783691,
      "learning_rate": 7.423449461021716e-05,
      "loss": 1.4065,
      "step": 6600
    },
    {
      "epoch": 1.0349917987971569,
      "grad_norm": 1.0185261964797974,
      "learning_rate": 7.41368536166224e-05,
      "loss": 1.3181,
      "step": 6625
    },
    {
      "epoch": 1.0388971334843395,
      "grad_norm": 0.8133153319358826,
      "learning_rate": 7.403921262302765e-05,
      "loss": 1.3429,
      "step": 6650
    },
    {
      "epoch": 1.0428024681715222,
      "grad_norm": 0.9767525792121887,
      "learning_rate": 7.39415716294329e-05,
      "loss": 1.3691,
      "step": 6675
    },
    {
      "epoch": 1.046707802858705,
      "grad_norm": 1.0633299350738525,
      "learning_rate": 7.384393063583816e-05,
      "loss": 1.3778,
      "step": 6700
    },
    {
      "epoch": 1.0506131375458876,
      "grad_norm": 0.9497751593589783,
      "learning_rate": 7.37462896422434e-05,
      "loss": 1.3886,
      "step": 6725
    },
    {
      "epoch": 1.0545184722330703,
      "grad_norm": 0.7641226649284363,
      "learning_rate": 7.364864864864865e-05,
      "loss": 1.3439,
      "step": 6750
    },
    {
      "epoch": 1.0584238069202532,
      "grad_norm": 1.0509138107299805,
      "learning_rate": 7.35510076550539e-05,
      "loss": 1.3767,
      "step": 6775
    },
    {
      "epoch": 1.0623291416074359,
      "grad_norm": 1.1366339921951294,
      "learning_rate": 7.345336666145916e-05,
      "loss": 1.306,
      "step": 6800
    },
    {
      "epoch": 1.0662344762946185,
      "grad_norm": 0.7490823268890381,
      "learning_rate": 7.33557256678644e-05,
      "loss": 1.4165,
      "step": 6825
    },
    {
      "epoch": 1.0701398109818012,
      "grad_norm": 0.6644013524055481,
      "learning_rate": 7.325808467426964e-05,
      "loss": 1.3921,
      "step": 6850
    },
    {
      "epoch": 1.074045145668984,
      "grad_norm": 0.9066840410232544,
      "learning_rate": 7.316044368067489e-05,
      "loss": 1.4062,
      "step": 6875
    },
    {
      "epoch": 1.0779504803561666,
      "grad_norm": 0.8762468695640564,
      "learning_rate": 7.306280268708015e-05,
      "loss": 1.3227,
      "step": 6900
    },
    {
      "epoch": 1.0818558150433493,
      "grad_norm": 0.9282339215278625,
      "learning_rate": 7.29651616934854e-05,
      "loss": 1.363,
      "step": 6925
    },
    {
      "epoch": 1.085761149730532,
      "grad_norm": 0.6422094106674194,
      "learning_rate": 7.286752069989064e-05,
      "loss": 1.3374,
      "step": 6950
    },
    {
      "epoch": 1.0896664844177146,
      "grad_norm": 0.5498624444007874,
      "learning_rate": 7.27698797062959e-05,
      "loss": 1.4027,
      "step": 6975
    },
    {
      "epoch": 1.0935718191048973,
      "grad_norm": 0.8136439919471741,
      "learning_rate": 7.267223871270115e-05,
      "loss": 1.3625,
      "step": 7000
    },
    {
      "epoch": 1.0935718191048973,
      "eval_loss": 1.3712836503982544,
      "eval_runtime": 1634.2173,
      "eval_samples_per_second": 6.267,
      "eval_steps_per_second": 6.267,
      "step": 7000
    },
    {
      "epoch": 1.09747715379208,
      "grad_norm": 0.6871637105941772,
      "learning_rate": 7.25745977191064e-05,
      "loss": 1.436,
      "step": 7025
    },
    {
      "epoch": 1.1013824884792627,
      "grad_norm": 0.8191506266593933,
      "learning_rate": 7.247695672551164e-05,
      "loss": 1.3494,
      "step": 7050
    },
    {
      "epoch": 1.1052878231664454,
      "grad_norm": 0.8758462071418762,
      "learning_rate": 7.23793157319169e-05,
      "loss": 1.3738,
      "step": 7075
    },
    {
      "epoch": 1.109193157853628,
      "grad_norm": 0.7861376404762268,
      "learning_rate": 7.228167473832214e-05,
      "loss": 1.3999,
      "step": 7100
    },
    {
      "epoch": 1.1130984925408107,
      "grad_norm": 1.6929030418395996,
      "learning_rate": 7.218403374472739e-05,
      "loss": 1.3396,
      "step": 7125
    },
    {
      "epoch": 1.1170038272279934,
      "grad_norm": 0.6532300114631653,
      "learning_rate": 7.208639275113264e-05,
      "loss": 1.3813,
      "step": 7150
    },
    {
      "epoch": 1.120909161915176,
      "grad_norm": 0.6423124074935913,
      "learning_rate": 7.198875175753788e-05,
      "loss": 1.3279,
      "step": 7175
    },
    {
      "epoch": 1.1248144966023588,
      "grad_norm": 0.653894305229187,
      "learning_rate": 7.189111076394314e-05,
      "loss": 1.4054,
      "step": 7200
    },
    {
      "epoch": 1.1287198312895415,
      "grad_norm": 0.668275773525238,
      "learning_rate": 7.179346977034839e-05,
      "loss": 1.3701,
      "step": 7225
    },
    {
      "epoch": 1.1326251659767241,
      "grad_norm": 0.7459421753883362,
      "learning_rate": 7.169582877675364e-05,
      "loss": 1.3487,
      "step": 7250
    },
    {
      "epoch": 1.1365305006639068,
      "grad_norm": 0.8038095831871033,
      "learning_rate": 7.159818778315888e-05,
      "loss": 1.4723,
      "step": 7275
    },
    {
      "epoch": 1.1404358353510895,
      "grad_norm": 0.7304537892341614,
      "learning_rate": 7.150054678956414e-05,
      "loss": 1.4164,
      "step": 7300
    },
    {
      "epoch": 1.1443411700382722,
      "grad_norm": 0.6513001918792725,
      "learning_rate": 7.140290579596939e-05,
      "loss": 1.3327,
      "step": 7325
    },
    {
      "epoch": 1.148246504725455,
      "grad_norm": 1.1853796243667603,
      "learning_rate": 7.130526480237463e-05,
      "loss": 1.3854,
      "step": 7350
    },
    {
      "epoch": 1.1521518394126375,
      "grad_norm": 0.8133282661437988,
      "learning_rate": 7.120762380877987e-05,
      "loss": 1.3534,
      "step": 7375
    },
    {
      "epoch": 1.1560571740998205,
      "grad_norm": 0.7639807462692261,
      "learning_rate": 7.110998281518512e-05,
      "loss": 1.3909,
      "step": 7400
    },
    {
      "epoch": 1.1599625087870031,
      "grad_norm": 0.929000973701477,
      "learning_rate": 7.101234182159038e-05,
      "loss": 1.3816,
      "step": 7425
    },
    {
      "epoch": 1.1638678434741858,
      "grad_norm": 0.5327014327049255,
      "learning_rate": 7.091470082799563e-05,
      "loss": 1.3922,
      "step": 7450
    },
    {
      "epoch": 1.1677731781613685,
      "grad_norm": 1.1107865571975708,
      "learning_rate": 7.081705983440089e-05,
      "loss": 1.3218,
      "step": 7475
    },
    {
      "epoch": 1.1716785128485512,
      "grad_norm": 0.8491135239601135,
      "learning_rate": 7.071941884080613e-05,
      "loss": 1.3523,
      "step": 7500
    },
    {
      "epoch": 1.1755838475357339,
      "grad_norm": 0.7545779943466187,
      "learning_rate": 7.062177784721138e-05,
      "loss": 1.3989,
      "step": 7525
    },
    {
      "epoch": 1.1794891822229165,
      "grad_norm": 0.6979825496673584,
      "learning_rate": 7.052413685361663e-05,
      "loss": 1.3562,
      "step": 7550
    },
    {
      "epoch": 1.1833945169100992,
      "grad_norm": 0.775160551071167,
      "learning_rate": 7.042649586002189e-05,
      "loss": 1.4045,
      "step": 7575
    },
    {
      "epoch": 1.187299851597282,
      "grad_norm": 0.6832802891731262,
      "learning_rate": 7.032885486642713e-05,
      "loss": 1.3483,
      "step": 7600
    },
    {
      "epoch": 1.1912051862844646,
      "grad_norm": 0.601177990436554,
      "learning_rate": 7.023121387283237e-05,
      "loss": 1.3271,
      "step": 7625
    },
    {
      "epoch": 1.1951105209716473,
      "grad_norm": 0.6512954831123352,
      "learning_rate": 7.013357287923762e-05,
      "loss": 1.3729,
      "step": 7650
    },
    {
      "epoch": 1.19901585565883,
      "grad_norm": 0.8090227246284485,
      "learning_rate": 7.003593188564287e-05,
      "loss": 1.357,
      "step": 7675
    },
    {
      "epoch": 1.2029211903460126,
      "grad_norm": 0.745160698890686,
      "learning_rate": 6.993829089204811e-05,
      "loss": 1.4114,
      "step": 7700
    },
    {
      "epoch": 1.2068265250331953,
      "grad_norm": 0.9759581685066223,
      "learning_rate": 6.984064989845337e-05,
      "loss": 1.3834,
      "step": 7725
    },
    {
      "epoch": 1.210731859720378,
      "grad_norm": 0.6594054102897644,
      "learning_rate": 6.974300890485862e-05,
      "loss": 1.391,
      "step": 7750
    },
    {
      "epoch": 1.2146371944075607,
      "grad_norm": 0.845685601234436,
      "learning_rate": 6.964536791126387e-05,
      "loss": 1.4352,
      "step": 7775
    },
    {
      "epoch": 1.2185425290947434,
      "grad_norm": 1.0141022205352783,
      "learning_rate": 6.954772691766911e-05,
      "loss": 1.2975,
      "step": 7800
    },
    {
      "epoch": 1.222447863781926,
      "grad_norm": 1.0377135276794434,
      "learning_rate": 6.945008592407437e-05,
      "loss": 1.3642,
      "step": 7825
    },
    {
      "epoch": 1.2263531984691087,
      "grad_norm": 1.0361521244049072,
      "learning_rate": 6.935244493047962e-05,
      "loss": 1.382,
      "step": 7850
    },
    {
      "epoch": 1.2302585331562914,
      "grad_norm": 1.0126973390579224,
      "learning_rate": 6.925480393688486e-05,
      "loss": 1.3799,
      "step": 7875
    },
    {
      "epoch": 1.234163867843474,
      "grad_norm": 0.9690948128700256,
      "learning_rate": 6.915716294329012e-05,
      "loss": 1.3985,
      "step": 7900
    },
    {
      "epoch": 1.238069202530657,
      "grad_norm": 0.6522526741027832,
      "learning_rate": 6.905952194969536e-05,
      "loss": 1.3575,
      "step": 7925
    },
    {
      "epoch": 1.2419745372178395,
      "grad_norm": 0.9931288957595825,
      "learning_rate": 6.896188095610061e-05,
      "loss": 1.3407,
      "step": 7950
    },
    {
      "epoch": 1.2458798719050224,
      "grad_norm": 0.7055680751800537,
      "learning_rate": 6.886423996250586e-05,
      "loss": 1.3875,
      "step": 7975
    },
    {
      "epoch": 1.249785206592205,
      "grad_norm": 0.8442485332489014,
      "learning_rate": 6.876659896891112e-05,
      "loss": 1.3636,
      "step": 8000
    },
    {
      "epoch": 1.249785206592205,
      "eval_loss": 1.369206190109253,
      "eval_runtime": 1634.4216,
      "eval_samples_per_second": 6.266,
      "eval_steps_per_second": 6.266,
      "step": 8000
    },
    {
      "epoch": 1.2536905412793877,
      "grad_norm": 0.8141821622848511,
      "learning_rate": 6.866895797531636e-05,
      "loss": 1.352,
      "step": 8025
    },
    {
      "epoch": 1.2575958759665704,
      "grad_norm": 0.9480127096176147,
      "learning_rate": 6.857131698172161e-05,
      "loss": 1.4302,
      "step": 8050
    },
    {
      "epoch": 1.261501210653753,
      "grad_norm": 0.7328153848648071,
      "learning_rate": 6.847367598812686e-05,
      "loss": 1.3471,
      "step": 8075
    },
    {
      "epoch": 1.2654065453409358,
      "grad_norm": 1.0076953172683716,
      "learning_rate": 6.837603499453212e-05,
      "loss": 1.2896,
      "step": 8100
    },
    {
      "epoch": 1.2693118800281185,
      "grad_norm": 1.0877987146377563,
      "learning_rate": 6.827839400093736e-05,
      "loss": 1.3243,
      "step": 8125
    },
    {
      "epoch": 1.2732172147153011,
      "grad_norm": 0.8529407382011414,
      "learning_rate": 6.81807530073426e-05,
      "loss": 1.4164,
      "step": 8150
    },
    {
      "epoch": 1.2771225494024838,
      "grad_norm": 0.8677666187286377,
      "learning_rate": 6.808311201374785e-05,
      "loss": 1.3268,
      "step": 8175
    },
    {
      "epoch": 1.2810278840896665,
      "grad_norm": 1.0463528633117676,
      "learning_rate": 6.79854710201531e-05,
      "loss": 1.3718,
      "step": 8200
    },
    {
      "epoch": 1.2849332187768492,
      "grad_norm": 0.6416590213775635,
      "learning_rate": 6.788783002655836e-05,
      "loss": 1.3419,
      "step": 8225
    },
    {
      "epoch": 1.2888385534640319,
      "grad_norm": 0.8291686773300171,
      "learning_rate": 6.77901890329636e-05,
      "loss": 1.331,
      "step": 8250
    },
    {
      "epoch": 1.2927438881512145,
      "grad_norm": 0.8016397953033447,
      "learning_rate": 6.769254803936885e-05,
      "loss": 1.3243,
      "step": 8275
    },
    {
      "epoch": 1.2966492228383972,
      "grad_norm": 1.1671720743179321,
      "learning_rate": 6.75949070457741e-05,
      "loss": 1.3948,
      "step": 8300
    },
    {
      "epoch": 1.30055455752558,
      "grad_norm": 0.7608175277709961,
      "learning_rate": 6.749726605217936e-05,
      "loss": 1.3855,
      "step": 8325
    },
    {
      "epoch": 1.3044598922127626,
      "grad_norm": 1.5472832918167114,
      "learning_rate": 6.73996250585846e-05,
      "loss": 1.3912,
      "step": 8350
    },
    {
      "epoch": 1.3083652268999453,
      "grad_norm": 0.9188940525054932,
      "learning_rate": 6.730198406498985e-05,
      "loss": 1.3168,
      "step": 8375
    },
    {
      "epoch": 1.312270561587128,
      "grad_norm": 0.8308167457580566,
      "learning_rate": 6.720434307139509e-05,
      "loss": 1.371,
      "step": 8400
    },
    {
      "epoch": 1.3161758962743106,
      "grad_norm": 0.9710763096809387,
      "learning_rate": 6.710670207780035e-05,
      "loss": 1.2853,
      "step": 8425
    },
    {
      "epoch": 1.3200812309614933,
      "grad_norm": 0.9789024591445923,
      "learning_rate": 6.700906108420559e-05,
      "loss": 1.3626,
      "step": 8450
    },
    {
      "epoch": 1.323986565648676,
      "grad_norm": 0.865369439125061,
      "learning_rate": 6.691142009061084e-05,
      "loss": 1.3331,
      "step": 8475
    },
    {
      "epoch": 1.327891900335859,
      "grad_norm": 0.6146112084388733,
      "learning_rate": 6.68137790970161e-05,
      "loss": 1.359,
      "step": 8500
    },
    {
      "epoch": 1.3317972350230414,
      "grad_norm": 0.5943289995193481,
      "learning_rate": 6.672004374316513e-05,
      "loss": 1.3507,
      "step": 8525
    },
    {
      "epoch": 1.3357025697102243,
      "grad_norm": 0.9272064566612244,
      "learning_rate": 6.662240274957037e-05,
      "loss": 1.3623,
      "step": 8550
    },
    {
      "epoch": 1.3396079043974067,
      "grad_norm": 0.6243643164634705,
      "learning_rate": 6.652476175597563e-05,
      "loss": 1.3879,
      "step": 8575
    },
    {
      "epoch": 1.3435132390845896,
      "grad_norm": 0.744561493396759,
      "learning_rate": 6.642712076238088e-05,
      "loss": 1.3828,
      "step": 8600
    },
    {
      "epoch": 1.3474185737717723,
      "grad_norm": 0.7397298216819763,
      "learning_rate": 6.632947976878614e-05,
      "loss": 1.38,
      "step": 8625
    },
    {
      "epoch": 1.351323908458955,
      "grad_norm": 0.6475093364715576,
      "learning_rate": 6.623183877519138e-05,
      "loss": 1.3509,
      "step": 8650
    },
    {
      "epoch": 1.3552292431461377,
      "grad_norm": 0.8012126684188843,
      "learning_rate": 6.613419778159663e-05,
      "loss": 1.3691,
      "step": 8675
    },
    {
      "epoch": 1.3591345778333204,
      "grad_norm": 0.6896969676017761,
      "learning_rate": 6.603655678800188e-05,
      "loss": 1.2855,
      "step": 8700
    },
    {
      "epoch": 1.363039912520503,
      "grad_norm": 0.9543899893760681,
      "learning_rate": 6.593891579440714e-05,
      "loss": 1.3325,
      "step": 8725
    },
    {
      "epoch": 1.3669452472076857,
      "grad_norm": 0.7190353870391846,
      "learning_rate": 6.584127480081238e-05,
      "loss": 1.3722,
      "step": 8750
    },
    {
      "epoch": 1.3708505818948684,
      "grad_norm": 0.7913508415222168,
      "learning_rate": 6.574363380721763e-05,
      "loss": 1.3992,
      "step": 8775
    },
    {
      "epoch": 1.374755916582051,
      "grad_norm": 0.8860772252082825,
      "learning_rate": 6.564599281362287e-05,
      "loss": 1.3808,
      "step": 8800
    },
    {
      "epoch": 1.3786612512692338,
      "grad_norm": 0.8574299812316895,
      "learning_rate": 6.554835182002812e-05,
      "loss": 1.2686,
      "step": 8825
    },
    {
      "epoch": 1.3825665859564165,
      "grad_norm": 0.7567448019981384,
      "learning_rate": 6.545071082643336e-05,
      "loss": 1.2791,
      "step": 8850
    },
    {
      "epoch": 1.3864719206435991,
      "grad_norm": 0.6631556749343872,
      "learning_rate": 6.535306983283862e-05,
      "loss": 1.4176,
      "step": 8875
    },
    {
      "epoch": 1.3903772553307818,
      "grad_norm": 0.8510225415229797,
      "learning_rate": 6.525542883924387e-05,
      "loss": 1.3921,
      "step": 8900
    },
    {
      "epoch": 1.3942825900179645,
      "grad_norm": 0.6551876068115234,
      "learning_rate": 6.515778784564913e-05,
      "loss": 1.2743,
      "step": 8925
    },
    {
      "epoch": 1.3981879247051472,
      "grad_norm": 0.8922395706176758,
      "learning_rate": 6.506014685205437e-05,
      "loss": 1.3467,
      "step": 8950
    },
    {
      "epoch": 1.4020932593923299,
      "grad_norm": 1.200325846672058,
      "learning_rate": 6.496250585845962e-05,
      "loss": 1.3316,
      "step": 8975
    },
    {
      "epoch": 1.4059985940795126,
      "grad_norm": 0.9003533124923706,
      "learning_rate": 6.486486486486487e-05,
      "loss": 1.3586,
      "step": 9000
    },
    {
      "epoch": 1.4059985940795126,
      "eval_loss": 1.3649587631225586,
      "eval_runtime": 1634.1389,
      "eval_samples_per_second": 6.268,
      "eval_steps_per_second": 6.268,
      "step": 9000
    },
    {
      "epoch": 1.4099039287666952,
      "grad_norm": 0.7240356206893921,
      "learning_rate": 6.476722387127013e-05,
      "loss": 1.2956,
      "step": 9025
    },
    {
      "epoch": 1.413809263453878,
      "grad_norm": 1.309023380279541,
      "learning_rate": 6.466958287767537e-05,
      "loss": 1.3779,
      "step": 9050
    },
    {
      "epoch": 1.4177145981410608,
      "grad_norm": 0.7921628355979919,
      "learning_rate": 6.45719418840806e-05,
      "loss": 1.2669,
      "step": 9075
    },
    {
      "epoch": 1.4216199328282433,
      "grad_norm": 0.7225480079650879,
      "learning_rate": 6.447430089048586e-05,
      "loss": 1.3671,
      "step": 9100
    },
    {
      "epoch": 1.4255252675154262,
      "grad_norm": 1.1047474145889282,
      "learning_rate": 6.437665989689111e-05,
      "loss": 1.3851,
      "step": 9125
    },
    {
      "epoch": 1.4294306022026086,
      "grad_norm": 0.9978737831115723,
      "learning_rate": 6.427901890329637e-05,
      "loss": 1.3417,
      "step": 9150
    },
    {
      "epoch": 1.4333359368897916,
      "grad_norm": 0.7221362590789795,
      "learning_rate": 6.418137790970161e-05,
      "loss": 1.3123,
      "step": 9175
    },
    {
      "epoch": 1.437241271576974,
      "grad_norm": 0.7195819616317749,
      "learning_rate": 6.408373691610686e-05,
      "loss": 1.3229,
      "step": 9200
    },
    {
      "epoch": 1.441146606264157,
      "grad_norm": 0.8682713508605957,
      "learning_rate": 6.398609592251211e-05,
      "loss": 1.3759,
      "step": 9225
    },
    {
      "epoch": 1.4450519409513396,
      "grad_norm": 0.6528059244155884,
      "learning_rate": 6.388845492891737e-05,
      "loss": 1.3658,
      "step": 9250
    },
    {
      "epoch": 1.4489572756385223,
      "grad_norm": 0.7115724086761475,
      "learning_rate": 6.379081393532261e-05,
      "loss": 1.3539,
      "step": 9275
    },
    {
      "epoch": 1.452862610325705,
      "grad_norm": 0.6947727203369141,
      "learning_rate": 6.369317294172786e-05,
      "loss": 1.3274,
      "step": 9300
    },
    {
      "epoch": 1.4567679450128876,
      "grad_norm": 0.7703093886375427,
      "learning_rate": 6.35955319481331e-05,
      "loss": 1.3245,
      "step": 9325
    },
    {
      "epoch": 1.4606732797000703,
      "grad_norm": 0.7850073575973511,
      "learning_rate": 6.349789095453836e-05,
      "loss": 1.3695,
      "step": 9350
    },
    {
      "epoch": 1.464578614387253,
      "grad_norm": 0.7219585180282593,
      "learning_rate": 6.340024996094361e-05,
      "loss": 1.3696,
      "step": 9375
    },
    {
      "epoch": 1.4684839490744357,
      "grad_norm": 0.9624717235565186,
      "learning_rate": 6.330260896734885e-05,
      "loss": 1.3849,
      "step": 9400
    },
    {
      "epoch": 1.4723892837616184,
      "grad_norm": 0.713996410369873,
      "learning_rate": 6.32049679737541e-05,
      "loss": 1.3071,
      "step": 9425
    },
    {
      "epoch": 1.476294618448801,
      "grad_norm": 0.6346928477287292,
      "learning_rate": 6.310732698015936e-05,
      "loss": 1.407,
      "step": 9450
    },
    {
      "epoch": 1.4801999531359837,
      "grad_norm": 0.7286780476570129,
      "learning_rate": 6.300968598656461e-05,
      "loss": 1.3955,
      "step": 9475
    },
    {
      "epoch": 1.4841052878231664,
      "grad_norm": 0.7447071075439453,
      "learning_rate": 6.291204499296985e-05,
      "loss": 1.31,
      "step": 9500
    },
    {
      "epoch": 1.488010622510349,
      "grad_norm": 0.8580664396286011,
      "learning_rate": 6.28144039993751e-05,
      "loss": 1.348,
      "step": 9525
    },
    {
      "epoch": 1.4919159571975318,
      "grad_norm": 0.8237919211387634,
      "learning_rate": 6.271676300578036e-05,
      "loss": 1.376,
      "step": 9550
    },
    {
      "epoch": 1.4958212918847145,
      "grad_norm": 0.7300108671188354,
      "learning_rate": 6.26191220121856e-05,
      "loss": 1.2586,
      "step": 9575
    },
    {
      "epoch": 1.4997266265718971,
      "grad_norm": 0.7839226722717285,
      "learning_rate": 6.252148101859084e-05,
      "loss": 1.3262,
      "step": 9600
    },
    {
      "epoch": 1.5036319612590798,
      "grad_norm": 0.7655742168426514,
      "learning_rate": 6.242384002499609e-05,
      "loss": 1.3684,
      "step": 9625
    },
    {
      "epoch": 1.5075372959462627,
      "grad_norm": 0.7352942824363708,
      "learning_rate": 6.232619903140134e-05,
      "loss": 1.3102,
      "step": 9650
    },
    {
      "epoch": 1.5114426306334452,
      "grad_norm": 0.7664439082145691,
      "learning_rate": 6.22285580378066e-05,
      "loss": 1.3106,
      "step": 9675
    },
    {
      "epoch": 1.515347965320628,
      "grad_norm": 0.8649623394012451,
      "learning_rate": 6.213091704421184e-05,
      "loss": 1.3588,
      "step": 9700
    },
    {
      "epoch": 1.5192533000078106,
      "grad_norm": 0.8835758566856384,
      "learning_rate": 6.203327605061709e-05,
      "loss": 1.3729,
      "step": 9725
    },
    {
      "epoch": 1.5231586346949935,
      "grad_norm": 0.8498286008834839,
      "learning_rate": 6.193563505702235e-05,
      "loss": 1.3573,
      "step": 9750
    },
    {
      "epoch": 1.527063969382176,
      "grad_norm": 0.518770694732666,
      "learning_rate": 6.18379940634276e-05,
      "loss": 1.3269,
      "step": 9775
    },
    {
      "epoch": 1.5309693040693588,
      "grad_norm": 0.6482419371604919,
      "learning_rate": 6.174035306983284e-05,
      "loss": 1.3432,
      "step": 9800
    },
    {
      "epoch": 1.5348746387565413,
      "grad_norm": 0.8815557956695557,
      "learning_rate": 6.164271207623809e-05,
      "loss": 1.3201,
      "step": 9825
    },
    {
      "epoch": 1.5387799734437242,
      "grad_norm": 0.6976563930511475,
      "learning_rate": 6.154507108264333e-05,
      "loss": 1.3439,
      "step": 9850
    },
    {
      "epoch": 1.5426853081309069,
      "grad_norm": 0.9021669030189514,
      "learning_rate": 6.144743008904859e-05,
      "loss": 1.3324,
      "step": 9875
    },
    {
      "epoch": 1.5465906428180896,
      "grad_norm": 0.9769601225852966,
      "learning_rate": 6.134978909545384e-05,
      "loss": 1.3546,
      "step": 9900
    },
    {
      "epoch": 1.5504959775052722,
      "grad_norm": 1.0468862056732178,
      "learning_rate": 6.125214810185908e-05,
      "loss": 1.3582,
      "step": 9925
    },
    {
      "epoch": 1.554401312192455,
      "grad_norm": 0.7685632109642029,
      "learning_rate": 6.115450710826433e-05,
      "loss": 1.3734,
      "step": 9950
    },
    {
      "epoch": 1.5583066468796376,
      "grad_norm": 0.7127953171730042,
      "learning_rate": 6.105686611466959e-05,
      "loss": 1.3371,
      "step": 9975
    },
    {
      "epoch": 1.5622119815668203,
      "grad_norm": 0.735394299030304,
      "learning_rate": 6.0959225121074834e-05,
      "loss": 1.3566,
      "step": 10000
    },
    {
      "epoch": 1.5622119815668203,
      "eval_loss": 1.364108920097351,
      "eval_runtime": 1641.5016,
      "eval_samples_per_second": 6.239,
      "eval_steps_per_second": 6.239,
      "step": 10000
    },
    {
      "epoch": 1.566117316254003,
      "grad_norm": 1.0336960554122925,
      "learning_rate": 6.086158412748009e-05,
      "loss": 1.3889,
      "step": 10025
    },
    {
      "epoch": 1.5700226509411856,
      "grad_norm": 0.9717611074447632,
      "learning_rate": 6.0763943133885335e-05,
      "loss": 1.384,
      "step": 10050
    },
    {
      "epoch": 1.5739279856283683,
      "grad_norm": 0.6737681031227112,
      "learning_rate": 6.066630214029059e-05,
      "loss": 1.3391,
      "step": 10075
    },
    {
      "epoch": 1.577833320315551,
      "grad_norm": 0.7138047218322754,
      "learning_rate": 6.056866114669583e-05,
      "loss": 1.3737,
      "step": 10100
    },
    {
      "epoch": 1.5817386550027337,
      "grad_norm": 0.8504524230957031,
      "learning_rate": 6.0471020153101075e-05,
      "loss": 1.353,
      "step": 10125
    },
    {
      "epoch": 1.5856439896899164,
      "grad_norm": 0.9791404008865356,
      "learning_rate": 6.037337915950633e-05,
      "loss": 1.3136,
      "step": 10150
    },
    {
      "epoch": 1.5895493243770993,
      "grad_norm": 0.9580011963844299,
      "learning_rate": 6.0275738165911576e-05,
      "loss": 1.3457,
      "step": 10175
    },
    {
      "epoch": 1.5934546590642817,
      "grad_norm": 0.652380108833313,
      "learning_rate": 6.017809717231683e-05,
      "loss": 1.3699,
      "step": 10200
    },
    {
      "epoch": 1.5973599937514646,
      "grad_norm": 0.7859220504760742,
      "learning_rate": 6.0080456178722076e-05,
      "loss": 1.3332,
      "step": 10225
    },
    {
      "epoch": 1.601265328438647,
      "grad_norm": 0.8810251355171204,
      "learning_rate": 5.998281518512733e-05,
      "loss": 1.3123,
      "step": 10250
    },
    {
      "epoch": 1.60517066312583,
      "grad_norm": 0.791767418384552,
      "learning_rate": 5.988517419153258e-05,
      "loss": 1.4239,
      "step": 10275
    },
    {
      "epoch": 1.6090759978130125,
      "grad_norm": 0.7632609605789185,
      "learning_rate": 5.978753319793783e-05,
      "loss": 1.3725,
      "step": 10300
    },
    {
      "epoch": 1.6129813325001954,
      "grad_norm": 0.7978947162628174,
      "learning_rate": 5.968989220434308e-05,
      "loss": 1.3469,
      "step": 10325
    },
    {
      "epoch": 1.6168866671873778,
      "grad_norm": 0.6841965913772583,
      "learning_rate": 5.959225121074833e-05,
      "loss": 1.3253,
      "step": 10350
    },
    {
      "epoch": 1.6207920018745607,
      "grad_norm": 2.093449115753174,
      "learning_rate": 5.949461021715357e-05,
      "loss": 1.3366,
      "step": 10375
    },
    {
      "epoch": 1.6246973365617432,
      "grad_norm": 0.9258047342300415,
      "learning_rate": 5.939696922355882e-05,
      "loss": 1.3435,
      "step": 10400
    },
    {
      "epoch": 1.628602671248926,
      "grad_norm": 1.30410635471344,
      "learning_rate": 5.929932822996407e-05,
      "loss": 1.3092,
      "step": 10425
    },
    {
      "epoch": 1.6325080059361086,
      "grad_norm": 0.6484313011169434,
      "learning_rate": 5.920168723636932e-05,
      "loss": 1.3306,
      "step": 10450
    },
    {
      "epoch": 1.6364133406232915,
      "grad_norm": 0.7532194256782532,
      "learning_rate": 5.910404624277457e-05,
      "loss": 1.3879,
      "step": 10475
    },
    {
      "epoch": 1.6403186753104742,
      "grad_norm": 0.8537195324897766,
      "learning_rate": 5.900640524917982e-05,
      "loss": 1.3696,
      "step": 10500
    },
    {
      "epoch": 1.6442240099976568,
      "grad_norm": 0.9194633960723877,
      "learning_rate": 5.890876425558507e-05,
      "loss": 1.4162,
      "step": 10525
    },
    {
      "epoch": 1.6481293446848395,
      "grad_norm": 0.8305969834327698,
      "learning_rate": 5.881112326199032e-05,
      "loss": 1.3667,
      "step": 10550
    },
    {
      "epoch": 1.6520346793720222,
      "grad_norm": 1.0881606340408325,
      "learning_rate": 5.871348226839557e-05,
      "loss": 1.3894,
      "step": 10575
    },
    {
      "epoch": 1.6559400140592049,
      "grad_norm": 0.9575119018554688,
      "learning_rate": 5.861584127480082e-05,
      "loss": 1.4001,
      "step": 10600
    },
    {
      "epoch": 1.6598453487463876,
      "grad_norm": 0.5831546783447266,
      "learning_rate": 5.851820028120606e-05,
      "loss": 1.3394,
      "step": 10625
    },
    {
      "epoch": 1.6637506834335702,
      "grad_norm": 0.7994945049285889,
      "learning_rate": 5.842055928761131e-05,
      "loss": 1.4081,
      "step": 10650
    },
    {
      "epoch": 1.667656018120753,
      "grad_norm": 1.273805856704712,
      "learning_rate": 5.832291829401656e-05,
      "loss": 1.3291,
      "step": 10675
    },
    {
      "epoch": 1.6715613528079356,
      "grad_norm": 0.7565019130706787,
      "learning_rate": 5.822527730042181e-05,
      "loss": 1.3341,
      "step": 10700
    },
    {
      "epoch": 1.6754666874951183,
      "grad_norm": 0.8795378804206848,
      "learning_rate": 5.812763630682706e-05,
      "loss": 1.383,
      "step": 10725
    },
    {
      "epoch": 1.679372022182301,
      "grad_norm": 0.7607576847076416,
      "learning_rate": 5.802999531323231e-05,
      "loss": 1.3052,
      "step": 10750
    },
    {
      "epoch": 1.6832773568694837,
      "grad_norm": 0.6597704291343689,
      "learning_rate": 5.793235431963756e-05,
      "loss": 1.3097,
      "step": 10775
    },
    {
      "epoch": 1.6871826915566666,
      "grad_norm": 0.631804883480072,
      "learning_rate": 5.783471332604281e-05,
      "loss": 1.3873,
      "step": 10800
    },
    {
      "epoch": 1.691088026243849,
      "grad_norm": 0.8984586000442505,
      "learning_rate": 5.773707233244806e-05,
      "loss": 1.3576,
      "step": 10825
    },
    {
      "epoch": 1.694993360931032,
      "grad_norm": 0.6577986478805542,
      "learning_rate": 5.763943133885331e-05,
      "loss": 1.3518,
      "step": 10850
    },
    {
      "epoch": 1.6988986956182144,
      "grad_norm": 0.6625407338142395,
      "learning_rate": 5.754179034525856e-05,
      "loss": 1.3909,
      "step": 10875
    },
    {
      "epoch": 1.7028040303053973,
      "grad_norm": 1.0003132820129395,
      "learning_rate": 5.74441493516638e-05,
      "loss": 1.3487,
      "step": 10900
    },
    {
      "epoch": 1.7067093649925797,
      "grad_norm": 0.9038766622543335,
      "learning_rate": 5.734650835806905e-05,
      "loss": 1.3209,
      "step": 10925
    },
    {
      "epoch": 1.7106146996797627,
      "grad_norm": 0.8501367568969727,
      "learning_rate": 5.72488673644743e-05,
      "loss": 1.405,
      "step": 10950
    },
    {
      "epoch": 1.7145200343669451,
      "grad_norm": 0.7649689316749573,
      "learning_rate": 5.715122637087955e-05,
      "loss": 1.3757,
      "step": 10975
    },
    {
      "epoch": 1.718425369054128,
      "grad_norm": 0.9240680932998657,
      "learning_rate": 5.70535853772848e-05,
      "loss": 1.3672,
      "step": 11000
    },
    {
      "epoch": 1.718425369054128,
      "eval_loss": 1.3619933128356934,
      "eval_runtime": 1673.6579,
      "eval_samples_per_second": 6.12,
      "eval_steps_per_second": 6.12,
      "step": 11000
    },
    {
      "epoch": 1.7223307037413105,
      "grad_norm": 0.6878304481506348,
      "learning_rate": 5.695594438369005e-05,
      "loss": 1.3532,
      "step": 11025
    },
    {
      "epoch": 1.7262360384284934,
      "grad_norm": 1.092368483543396,
      "learning_rate": 5.6858303390095304e-05,
      "loss": 1.3128,
      "step": 11050
    },
    {
      "epoch": 1.730141373115676,
      "grad_norm": 0.841469943523407,
      "learning_rate": 5.676066239650055e-05,
      "loss": 1.3235,
      "step": 11075
    },
    {
      "epoch": 1.7340467078028587,
      "grad_norm": 0.8239331841468811,
      "learning_rate": 5.6663021402905804e-05,
      "loss": 1.3939,
      "step": 11100
    },
    {
      "epoch": 1.7379520424900414,
      "grad_norm": 0.8255379796028137,
      "learning_rate": 5.656538040931105e-05,
      "loss": 1.3487,
      "step": 11125
    },
    {
      "epoch": 1.741857377177224,
      "grad_norm": 0.7424173355102539,
      "learning_rate": 5.646773941571629e-05,
      "loss": 1.399,
      "step": 11150
    },
    {
      "epoch": 1.7457627118644068,
      "grad_norm": 0.9819462299346924,
      "learning_rate": 5.6370098422121545e-05,
      "loss": 1.3494,
      "step": 11175
    },
    {
      "epoch": 1.7496680465515895,
      "grad_norm": 0.819744884967804,
      "learning_rate": 5.627245742852679e-05,
      "loss": 1.3693,
      "step": 11200
    },
    {
      "epoch": 1.7535733812387722,
      "grad_norm": 0.960800290107727,
      "learning_rate": 5.6174816434932045e-05,
      "loss": 1.3403,
      "step": 11225
    },
    {
      "epoch": 1.7574787159259548,
      "grad_norm": 1.08053457736969,
      "learning_rate": 5.607717544133729e-05,
      "loss": 1.2821,
      "step": 11250
    },
    {
      "epoch": 1.7613840506131375,
      "grad_norm": 0.99693763256073,
      "learning_rate": 5.5979534447742546e-05,
      "loss": 1.3208,
      "step": 11275
    },
    {
      "epoch": 1.7652893853003202,
      "grad_norm": 0.9643491506576538,
      "learning_rate": 5.588189345414779e-05,
      "loss": 1.3431,
      "step": 11300
    },
    {
      "epoch": 1.7691947199875029,
      "grad_norm": 0.8187214136123657,
      "learning_rate": 5.5784252460553046e-05,
      "loss": 1.3162,
      "step": 11325
    },
    {
      "epoch": 1.7731000546746856,
      "grad_norm": 0.726246178150177,
      "learning_rate": 5.568661146695829e-05,
      "loss": 1.3547,
      "step": 11350
    },
    {
      "epoch": 1.7770053893618685,
      "grad_norm": 0.885657012462616,
      "learning_rate": 5.5588970473363547e-05,
      "loss": 1.3544,
      "step": 11375
    },
    {
      "epoch": 1.780910724049051,
      "grad_norm": 0.9122483134269714,
      "learning_rate": 5.5491329479768787e-05,
      "loss": 1.3377,
      "step": 11400
    },
    {
      "epoch": 1.7848160587362338,
      "grad_norm": 0.5902431607246399,
      "learning_rate": 5.5393688486174033e-05,
      "loss": 1.3914,
      "step": 11425
    },
    {
      "epoch": 1.7887213934234163,
      "grad_norm": 1.063346266746521,
      "learning_rate": 5.529604749257929e-05,
      "loss": 1.3844,
      "step": 11450
    },
    {
      "epoch": 1.7926267281105992,
      "grad_norm": 0.6201026439666748,
      "learning_rate": 5.5198406498984534e-05,
      "loss": 1.3404,
      "step": 11475
    },
    {
      "epoch": 1.7965320627977817,
      "grad_norm": 1.2140604257583618,
      "learning_rate": 5.510076550538979e-05,
      "loss": 1.3395,
      "step": 11500
    },
    {
      "epoch": 1.8004373974849646,
      "grad_norm": 0.8478405475616455,
      "learning_rate": 5.5003124511795034e-05,
      "loss": 1.327,
      "step": 11525
    },
    {
      "epoch": 1.804342732172147,
      "grad_norm": 0.9936119914054871,
      "learning_rate": 5.490548351820029e-05,
      "loss": 1.3605,
      "step": 11550
    },
    {
      "epoch": 1.80824806685933,
      "grad_norm": 0.767670750617981,
      "learning_rate": 5.4807842524605535e-05,
      "loss": 1.3885,
      "step": 11575
    },
    {
      "epoch": 1.8121534015465124,
      "grad_norm": 0.8203369975090027,
      "learning_rate": 5.471020153101079e-05,
      "loss": 1.3426,
      "step": 11600
    },
    {
      "epoch": 1.8160587362336953,
      "grad_norm": 0.7723694443702698,
      "learning_rate": 5.4612560537416035e-05,
      "loss": 1.3002,
      "step": 11625
    },
    {
      "epoch": 1.819964070920878,
      "grad_norm": 0.769467830657959,
      "learning_rate": 5.451491954382129e-05,
      "loss": 1.3392,
      "step": 11650
    },
    {
      "epoch": 1.8238694056080607,
      "grad_norm": 1.0142529010772705,
      "learning_rate": 5.441727855022652e-05,
      "loss": 1.3768,
      "step": 11675
    },
    {
      "epoch": 1.8277747402952433,
      "grad_norm": 1.2035634517669678,
      "learning_rate": 5.4319637556631776e-05,
      "loss": 1.3212,
      "step": 11700
    },
    {
      "epoch": 1.831680074982426,
      "grad_norm": 0.7025572657585144,
      "learning_rate": 5.422199656303702e-05,
      "loss": 1.3823,
      "step": 11725
    },
    {
      "epoch": 1.8355854096696087,
      "grad_norm": 0.8222755789756775,
      "learning_rate": 5.4124355569442276e-05,
      "loss": 1.3496,
      "step": 11750
    },
    {
      "epoch": 1.8394907443567914,
      "grad_norm": 0.8046228885650635,
      "learning_rate": 5.402671457584752e-05,
      "loss": 1.414,
      "step": 11775
    },
    {
      "epoch": 1.843396079043974,
      "grad_norm": 0.8065323829650879,
      "learning_rate": 5.392907358225278e-05,
      "loss": 1.394,
      "step": 11800
    },
    {
      "epoch": 1.8473014137311567,
      "grad_norm": 0.705103874206543,
      "learning_rate": 5.3831432588658024e-05,
      "loss": 1.3084,
      "step": 11825
    },
    {
      "epoch": 1.8512067484183394,
      "grad_norm": 0.8992977738380432,
      "learning_rate": 5.373379159506328e-05,
      "loss": 1.3588,
      "step": 11850
    },
    {
      "epoch": 1.8551120831055221,
      "grad_norm": 0.992720901966095,
      "learning_rate": 5.3636150601468524e-05,
      "loss": 1.3106,
      "step": 11875
    },
    {
      "epoch": 1.8590174177927048,
      "grad_norm": 0.7058011889457703,
      "learning_rate": 5.353850960787378e-05,
      "loss": 1.3128,
      "step": 11900
    },
    {
      "epoch": 1.8629227524798875,
      "grad_norm": 0.9871295690536499,
      "learning_rate": 5.344086861427902e-05,
      "loss": 1.3465,
      "step": 11925
    },
    {
      "epoch": 1.8668280871670704,
      "grad_norm": 0.7670223116874695,
      "learning_rate": 5.3343227620684265e-05,
      "loss": 1.3465,
      "step": 11950
    },
    {
      "epoch": 1.8707334218542528,
      "grad_norm": 1.4455609321594238,
      "learning_rate": 5.324558662708952e-05,
      "loss": 1.409,
      "step": 11975
    },
    {
      "epoch": 1.8746387565414357,
      "grad_norm": 0.843940019607544,
      "learning_rate": 5.3147945633494765e-05,
      "loss": 1.3446,
      "step": 12000
    },
    {
      "epoch": 1.8746387565414357,
      "eval_loss": 1.3589731454849243,
      "eval_runtime": 1680.1198,
      "eval_samples_per_second": 6.096,
      "eval_steps_per_second": 6.096,
      "step": 12000
    },
    {
      "epoch": 1.8785440912286182,
      "grad_norm": 0.7286854386329651,
      "learning_rate": 5.305030463990002e-05,
      "loss": 1.2998,
      "step": 12025
    },
    {
      "epoch": 1.8824494259158011,
      "grad_norm": 0.876259982585907,
      "learning_rate": 5.2952663646305266e-05,
      "loss": 1.3718,
      "step": 12050
    },
    {
      "epoch": 1.8863547606029836,
      "grad_norm": 0.8706088662147522,
      "learning_rate": 5.285502265271052e-05,
      "loss": 1.3831,
      "step": 12075
    },
    {
      "epoch": 1.8902600952901665,
      "grad_norm": 1.0221946239471436,
      "learning_rate": 5.2757381659115766e-05,
      "loss": 1.3616,
      "step": 12100
    },
    {
      "epoch": 1.894165429977349,
      "grad_norm": 0.724025309085846,
      "learning_rate": 5.265974066552102e-05,
      "loss": 1.3548,
      "step": 12125
    },
    {
      "epoch": 1.8980707646645318,
      "grad_norm": 0.7790807485580444,
      "learning_rate": 5.2562099671926267e-05,
      "loss": 1.3895,
      "step": 12150
    },
    {
      "epoch": 1.9019760993517143,
      "grad_norm": 1.163106083869934,
      "learning_rate": 5.246445867833152e-05,
      "loss": 1.3846,
      "step": 12175
    },
    {
      "epoch": 1.9058814340388972,
      "grad_norm": 0.7226018905639648,
      "learning_rate": 5.236681768473676e-05,
      "loss": 1.3084,
      "step": 12200
    },
    {
      "epoch": 1.9097867687260797,
      "grad_norm": 0.6894704699516296,
      "learning_rate": 5.226917669114201e-05,
      "loss": 1.3114,
      "step": 12225
    },
    {
      "epoch": 1.9136921034132626,
      "grad_norm": 0.7018880844116211,
      "learning_rate": 5.217153569754726e-05,
      "loss": 1.3367,
      "step": 12250
    },
    {
      "epoch": 1.9175974381004453,
      "grad_norm": 1.1130802631378174,
      "learning_rate": 5.207389470395251e-05,
      "loss": 1.3588,
      "step": 12275
    },
    {
      "epoch": 1.921502772787628,
      "grad_norm": 0.8616214990615845,
      "learning_rate": 5.197625371035776e-05,
      "loss": 1.3374,
      "step": 12300
    },
    {
      "epoch": 1.9254081074748106,
      "grad_norm": 1.0426561832427979,
      "learning_rate": 5.187861271676301e-05,
      "loss": 1.3253,
      "step": 12325
    },
    {
      "epoch": 1.9293134421619933,
      "grad_norm": 0.6884651184082031,
      "learning_rate": 5.178097172316826e-05,
      "loss": 1.3387,
      "step": 12350
    },
    {
      "epoch": 1.933218776849176,
      "grad_norm": 0.8176444172859192,
      "learning_rate": 5.168333072957351e-05,
      "loss": 1.3634,
      "step": 12375
    },
    {
      "epoch": 1.9371241115363587,
      "grad_norm": 0.6953847408294678,
      "learning_rate": 5.158568973597876e-05,
      "loss": 1.3438,
      "step": 12400
    },
    {
      "epoch": 1.9410294462235413,
      "grad_norm": 1.708151936531067,
      "learning_rate": 5.148804874238401e-05,
      "loss": 1.2752,
      "step": 12425
    },
    {
      "epoch": 1.944934780910724,
      "grad_norm": 0.7255861163139343,
      "learning_rate": 5.139040774878925e-05,
      "loss": 1.3679,
      "step": 12450
    },
    {
      "epoch": 1.9488401155979067,
      "grad_norm": 0.6945902109146118,
      "learning_rate": 5.1292766755194496e-05,
      "loss": 1.3806,
      "step": 12475
    },
    {
      "epoch": 1.9527454502850894,
      "grad_norm": 0.7466607689857483,
      "learning_rate": 5.119512576159975e-05,
      "loss": 1.2858,
      "step": 12500
    },
    {
      "epoch": 1.956650784972272,
      "grad_norm": 0.6845008134841919,
      "learning_rate": 5.1097484768004996e-05,
      "loss": 1.2775,
      "step": 12525
    },
    {
      "epoch": 1.9605561196594548,
      "grad_norm": 0.7795363664627075,
      "learning_rate": 5.099984377441025e-05,
      "loss": 1.3295,
      "step": 12550
    },
    {
      "epoch": 1.9644614543466377,
      "grad_norm": 1.1081613302230835,
      "learning_rate": 5.09022027808155e-05,
      "loss": 1.32,
      "step": 12575
    },
    {
      "epoch": 1.9683667890338201,
      "grad_norm": 0.5897329449653625,
      "learning_rate": 5.080456178722075e-05,
      "loss": 1.3982,
      "step": 12600
    },
    {
      "epoch": 1.972272123721003,
      "grad_norm": 0.7627431750297546,
      "learning_rate": 5.0706920793626e-05,
      "loss": 1.3793,
      "step": 12625
    },
    {
      "epoch": 1.9761774584081855,
      "grad_norm": 0.777382493019104,
      "learning_rate": 5.060927980003125e-05,
      "loss": 1.3978,
      "step": 12650
    },
    {
      "epoch": 1.9800827930953684,
      "grad_norm": 0.7570546865463257,
      "learning_rate": 5.05116388064365e-05,
      "loss": 1.4417,
      "step": 12675
    },
    {
      "epoch": 1.9839881277825508,
      "grad_norm": 0.6211270093917847,
      "learning_rate": 5.041399781284175e-05,
      "loss": 1.3567,
      "step": 12700
    },
    {
      "epoch": 1.9878934624697338,
      "grad_norm": 1.323318600654602,
      "learning_rate": 5.031635681924699e-05,
      "loss": 1.331,
      "step": 12725
    },
    {
      "epoch": 1.9917987971569162,
      "grad_norm": 0.6921694874763489,
      "learning_rate": 5.021871582565224e-05,
      "loss": 1.3436,
      "step": 12750
    },
    {
      "epoch": 1.9957041318440991,
      "grad_norm": 0.6609841585159302,
      "learning_rate": 5.012107483205749e-05,
      "loss": 1.3136,
      "step": 12775
    },
    {
      "epoch": 1.9996094665312816,
      "grad_norm": 0.7500146627426147,
      "learning_rate": 5.002343383846274e-05,
      "loss": 1.3087,
      "step": 12800
    },
    {
      "epoch": 2.0035148012184645,
      "grad_norm": 0.6617627739906311,
      "learning_rate": 4.992579284486799e-05,
      "loss": 1.3339,
      "step": 12825
    },
    {
      "epoch": 2.007420135905647,
      "grad_norm": 0.7809333801269531,
      "learning_rate": 4.982815185127324e-05,
      "loss": 1.2696,
      "step": 12850
    },
    {
      "epoch": 2.01132547059283,
      "grad_norm": 0.8872743844985962,
      "learning_rate": 4.973051085767849e-05,
      "loss": 1.332,
      "step": 12875
    },
    {
      "epoch": 2.0152308052800123,
      "grad_norm": 0.9883382320404053,
      "learning_rate": 4.963286986408374e-05,
      "loss": 1.3527,
      "step": 12900
    },
    {
      "epoch": 2.019136139967195,
      "grad_norm": 1.0361509323120117,
      "learning_rate": 4.9535228870488987e-05,
      "loss": 1.3529,
      "step": 12925
    },
    {
      "epoch": 2.0230414746543777,
      "grad_norm": 0.7388831377029419,
      "learning_rate": 4.943758787689424e-05,
      "loss": 1.2941,
      "step": 12950
    },
    {
      "epoch": 2.0269468093415606,
      "grad_norm": 0.5949801206588745,
      "learning_rate": 4.933994688329949e-05,
      "loss": 1.2962,
      "step": 12975
    },
    {
      "epoch": 2.0308521440287435,
      "grad_norm": 0.7465807199478149,
      "learning_rate": 4.924230588970474e-05,
      "loss": 1.3724,
      "step": 13000
    },
    {
      "epoch": 2.0308521440287435,
      "eval_loss": 1.3582780361175537,
      "eval_runtime": 1678.7552,
      "eval_samples_per_second": 6.101,
      "eval_steps_per_second": 6.101,
      "step": 13000
    },
    {
      "epoch": 2.034757478715926,
      "grad_norm": 0.7655709981918335,
      "learning_rate": 4.914466489610999e-05,
      "loss": 1.3734,
      "step": 13025
    },
    {
      "epoch": 2.038662813403109,
      "grad_norm": 0.6991175413131714,
      "learning_rate": 4.9047023902515234e-05,
      "loss": 1.3581,
      "step": 13050
    },
    {
      "epoch": 2.0425681480902913,
      "grad_norm": 0.8869374394416809,
      "learning_rate": 4.894938290892048e-05,
      "loss": 1.3122,
      "step": 13075
    },
    {
      "epoch": 2.046473482777474,
      "grad_norm": 0.5490137934684753,
      "learning_rate": 4.8851741915325735e-05,
      "loss": 1.3565,
      "step": 13100
    },
    {
      "epoch": 2.0503788174646567,
      "grad_norm": 0.9734514951705933,
      "learning_rate": 4.875410092173098e-05,
      "loss": 1.2973,
      "step": 13125
    },
    {
      "epoch": 2.0542841521518396,
      "grad_norm": 0.6825133562088013,
      "learning_rate": 4.8656459928136235e-05,
      "loss": 1.2905,
      "step": 13150
    },
    {
      "epoch": 2.058189486839022,
      "grad_norm": 0.8466511368751526,
      "learning_rate": 4.8558818934541475e-05,
      "loss": 1.268,
      "step": 13175
    },
    {
      "epoch": 2.062094821526205,
      "grad_norm": 0.8697696924209595,
      "learning_rate": 4.846117794094673e-05,
      "loss": 1.3547,
      "step": 13200
    },
    {
      "epoch": 2.0660001562133874,
      "grad_norm": 0.6332617998123169,
      "learning_rate": 4.8363536947351976e-05,
      "loss": 1.3531,
      "step": 13225
    },
    {
      "epoch": 2.0699054909005703,
      "grad_norm": 0.8571816086769104,
      "learning_rate": 4.826589595375723e-05,
      "loss": 1.2995,
      "step": 13250
    },
    {
      "epoch": 2.0738108255877528,
      "grad_norm": 0.9128394722938538,
      "learning_rate": 4.8168254960162476e-05,
      "loss": 1.3435,
      "step": 13275
    },
    {
      "epoch": 2.0777161602749357,
      "grad_norm": 0.7887376546859741,
      "learning_rate": 4.807061396656772e-05,
      "loss": 1.3021,
      "step": 13300
    },
    {
      "epoch": 2.081621494962118,
      "grad_norm": 0.7350311279296875,
      "learning_rate": 4.797297297297298e-05,
      "loss": 1.3331,
      "step": 13325
    },
    {
      "epoch": 2.085526829649301,
      "grad_norm": 0.9195606708526611,
      "learning_rate": 4.7875331979378224e-05,
      "loss": 1.3296,
      "step": 13350
    },
    {
      "epoch": 2.0894321643364835,
      "grad_norm": 1.2766687870025635,
      "learning_rate": 4.777769098578348e-05,
      "loss": 1.3542,
      "step": 13375
    },
    {
      "epoch": 2.0933374990236664,
      "grad_norm": 1.1098287105560303,
      "learning_rate": 4.7680049992188724e-05,
      "loss": 1.3493,
      "step": 13400
    },
    {
      "epoch": 2.097242833710849,
      "grad_norm": 0.6439293622970581,
      "learning_rate": 4.758240899859398e-05,
      "loss": 1.3525,
      "step": 13425
    },
    {
      "epoch": 2.1011481683980318,
      "grad_norm": 0.7285522222518921,
      "learning_rate": 4.748476800499922e-05,
      "loss": 1.3698,
      "step": 13450
    },
    {
      "epoch": 2.105053503085214,
      "grad_norm": 0.7946466207504272,
      "learning_rate": 4.738712701140447e-05,
      "loss": 1.3178,
      "step": 13475
    },
    {
      "epoch": 2.108958837772397,
      "grad_norm": 0.7725076675415039,
      "learning_rate": 4.728948601780972e-05,
      "loss": 1.3111,
      "step": 13500
    },
    {
      "epoch": 2.1128641724595796,
      "grad_norm": 0.8298750519752502,
      "learning_rate": 4.719184502421497e-05,
      "loss": 1.3443,
      "step": 13525
    },
    {
      "epoch": 2.1167695071467625,
      "grad_norm": 0.6342355608940125,
      "learning_rate": 4.709420403062022e-05,
      "loss": 1.2831,
      "step": 13550
    },
    {
      "epoch": 2.120674841833945,
      "grad_norm": 0.8746190667152405,
      "learning_rate": 4.6996563037025466e-05,
      "loss": 1.3293,
      "step": 13575
    },
    {
      "epoch": 2.124580176521128,
      "grad_norm": 0.7263983488082886,
      "learning_rate": 4.689892204343071e-05,
      "loss": 1.3072,
      "step": 13600
    },
    {
      "epoch": 2.1284855112083108,
      "grad_norm": 0.953193187713623,
      "learning_rate": 4.6801281049835966e-05,
      "loss": 1.3193,
      "step": 13625
    },
    {
      "epoch": 2.132390845895493,
      "grad_norm": 0.5558953881263733,
      "learning_rate": 4.670364005624121e-05,
      "loss": 1.303,
      "step": 13650
    },
    {
      "epoch": 2.136296180582676,
      "grad_norm": 0.7621833086013794,
      "learning_rate": 4.6605999062646467e-05,
      "loss": 1.3279,
      "step": 13675
    },
    {
      "epoch": 2.1402015152698586,
      "grad_norm": 0.8638795018196106,
      "learning_rate": 4.6508358069051713e-05,
      "loss": 1.305,
      "step": 13700
    },
    {
      "epoch": 2.1441068499570415,
      "grad_norm": 0.9154067039489746,
      "learning_rate": 4.641071707545696e-05,
      "loss": 1.3458,
      "step": 13725
    },
    {
      "epoch": 2.148012184644224,
      "grad_norm": 0.8363500833511353,
      "learning_rate": 4.6313076081862214e-05,
      "loss": 1.3528,
      "step": 13750
    },
    {
      "epoch": 2.151917519331407,
      "grad_norm": 0.7573079466819763,
      "learning_rate": 4.621543508826746e-05,
      "loss": 1.3665,
      "step": 13775
    },
    {
      "epoch": 2.1558228540185893,
      "grad_norm": 0.8985321521759033,
      "learning_rate": 4.6117794094672714e-05,
      "loss": 1.3484,
      "step": 13800
    },
    {
      "epoch": 2.159728188705772,
      "grad_norm": 0.699242889881134,
      "learning_rate": 4.6020153101077954e-05,
      "loss": 1.2865,
      "step": 13825
    },
    {
      "epoch": 2.1636335233929547,
      "grad_norm": 0.6833735704421997,
      "learning_rate": 4.592251210748321e-05,
      "loss": 1.2749,
      "step": 13850
    },
    {
      "epoch": 2.1675388580801376,
      "grad_norm": 0.6184285879135132,
      "learning_rate": 4.5824871113888455e-05,
      "loss": 1.3194,
      "step": 13875
    },
    {
      "epoch": 2.17144419276732,
      "grad_norm": 0.940856397151947,
      "learning_rate": 4.572723012029371e-05,
      "loss": 1.3,
      "step": 13900
    },
    {
      "epoch": 2.175349527454503,
      "grad_norm": 0.8263774514198303,
      "learning_rate": 4.5629589126698955e-05,
      "loss": 1.2856,
      "step": 13925
    },
    {
      "epoch": 2.1792548621416854,
      "grad_norm": 0.6715937852859497,
      "learning_rate": 4.55319481331042e-05,
      "loss": 1.3303,
      "step": 13950
    },
    {
      "epoch": 2.1831601968288683,
      "grad_norm": 0.7521678805351257,
      "learning_rate": 4.543430713950945e-05,
      "loss": 1.3176,
      "step": 13975
    },
    {
      "epoch": 2.1870655315160508,
      "grad_norm": 0.6195969581604004,
      "learning_rate": 4.53366661459147e-05,
      "loss": 1.3374,
      "step": 14000
    },
    {
      "epoch": 2.1870655315160508,
      "eval_loss": 1.357865810394287,
      "eval_runtime": 1679.4631,
      "eval_samples_per_second": 6.098,
      "eval_steps_per_second": 6.098,
      "step": 14000
    },
    {
      "epoch": 2.1909708662032337,
      "grad_norm": 1.0047944784164429,
      "learning_rate": 4.523902515231995e-05,
      "loss": 1.3211,
      "step": 14025
    },
    {
      "epoch": 2.194876200890416,
      "grad_norm": 0.9657245874404907,
      "learning_rate": 4.51413841587252e-05,
      "loss": 1.3119,
      "step": 14050
    },
    {
      "epoch": 2.198781535577599,
      "grad_norm": 0.6374331116676331,
      "learning_rate": 4.504374316513045e-05,
      "loss": 1.3195,
      "step": 14075
    },
    {
      "epoch": 2.2026868702647815,
      "grad_norm": 0.6543293595314026,
      "learning_rate": 4.49461021715357e-05,
      "loss": 1.3145,
      "step": 14100
    },
    {
      "epoch": 2.2065922049519644,
      "grad_norm": 1.1283774375915527,
      "learning_rate": 4.484846117794095e-05,
      "loss": 1.3623,
      "step": 14125
    },
    {
      "epoch": 2.210497539639147,
      "grad_norm": 0.6165851354598999,
      "learning_rate": 4.47508201843462e-05,
      "loss": 1.3212,
      "step": 14150
    },
    {
      "epoch": 2.2144028743263298,
      "grad_norm": 0.8878902196884155,
      "learning_rate": 4.465317919075145e-05,
      "loss": 1.2871,
      "step": 14175
    },
    {
      "epoch": 2.2183082090135127,
      "grad_norm": 0.6543083786964417,
      "learning_rate": 4.45555381971567e-05,
      "loss": 1.3257,
      "step": 14200
    },
    {
      "epoch": 2.222213543700695,
      "grad_norm": 0.644936203956604,
      "learning_rate": 4.4457897203561945e-05,
      "loss": 1.3251,
      "step": 14225
    },
    {
      "epoch": 2.226118878387878,
      "grad_norm": 0.7872569561004639,
      "learning_rate": 4.436025620996719e-05,
      "loss": 1.3329,
      "step": 14250
    },
    {
      "epoch": 2.2300242130750605,
      "grad_norm": 0.7700414657592773,
      "learning_rate": 4.4262615216372445e-05,
      "loss": 1.3156,
      "step": 14275
    },
    {
      "epoch": 2.2339295477622434,
      "grad_norm": 0.9739892482757568,
      "learning_rate": 4.416497422277769e-05,
      "loss": 1.3132,
      "step": 14300
    },
    {
      "epoch": 2.237834882449426,
      "grad_norm": 0.7968143224716187,
      "learning_rate": 4.4067333229182946e-05,
      "loss": 1.3677,
      "step": 14325
    },
    {
      "epoch": 2.2417402171366088,
      "grad_norm": 0.7348251342773438,
      "learning_rate": 4.3969692235588186e-05,
      "loss": 1.3275,
      "step": 14350
    },
    {
      "epoch": 2.245645551823791,
      "grad_norm": 0.9773610830307007,
      "learning_rate": 4.387205124199344e-05,
      "loss": 1.3119,
      "step": 14375
    },
    {
      "epoch": 2.249550886510974,
      "grad_norm": 0.6627633571624756,
      "learning_rate": 4.3774410248398686e-05,
      "loss": 1.3808,
      "step": 14400
    },
    {
      "epoch": 2.2534562211981566,
      "grad_norm": 0.7796668410301208,
      "learning_rate": 4.367676925480394e-05,
      "loss": 1.3384,
      "step": 14425
    },
    {
      "epoch": 2.2573615558853395,
      "grad_norm": 0.7641957998275757,
      "learning_rate": 4.3579128261209193e-05,
      "loss": 1.3561,
      "step": 14450
    },
    {
      "epoch": 2.261266890572522,
      "grad_norm": 0.6668298840522766,
      "learning_rate": 4.3481487267614433e-05,
      "loss": 1.2865,
      "step": 14475
    },
    {
      "epoch": 2.265172225259705,
      "grad_norm": 1.1929060220718384,
      "learning_rate": 4.338384627401969e-05,
      "loss": 1.3152,
      "step": 14500
    },
    {
      "epoch": 2.2690775599468873,
      "grad_norm": 0.6475844979286194,
      "learning_rate": 4.329011092016873e-05,
      "loss": 1.315,
      "step": 14525
    },
    {
      "epoch": 2.27298289463407,
      "grad_norm": 0.9940506219863892,
      "learning_rate": 4.3192469926573975e-05,
      "loss": 1.3039,
      "step": 14550
    },
    {
      "epoch": 2.2768882293212527,
      "grad_norm": 0.9370439648628235,
      "learning_rate": 4.309482893297923e-05,
      "loss": 1.3537,
      "step": 14575
    },
    {
      "epoch": 2.2807935640084356,
      "grad_norm": 0.7804174423217773,
      "learning_rate": 4.2997187939384475e-05,
      "loss": 1.3953,
      "step": 14600
    },
    {
      "epoch": 2.284698898695618,
      "grad_norm": 0.9663949012756348,
      "learning_rate": 4.289954694578972e-05,
      "loss": 1.3228,
      "step": 14625
    },
    {
      "epoch": 2.288604233382801,
      "grad_norm": 0.9068754315376282,
      "learning_rate": 4.280190595219497e-05,
      "loss": 1.3479,
      "step": 14650
    },
    {
      "epoch": 2.2925095680699834,
      "grad_norm": 0.7789004445075989,
      "learning_rate": 4.270426495860022e-05,
      "loss": 1.2887,
      "step": 14675
    },
    {
      "epoch": 2.2964149027571663,
      "grad_norm": 0.8481960892677307,
      "learning_rate": 4.260662396500547e-05,
      "loss": 1.3215,
      "step": 14700
    },
    {
      "epoch": 2.3003202374443488,
      "grad_norm": 0.7717090845108032,
      "learning_rate": 4.250898297141072e-05,
      "loss": 1.2931,
      "step": 14725
    },
    {
      "epoch": 2.3042255721315317,
      "grad_norm": 0.8385216593742371,
      "learning_rate": 4.241134197781596e-05,
      "loss": 1.2906,
      "step": 14750
    },
    {
      "epoch": 2.3081309068187146,
      "grad_norm": 0.7101007103919983,
      "learning_rate": 4.231370098422122e-05,
      "loss": 1.3386,
      "step": 14775
    },
    {
      "epoch": 2.312036241505897,
      "grad_norm": 0.4955604374408722,
      "learning_rate": 4.2216059990626464e-05,
      "loss": 1.3217,
      "step": 14800
    },
    {
      "epoch": 2.3159415761930795,
      "grad_norm": 0.9139432907104492,
      "learning_rate": 4.211841899703172e-05,
      "loss": 1.315,
      "step": 14825
    },
    {
      "epoch": 2.3198469108802624,
      "grad_norm": 0.7565802335739136,
      "learning_rate": 4.2020778003436964e-05,
      "loss": 1.3103,
      "step": 14850
    },
    {
      "epoch": 2.3237522455674453,
      "grad_norm": 0.658191442489624,
      "learning_rate": 4.192313700984221e-05,
      "loss": 1.2726,
      "step": 14875
    },
    {
      "epoch": 2.3276575802546278,
      "grad_norm": 0.7598082423210144,
      "learning_rate": 4.1825496016247464e-05,
      "loss": 1.3262,
      "step": 14900
    },
    {
      "epoch": 2.3315629149418107,
      "grad_norm": 0.8351497054100037,
      "learning_rate": 4.172785502265271e-05,
      "loss": 1.251,
      "step": 14925
    },
    {
      "epoch": 2.335468249628993,
      "grad_norm": 0.8249756097793579,
      "learning_rate": 4.1630214029057965e-05,
      "loss": 1.3039,
      "step": 14950
    },
    {
      "epoch": 2.339373584316176,
      "grad_norm": 1.002480149269104,
      "learning_rate": 4.153257303546321e-05,
      "loss": 1.3429,
      "step": 14975
    },
    {
      "epoch": 2.3432789190033585,
      "grad_norm": 1.30265212059021,
      "learning_rate": 4.1434932041868465e-05,
      "loss": 1.3041,
      "step": 15000
    },
    {
      "epoch": 2.3432789190033585,
      "eval_loss": 1.3571608066558838,
      "eval_runtime": 1680.1738,
      "eval_samples_per_second": 6.096,
      "eval_steps_per_second": 6.096,
      "step": 15000
    },
    {
      "epoch": 2.3471842536905414,
      "grad_norm": 0.607269823551178,
      "learning_rate": 4.1337291048273705e-05,
      "loss": 1.3319,
      "step": 15025
    },
    {
      "epoch": 2.351089588377724,
      "grad_norm": 0.8199865221977234,
      "learning_rate": 4.123965005467896e-05,
      "loss": 1.2742,
      "step": 15050
    },
    {
      "epoch": 2.3549949230649068,
      "grad_norm": 0.7764066457748413,
      "learning_rate": 4.1142009061084206e-05,
      "loss": 1.3407,
      "step": 15075
    },
    {
      "epoch": 2.3589002577520892,
      "grad_norm": 1.266414761543274,
      "learning_rate": 4.104436806748946e-05,
      "loss": 1.3685,
      "step": 15100
    },
    {
      "epoch": 2.362805592439272,
      "grad_norm": 0.8170753717422485,
      "learning_rate": 4.0946727073894706e-05,
      "loss": 1.3141,
      "step": 15125
    },
    {
      "epoch": 2.3667109271264546,
      "grad_norm": 0.7031393647193909,
      "learning_rate": 4.084908608029995e-05,
      "loss": 1.3144,
      "step": 15150
    },
    {
      "epoch": 2.3706162618136375,
      "grad_norm": 0.8947126865386963,
      "learning_rate": 4.07514450867052e-05,
      "loss": 1.324,
      "step": 15175
    },
    {
      "epoch": 2.37452159650082,
      "grad_norm": 0.7413226366043091,
      "learning_rate": 4.0653804093110454e-05,
      "loss": 1.3784,
      "step": 15200
    },
    {
      "epoch": 2.378426931188003,
      "grad_norm": 0.7551025748252869,
      "learning_rate": 4.05561630995157e-05,
      "loss": 1.377,
      "step": 15225
    },
    {
      "epoch": 2.3823322658751853,
      "grad_norm": 0.664182722568512,
      "learning_rate": 4.0458522105920954e-05,
      "loss": 1.267,
      "step": 15250
    },
    {
      "epoch": 2.386237600562368,
      "grad_norm": 0.8426691889762878,
      "learning_rate": 4.03608811123262e-05,
      "loss": 1.3404,
      "step": 15275
    },
    {
      "epoch": 2.3901429352495507,
      "grad_norm": 0.8007363677024841,
      "learning_rate": 4.026324011873145e-05,
      "loss": 1.2659,
      "step": 15300
    },
    {
      "epoch": 2.3940482699367336,
      "grad_norm": 0.8507068157196045,
      "learning_rate": 4.01655991251367e-05,
      "loss": 1.3317,
      "step": 15325
    },
    {
      "epoch": 2.3979536046239165,
      "grad_norm": 0.7290984392166138,
      "learning_rate": 4.006795813154195e-05,
      "loss": 1.3747,
      "step": 15350
    },
    {
      "epoch": 2.401858939311099,
      "grad_norm": 0.7266700267791748,
      "learning_rate": 3.99703171379472e-05,
      "loss": 1.3032,
      "step": 15375
    },
    {
      "epoch": 2.4057642739982814,
      "grad_norm": 0.8202943801879883,
      "learning_rate": 3.987267614435244e-05,
      "loss": 1.3416,
      "step": 15400
    },
    {
      "epoch": 2.4096696086854643,
      "grad_norm": 0.9097173810005188,
      "learning_rate": 3.977894079050148e-05,
      "loss": 1.3473,
      "step": 15425
    },
    {
      "epoch": 2.413574943372647,
      "grad_norm": 0.7089714407920837,
      "learning_rate": 3.9681299796906736e-05,
      "loss": 1.3297,
      "step": 15450
    },
    {
      "epoch": 2.4174802780598297,
      "grad_norm": 0.8064548969268799,
      "learning_rate": 3.958365880331198e-05,
      "loss": 1.3207,
      "step": 15475
    },
    {
      "epoch": 2.4213856127470126,
      "grad_norm": 0.721885085105896,
      "learning_rate": 3.948601780971724e-05,
      "loss": 1.3619,
      "step": 15500
    },
    {
      "epoch": 2.425290947434195,
      "grad_norm": 0.8266960978507996,
      "learning_rate": 3.9388376816122484e-05,
      "loss": 1.3138,
      "step": 15525
    },
    {
      "epoch": 2.429196282121378,
      "grad_norm": 0.5915880799293518,
      "learning_rate": 3.929073582252773e-05,
      "loss": 1.3539,
      "step": 15550
    },
    {
      "epoch": 2.4331016168085604,
      "grad_norm": 0.955826461315155,
      "learning_rate": 3.919309482893298e-05,
      "loss": 1.3633,
      "step": 15575
    },
    {
      "epoch": 2.4370069514957433,
      "grad_norm": 0.8345049619674683,
      "learning_rate": 3.909545383533823e-05,
      "loss": 1.3198,
      "step": 15600
    },
    {
      "epoch": 2.4409122861829258,
      "grad_norm": 0.5345941185951233,
      "learning_rate": 3.899781284174348e-05,
      "loss": 1.2934,
      "step": 15625
    },
    {
      "epoch": 2.4448176208701087,
      "grad_norm": 0.6185193657875061,
      "learning_rate": 3.890017184814873e-05,
      "loss": 1.3436,
      "step": 15650
    },
    {
      "epoch": 2.448722955557291,
      "grad_norm": 0.903962254524231,
      "learning_rate": 3.880253085455398e-05,
      "loss": 1.303,
      "step": 15675
    },
    {
      "epoch": 2.452628290244474,
      "grad_norm": 0.6176283359527588,
      "learning_rate": 3.8704889860959225e-05,
      "loss": 1.3081,
      "step": 15700
    },
    {
      "epoch": 2.4565336249316565,
      "grad_norm": 0.8949341773986816,
      "learning_rate": 3.860724886736448e-05,
      "loss": 1.2799,
      "step": 15725
    },
    {
      "epoch": 2.4604389596188394,
      "grad_norm": 0.9964592456817627,
      "learning_rate": 3.8509607873769726e-05,
      "loss": 1.3594,
      "step": 15750
    },
    {
      "epoch": 2.464344294306022,
      "grad_norm": 0.760585606098175,
      "learning_rate": 3.841196688017498e-05,
      "loss": 1.3074,
      "step": 15775
    },
    {
      "epoch": 2.4682496289932048,
      "grad_norm": 1.1112631559371948,
      "learning_rate": 3.831432588658022e-05,
      "loss": 1.3031,
      "step": 15800
    },
    {
      "epoch": 2.4721549636803872,
      "grad_norm": 0.93595951795578,
      "learning_rate": 3.821668489298547e-05,
      "loss": 1.3962,
      "step": 15825
    },
    {
      "epoch": 2.47606029836757,
      "grad_norm": 0.8299298882484436,
      "learning_rate": 3.811904389939072e-05,
      "loss": 1.3895,
      "step": 15850
    },
    {
      "epoch": 2.4799656330547526,
      "grad_norm": 0.7589401602745056,
      "learning_rate": 3.8021402905795974e-05,
      "loss": 1.2968,
      "step": 15875
    },
    {
      "epoch": 2.4838709677419355,
      "grad_norm": 0.6719589829444885,
      "learning_rate": 3.792376191220122e-05,
      "loss": 1.3079,
      "step": 15900
    },
    {
      "epoch": 2.4877763024291184,
      "grad_norm": 0.6489613056182861,
      "learning_rate": 3.782612091860647e-05,
      "loss": 1.3487,
      "step": 15925
    },
    {
      "epoch": 2.491681637116301,
      "grad_norm": 0.8210853338241577,
      "learning_rate": 3.7728479925011714e-05,
      "loss": 1.3468,
      "step": 15950
    },
    {
      "epoch": 2.4955869718034833,
      "grad_norm": 0.7691444754600525,
      "learning_rate": 3.763083893141697e-05,
      "loss": 1.3117,
      "step": 15975
    },
    {
      "epoch": 2.4994923064906662,
      "grad_norm": 0.9809427261352539,
      "learning_rate": 3.7533197937822215e-05,
      "loss": 1.3014,
      "step": 16000
    },
    {
      "epoch": 2.4994923064906662,
      "eval_loss": 1.3562723398208618,
      "eval_runtime": 1634.0001,
      "eval_samples_per_second": 6.268,
      "eval_steps_per_second": 6.268,
      "step": 16000
    },
    {
      "epoch": 2.503397641177849,
      "grad_norm": 0.7318494915962219,
      "learning_rate": 3.743555694422747e-05,
      "loss": 1.3078,
      "step": 16025
    },
    {
      "epoch": 2.5073029758650316,
      "grad_norm": 0.7161052227020264,
      "learning_rate": 3.7337915950632715e-05,
      "loss": 1.3139,
      "step": 16050
    },
    {
      "epoch": 2.511208310552214,
      "grad_norm": 0.7727983593940735,
      "learning_rate": 3.724027495703796e-05,
      "loss": 1.3735,
      "step": 16075
    },
    {
      "epoch": 2.515113645239397,
      "grad_norm": 0.9412252306938171,
      "learning_rate": 3.7142633963443215e-05,
      "loss": 1.3629,
      "step": 16100
    },
    {
      "epoch": 2.51901897992658,
      "grad_norm": 0.9899818301200867,
      "learning_rate": 3.704499296984846e-05,
      "loss": 1.3089,
      "step": 16125
    },
    {
      "epoch": 2.5229243146137623,
      "grad_norm": 0.658450186252594,
      "learning_rate": 3.6947351976253716e-05,
      "loss": 1.3282,
      "step": 16150
    },
    {
      "epoch": 2.5268296493009452,
      "grad_norm": 0.7711468935012817,
      "learning_rate": 3.684971098265896e-05,
      "loss": 1.279,
      "step": 16175
    },
    {
      "epoch": 2.5307349839881277,
      "grad_norm": 1.234827995300293,
      "learning_rate": 3.675206998906421e-05,
      "loss": 1.3127,
      "step": 16200
    },
    {
      "epoch": 2.5346403186753106,
      "grad_norm": 0.6669085025787354,
      "learning_rate": 3.6654428995469457e-05,
      "loss": 1.3476,
      "step": 16225
    },
    {
      "epoch": 2.538545653362493,
      "grad_norm": 1.0493701696395874,
      "learning_rate": 3.655678800187471e-05,
      "loss": 1.3222,
      "step": 16250
    },
    {
      "epoch": 2.542450988049676,
      "grad_norm": 0.7374215722084045,
      "learning_rate": 3.645914700827996e-05,
      "loss": 1.3111,
      "step": 16275
    },
    {
      "epoch": 2.5463563227368584,
      "grad_norm": 0.9263293147087097,
      "learning_rate": 3.636150601468521e-05,
      "loss": 1.353,
      "step": 16300
    },
    {
      "epoch": 2.5502616574240413,
      "grad_norm": 0.6064057350158691,
      "learning_rate": 3.626386502109045e-05,
      "loss": 1.3466,
      "step": 16325
    },
    {
      "epoch": 2.5541669921112238,
      "grad_norm": 1.032492995262146,
      "learning_rate": 3.6166224027495704e-05,
      "loss": 1.2795,
      "step": 16350
    },
    {
      "epoch": 2.5580723267984067,
      "grad_norm": 0.7248141169548035,
      "learning_rate": 3.606858303390095e-05,
      "loss": 1.2957,
      "step": 16375
    },
    {
      "epoch": 2.5619776614855896,
      "grad_norm": 1.0616356134414673,
      "learning_rate": 3.5970942040306205e-05,
      "loss": 1.3373,
      "step": 16400
    },
    {
      "epoch": 2.565882996172772,
      "grad_norm": 0.840248167514801,
      "learning_rate": 3.587330104671145e-05,
      "loss": 1.3796,
      "step": 16425
    },
    {
      "epoch": 2.5697883308599545,
      "grad_norm": 0.771522045135498,
      "learning_rate": 3.57756600531167e-05,
      "loss": 1.3248,
      "step": 16450
    },
    {
      "epoch": 2.5736936655471374,
      "grad_norm": 0.6676092147827148,
      "learning_rate": 3.567801905952195e-05,
      "loss": 1.3235,
      "step": 16475
    },
    {
      "epoch": 2.5775990002343203,
      "grad_norm": 1.047628402709961,
      "learning_rate": 3.55803780659272e-05,
      "loss": 1.3103,
      "step": 16500
    },
    {
      "epoch": 2.5815043349215028,
      "grad_norm": 1.1062836647033691,
      "learning_rate": 3.548273707233245e-05,
      "loss": 1.3629,
      "step": 16525
    },
    {
      "epoch": 2.5854096696086852,
      "grad_norm": 0.7283019423484802,
      "learning_rate": 3.53850960787377e-05,
      "loss": 1.2657,
      "step": 16550
    },
    {
      "epoch": 2.589315004295868,
      "grad_norm": 0.7392282485961914,
      "learning_rate": 3.528745508514295e-05,
      "loss": 1.2922,
      "step": 16575
    },
    {
      "epoch": 2.593220338983051,
      "grad_norm": 0.7613250017166138,
      "learning_rate": 3.518981409154819e-05,
      "loss": 1.3226,
      "step": 16600
    },
    {
      "epoch": 2.5971256736702335,
      "grad_norm": 0.6932321786880493,
      "learning_rate": 3.509217309795345e-05,
      "loss": 1.3093,
      "step": 16625
    },
    {
      "epoch": 2.601031008357416,
      "grad_norm": 0.885493278503418,
      "learning_rate": 3.4994532104358694e-05,
      "loss": 1.3829,
      "step": 16650
    },
    {
      "epoch": 2.604936343044599,
      "grad_norm": 0.8441534042358398,
      "learning_rate": 3.489689111076395e-05,
      "loss": 1.3127,
      "step": 16675
    },
    {
      "epoch": 2.6088416777317818,
      "grad_norm": 1.0324267148971558,
      "learning_rate": 3.4799250117169194e-05,
      "loss": 1.3638,
      "step": 16700
    },
    {
      "epoch": 2.6127470124189642,
      "grad_norm": 1.0077431201934814,
      "learning_rate": 3.470160912357444e-05,
      "loss": 1.2893,
      "step": 16725
    },
    {
      "epoch": 2.616652347106147,
      "grad_norm": 0.842291533946991,
      "learning_rate": 3.4603968129979695e-05,
      "loss": 1.264,
      "step": 16750
    },
    {
      "epoch": 2.6205576817933296,
      "grad_norm": 0.6417554616928101,
      "learning_rate": 3.450632713638494e-05,
      "loss": 1.2741,
      "step": 16775
    },
    {
      "epoch": 2.6244630164805125,
      "grad_norm": 0.650520384311676,
      "learning_rate": 3.4408686142790195e-05,
      "loss": 1.397,
      "step": 16800
    },
    {
      "epoch": 2.628368351167695,
      "grad_norm": 0.858197033405304,
      "learning_rate": 3.431104514919544e-05,
      "loss": 1.3058,
      "step": 16825
    },
    {
      "epoch": 2.632273685854878,
      "grad_norm": 0.6914021372795105,
      "learning_rate": 3.421340415560069e-05,
      "loss": 1.2982,
      "step": 16850
    },
    {
      "epoch": 2.6361790205420603,
      "grad_norm": 0.642240583896637,
      "learning_rate": 3.4115763162005936e-05,
      "loss": 1.3187,
      "step": 16875
    },
    {
      "epoch": 2.6400843552292432,
      "grad_norm": 0.7275794148445129,
      "learning_rate": 3.401812216841119e-05,
      "loss": 1.3768,
      "step": 16900
    },
    {
      "epoch": 2.6439896899164257,
      "grad_norm": 1.060484766960144,
      "learning_rate": 3.3920481174816436e-05,
      "loss": 1.3135,
      "step": 16925
    },
    {
      "epoch": 2.6478950246036086,
      "grad_norm": 0.8077365756034851,
      "learning_rate": 3.382284018122169e-05,
      "loss": 1.3372,
      "step": 16950
    },
    {
      "epoch": 2.6518003592907915,
      "grad_norm": 0.6196426153182983,
      "learning_rate": 3.372519918762693e-05,
      "loss": 1.2905,
      "step": 16975
    },
    {
      "epoch": 2.655705693977974,
      "grad_norm": 0.8007861375808716,
      "learning_rate": 3.362755819403218e-05,
      "loss": 1.3704,
      "step": 17000
    },
    {
      "epoch": 2.655705693977974,
      "eval_loss": 1.355633020401001,
      "eval_runtime": 1633.8529,
      "eval_samples_per_second": 6.269,
      "eval_steps_per_second": 6.269,
      "step": 17000
    },
    {
      "epoch": 2.6596110286651564,
      "grad_norm": 0.7200896739959717,
      "learning_rate": 3.352991720043743e-05,
      "loss": 1.2779,
      "step": 17025
    },
    {
      "epoch": 2.6635163633523393,
      "grad_norm": 0.6548914909362793,
      "learning_rate": 3.3432276206842684e-05,
      "loss": 1.2868,
      "step": 17050
    },
    {
      "epoch": 2.6674216980395222,
      "grad_norm": 0.9658435583114624,
      "learning_rate": 3.333463521324793e-05,
      "loss": 1.307,
      "step": 17075
    },
    {
      "epoch": 2.6713270327267047,
      "grad_norm": 0.79076087474823,
      "learning_rate": 3.323699421965318e-05,
      "loss": 1.2615,
      "step": 17100
    },
    {
      "epoch": 2.675232367413887,
      "grad_norm": 1.1146492958068848,
      "learning_rate": 3.313935322605843e-05,
      "loss": 1.3291,
      "step": 17125
    },
    {
      "epoch": 2.67913770210107,
      "grad_norm": 0.7142038345336914,
      "learning_rate": 3.304171223246368e-05,
      "loss": 1.3169,
      "step": 17150
    },
    {
      "epoch": 2.683043036788253,
      "grad_norm": 0.6787028908729553,
      "learning_rate": 3.294407123886893e-05,
      "loss": 1.3248,
      "step": 17175
    },
    {
      "epoch": 2.6869483714754354,
      "grad_norm": 1.1382848024368286,
      "learning_rate": 3.284643024527418e-05,
      "loss": 1.3401,
      "step": 17200
    },
    {
      "epoch": 2.690853706162618,
      "grad_norm": 0.8305028080940247,
      "learning_rate": 3.274878925167943e-05,
      "loss": 1.3154,
      "step": 17225
    },
    {
      "epoch": 2.694759040849801,
      "grad_norm": 0.9598212242126465,
      "learning_rate": 3.265114825808467e-05,
      "loss": 1.286,
      "step": 17250
    },
    {
      "epoch": 2.6986643755369837,
      "grad_norm": 0.9193353652954102,
      "learning_rate": 3.2553507264489926e-05,
      "loss": 1.295,
      "step": 17275
    },
    {
      "epoch": 2.702569710224166,
      "grad_norm": 0.8135173916816711,
      "learning_rate": 3.245586627089517e-05,
      "loss": 1.3311,
      "step": 17300
    },
    {
      "epoch": 2.706475044911349,
      "grad_norm": 0.8726162314414978,
      "learning_rate": 3.2358225277300426e-05,
      "loss": 1.3311,
      "step": 17325
    },
    {
      "epoch": 2.7103803795985315,
      "grad_norm": 0.6580794453620911,
      "learning_rate": 3.226058428370567e-05,
      "loss": 1.2861,
      "step": 17350
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.8000079393386841,
      "learning_rate": 3.216294329011092e-05,
      "loss": 1.3245,
      "step": 17375
    },
    {
      "epoch": 2.718191048972897,
      "grad_norm": 0.8962446451187134,
      "learning_rate": 3.206530229651617e-05,
      "loss": 1.3302,
      "step": 17400
    },
    {
      "epoch": 2.7220963836600798,
      "grad_norm": 0.6410462260246277,
      "learning_rate": 3.196766130292142e-05,
      "loss": 1.3403,
      "step": 17425
    },
    {
      "epoch": 2.7260017183472622,
      "grad_norm": 0.6466255187988281,
      "learning_rate": 3.187002030932667e-05,
      "loss": 1.3404,
      "step": 17450
    },
    {
      "epoch": 2.729907053034445,
      "grad_norm": 0.8271024823188782,
      "learning_rate": 3.177237931573192e-05,
      "loss": 1.2825,
      "step": 17475
    },
    {
      "epoch": 2.7338123877216276,
      "grad_norm": 0.8838009834289551,
      "learning_rate": 3.167473832213717e-05,
      "loss": 1.3564,
      "step": 17500
    },
    {
      "epoch": 2.7377177224088105,
      "grad_norm": 0.6439875960350037,
      "learning_rate": 3.1577097328542415e-05,
      "loss": 1.3136,
      "step": 17525
    },
    {
      "epoch": 2.741623057095993,
      "grad_norm": 0.9780490398406982,
      "learning_rate": 3.147945633494767e-05,
      "loss": 1.3697,
      "step": 17550
    },
    {
      "epoch": 2.745528391783176,
      "grad_norm": 0.6483983397483826,
      "learning_rate": 3.1381815341352915e-05,
      "loss": 1.326,
      "step": 17575
    },
    {
      "epoch": 2.7494337264703583,
      "grad_norm": 1.2200955152511597,
      "learning_rate": 3.128417434775817e-05,
      "loss": 1.3675,
      "step": 17600
    },
    {
      "epoch": 2.7533390611575412,
      "grad_norm": 0.9363064765930176,
      "learning_rate": 3.118653335416341e-05,
      "loss": 1.3291,
      "step": 17625
    },
    {
      "epoch": 2.757244395844724,
      "grad_norm": 0.696557343006134,
      "learning_rate": 3.108889236056866e-05,
      "loss": 1.2885,
      "step": 17650
    },
    {
      "epoch": 2.7611497305319066,
      "grad_norm": 1.0763038396835327,
      "learning_rate": 3.099125136697391e-05,
      "loss": 1.3443,
      "step": 17675
    },
    {
      "epoch": 2.765055065219089,
      "grad_norm": 0.7649971842765808,
      "learning_rate": 3.089361037337916e-05,
      "loss": 1.2385,
      "step": 17700
    },
    {
      "epoch": 2.768960399906272,
      "grad_norm": 0.8260789513587952,
      "learning_rate": 3.079596937978441e-05,
      "loss": 1.3199,
      "step": 17725
    },
    {
      "epoch": 2.772865734593455,
      "grad_norm": 0.7850938439369202,
      "learning_rate": 3.069832838618966e-05,
      "loss": 1.3221,
      "step": 17750
    },
    {
      "epoch": 2.7767710692806373,
      "grad_norm": 0.8302540183067322,
      "learning_rate": 3.06006873925949e-05,
      "loss": 1.3339,
      "step": 17775
    },
    {
      "epoch": 2.78067640396782,
      "grad_norm": 0.8823940753936768,
      "learning_rate": 3.0503046399000157e-05,
      "loss": 1.2778,
      "step": 17800
    },
    {
      "epoch": 2.7845817386550027,
      "grad_norm": 0.763630211353302,
      "learning_rate": 3.0405405405405407e-05,
      "loss": 1.3515,
      "step": 17825
    },
    {
      "epoch": 2.7884870733421856,
      "grad_norm": 0.8197940587997437,
      "learning_rate": 3.0307764411810657e-05,
      "loss": 1.3085,
      "step": 17850
    },
    {
      "epoch": 2.792392408029368,
      "grad_norm": 0.5815405249595642,
      "learning_rate": 3.0210123418215908e-05,
      "loss": 1.3081,
      "step": 17875
    },
    {
      "epoch": 2.796297742716551,
      "grad_norm": 0.9977304935455322,
      "learning_rate": 3.011248242462115e-05,
      "loss": 1.3539,
      "step": 17900
    },
    {
      "epoch": 2.8002030774037334,
      "grad_norm": 0.7387352585792542,
      "learning_rate": 3.00148414310264e-05,
      "loss": 1.395,
      "step": 17925
    },
    {
      "epoch": 2.8041084120909163,
      "grad_norm": 1.1226426362991333,
      "learning_rate": 2.991720043743165e-05,
      "loss": 1.2929,
      "step": 17950
    },
    {
      "epoch": 2.808013746778099,
      "grad_norm": 0.7817001342773438,
      "learning_rate": 2.9819559443836902e-05,
      "loss": 1.3797,
      "step": 17975
    },
    {
      "epoch": 2.8119190814652817,
      "grad_norm": 1.0050365924835205,
      "learning_rate": 2.9721918450242152e-05,
      "loss": 1.2868,
      "step": 18000
    },
    {
      "epoch": 2.8119190814652817,
      "eval_loss": 1.3550649881362915,
      "eval_runtime": 1633.9351,
      "eval_samples_per_second": 6.268,
      "eval_steps_per_second": 6.268,
      "step": 18000
    },
    {
      "epoch": 2.815824416152464,
      "grad_norm": 0.6144711375236511,
      "learning_rate": 2.96242774566474e-05,
      "loss": 1.3733,
      "step": 18025
    },
    {
      "epoch": 2.819729750839647,
      "grad_norm": 1.0607811212539673,
      "learning_rate": 2.952663646305265e-05,
      "loss": 1.3682,
      "step": 18050
    },
    {
      "epoch": 2.8236350855268295,
      "grad_norm": 0.6807270646095276,
      "learning_rate": 2.94289954694579e-05,
      "loss": 1.2914,
      "step": 18075
    },
    {
      "epoch": 2.8275404202140124,
      "grad_norm": 0.8147916793823242,
      "learning_rate": 2.933135447586315e-05,
      "loss": 1.3829,
      "step": 18100
    },
    {
      "epoch": 2.831445754901195,
      "grad_norm": 0.8159402012825012,
      "learning_rate": 2.92337134822684e-05,
      "loss": 1.3766,
      "step": 18125
    },
    {
      "epoch": 2.835351089588378,
      "grad_norm": 0.820648193359375,
      "learning_rate": 2.9136072488673643e-05,
      "loss": 1.2934,
      "step": 18150
    },
    {
      "epoch": 2.8392564242755602,
      "grad_norm": 0.7541840076446533,
      "learning_rate": 2.9038431495078894e-05,
      "loss": 1.2933,
      "step": 18175
    },
    {
      "epoch": 2.843161758962743,
      "grad_norm": 0.9433786273002625,
      "learning_rate": 2.8940790501484144e-05,
      "loss": 1.3143,
      "step": 18200
    },
    {
      "epoch": 2.847067093649926,
      "grad_norm": 0.6236405372619629,
      "learning_rate": 2.8843149507889394e-05,
      "loss": 1.304,
      "step": 18225
    },
    {
      "epoch": 2.8509724283371085,
      "grad_norm": 0.7685521841049194,
      "learning_rate": 2.8745508514294644e-05,
      "loss": 1.353,
      "step": 18250
    },
    {
      "epoch": 2.854877763024291,
      "grad_norm": 0.49937528371810913,
      "learning_rate": 2.8647867520699895e-05,
      "loss": 1.2904,
      "step": 18275
    },
    {
      "epoch": 2.858783097711474,
      "grad_norm": 0.8480183482170105,
      "learning_rate": 2.8550226527105138e-05,
      "loss": 1.2906,
      "step": 18300
    },
    {
      "epoch": 2.862688432398657,
      "grad_norm": 1.0172483921051025,
      "learning_rate": 2.8452585533510388e-05,
      "loss": 1.3883,
      "step": 18325
    },
    {
      "epoch": 2.8665937670858392,
      "grad_norm": 1.132555603981018,
      "learning_rate": 2.835494453991564e-05,
      "loss": 1.3259,
      "step": 18350
    },
    {
      "epoch": 2.8704991017730217,
      "grad_norm": 1.2546125650405884,
      "learning_rate": 2.825730354632089e-05,
      "loss": 1.2881,
      "step": 18375
    },
    {
      "epoch": 2.8744044364602046,
      "grad_norm": 0.6849790811538696,
      "learning_rate": 2.815966255272614e-05,
      "loss": 1.3029,
      "step": 18400
    },
    {
      "epoch": 2.8783097711473875,
      "grad_norm": 0.7187618017196655,
      "learning_rate": 2.8062021559131386e-05,
      "loss": 1.3441,
      "step": 18425
    },
    {
      "epoch": 2.88221510583457,
      "grad_norm": 0.8079923987388611,
      "learning_rate": 2.7964380565536636e-05,
      "loss": 1.3639,
      "step": 18450
    },
    {
      "epoch": 2.886120440521753,
      "grad_norm": 0.724310040473938,
      "learning_rate": 2.7866739571941886e-05,
      "loss": 1.4356,
      "step": 18475
    },
    {
      "epoch": 2.8900257752089353,
      "grad_norm": 0.8465993404388428,
      "learning_rate": 2.7769098578347136e-05,
      "loss": 1.3234,
      "step": 18500
    },
    {
      "epoch": 2.8939311098961182,
      "grad_norm": 0.6524661183357239,
      "learning_rate": 2.7671457584752387e-05,
      "loss": 1.3299,
      "step": 18525
    },
    {
      "epoch": 2.8978364445833007,
      "grad_norm": 0.8139395117759705,
      "learning_rate": 2.757381659115763e-05,
      "loss": 1.3556,
      "step": 18550
    },
    {
      "epoch": 2.9017417792704836,
      "grad_norm": 0.584649920463562,
      "learning_rate": 2.747617559756288e-05,
      "loss": 1.3054,
      "step": 18575
    },
    {
      "epoch": 2.905647113957666,
      "grad_norm": 0.8519339561462402,
      "learning_rate": 2.737853460396813e-05,
      "loss": 1.2704,
      "step": 18600
    },
    {
      "epoch": 2.909552448644849,
      "grad_norm": 0.7126177549362183,
      "learning_rate": 2.728089361037338e-05,
      "loss": 1.2817,
      "step": 18625
    },
    {
      "epoch": 2.9134577833320314,
      "grad_norm": 0.8790003061294556,
      "learning_rate": 2.718325261677863e-05,
      "loss": 1.3595,
      "step": 18650
    },
    {
      "epoch": 2.9173631180192143,
      "grad_norm": 0.8177013397216797,
      "learning_rate": 2.7085611623183878e-05,
      "loss": 1.3173,
      "step": 18675
    },
    {
      "epoch": 2.921268452706397,
      "grad_norm": 0.7569385170936584,
      "learning_rate": 2.6987970629589128e-05,
      "loss": 1.3344,
      "step": 18700
    },
    {
      "epoch": 2.9251737873935797,
      "grad_norm": 0.7866888046264648,
      "learning_rate": 2.689032963599438e-05,
      "loss": 1.2772,
      "step": 18725
    },
    {
      "epoch": 2.929079122080762,
      "grad_norm": 0.8126214742660522,
      "learning_rate": 2.679268864239963e-05,
      "loss": 1.337,
      "step": 18750
    },
    {
      "epoch": 2.932984456767945,
      "grad_norm": 0.8118805885314941,
      "learning_rate": 2.669504764880488e-05,
      "loss": 1.3431,
      "step": 18775
    },
    {
      "epoch": 2.936889791455128,
      "grad_norm": 0.8092276453971863,
      "learning_rate": 2.6597406655210122e-05,
      "loss": 1.3409,
      "step": 18800
    },
    {
      "epoch": 2.9407951261423104,
      "grad_norm": 0.8259429931640625,
      "learning_rate": 2.6499765661615373e-05,
      "loss": 1.3077,
      "step": 18825
    },
    {
      "epoch": 2.944700460829493,
      "grad_norm": 1.0016523599624634,
      "learning_rate": 2.6402124668020623e-05,
      "loss": 1.3514,
      "step": 18850
    },
    {
      "epoch": 2.948605795516676,
      "grad_norm": 1.06708562374115,
      "learning_rate": 2.6304483674425873e-05,
      "loss": 1.3167,
      "step": 18875
    },
    {
      "epoch": 2.9525111302038587,
      "grad_norm": 0.8427980542182922,
      "learning_rate": 2.6206842680831123e-05,
      "loss": 1.26,
      "step": 18900
    },
    {
      "epoch": 2.956416464891041,
      "grad_norm": 0.6428595781326294,
      "learning_rate": 2.6109201687236374e-05,
      "loss": 1.3724,
      "step": 18925
    },
    {
      "epoch": 2.9603217995782236,
      "grad_norm": 0.820805549621582,
      "learning_rate": 2.6011560693641617e-05,
      "loss": 1.3577,
      "step": 18950
    },
    {
      "epoch": 2.9642271342654065,
      "grad_norm": 0.7738881707191467,
      "learning_rate": 2.5913919700046867e-05,
      "loss": 1.3336,
      "step": 18975
    },
    {
      "epoch": 2.9681324689525894,
      "grad_norm": 0.7669734954833984,
      "learning_rate": 2.5816278706452117e-05,
      "loss": 1.3386,
      "step": 19000
    },
    {
      "epoch": 2.9681324689525894,
      "eval_loss": 1.353792667388916,
      "eval_runtime": 1676.5666,
      "eval_samples_per_second": 6.109,
      "eval_steps_per_second": 6.109,
      "step": 19000
    },
    {
      "epoch": 2.972037803639772,
      "grad_norm": 0.7770557999610901,
      "learning_rate": 2.5718637712857368e-05,
      "loss": 1.2758,
      "step": 19025
    },
    {
      "epoch": 2.975943138326955,
      "grad_norm": 0.7645183205604553,
      "learning_rate": 2.5620996719262618e-05,
      "loss": 1.3197,
      "step": 19050
    },
    {
      "epoch": 2.9798484730141372,
      "grad_norm": 0.8082094788551331,
      "learning_rate": 2.5523355725667865e-05,
      "loss": 1.3823,
      "step": 19075
    },
    {
      "epoch": 2.98375380770132,
      "grad_norm": 0.7298622727394104,
      "learning_rate": 2.5425714732073115e-05,
      "loss": 1.3168,
      "step": 19100
    },
    {
      "epoch": 2.9876591423885026,
      "grad_norm": 0.8774202466011047,
      "learning_rate": 2.5328073738478365e-05,
      "loss": 1.2944,
      "step": 19125
    },
    {
      "epoch": 2.9915644770756855,
      "grad_norm": 0.8170985579490662,
      "learning_rate": 2.5230432744883616e-05,
      "loss": 1.3274,
      "step": 19150
    },
    {
      "epoch": 2.995469811762868,
      "grad_norm": 0.7615393400192261,
      "learning_rate": 2.5132791751288866e-05,
      "loss": 1.3799,
      "step": 19175
    },
    {
      "epoch": 2.999375146450051,
      "grad_norm": 0.7685465216636658,
      "learning_rate": 2.503515075769411e-05,
      "loss": 1.353,
      "step": 19200
    },
    {
      "epoch": 3.0032804811372333,
      "grad_norm": 1.296862006187439,
      "learning_rate": 2.493750976409936e-05,
      "loss": 1.3057,
      "step": 19225
    },
    {
      "epoch": 3.0071858158244162,
      "grad_norm": 0.8092506527900696,
      "learning_rate": 2.483986877050461e-05,
      "loss": 1.2472,
      "step": 19250
    },
    {
      "epoch": 3.0110911505115987,
      "grad_norm": 0.8291056156158447,
      "learning_rate": 2.474222777690986e-05,
      "loss": 1.315,
      "step": 19275
    },
    {
      "epoch": 3.0149964851987816,
      "grad_norm": 0.7304224967956543,
      "learning_rate": 2.4644586783315107e-05,
      "loss": 1.2672,
      "step": 19300
    },
    {
      "epoch": 3.018901819885964,
      "grad_norm": 0.9971757531166077,
      "learning_rate": 2.4546945789720357e-05,
      "loss": 1.3054,
      "step": 19325
    },
    {
      "epoch": 3.022807154573147,
      "grad_norm": 0.7309479713439941,
      "learning_rate": 2.4449304796125607e-05,
      "loss": 1.3315,
      "step": 19350
    },
    {
      "epoch": 3.0267124892603294,
      "grad_norm": 0.8191229104995728,
      "learning_rate": 2.4355569442274645e-05,
      "loss": 1.2675,
      "step": 19375
    },
    {
      "epoch": 3.0306178239475123,
      "grad_norm": 0.8361122012138367,
      "learning_rate": 2.4257928448679895e-05,
      "loss": 1.2765,
      "step": 19400
    },
    {
      "epoch": 3.034523158634695,
      "grad_norm": 0.8540809154510498,
      "learning_rate": 2.4160287455085145e-05,
      "loss": 1.3086,
      "step": 19425
    },
    {
      "epoch": 3.0384284933218777,
      "grad_norm": 0.7492353320121765,
      "learning_rate": 2.4062646461490392e-05,
      "loss": 1.2511,
      "step": 19450
    },
    {
      "epoch": 3.04233382800906,
      "grad_norm": 0.8547862768173218,
      "learning_rate": 2.3965005467895642e-05,
      "loss": 1.2888,
      "step": 19475
    },
    {
      "epoch": 3.046239162696243,
      "grad_norm": 0.6011192202568054,
      "learning_rate": 2.386736447430089e-05,
      "loss": 1.3062,
      "step": 19500
    },
    {
      "epoch": 3.050144497383426,
      "grad_norm": 0.9319865703582764,
      "learning_rate": 2.376972348070614e-05,
      "loss": 1.3436,
      "step": 19525
    },
    {
      "epoch": 3.0540498320706084,
      "grad_norm": 0.642337441444397,
      "learning_rate": 2.367208248711139e-05,
      "loss": 1.3174,
      "step": 19550
    },
    {
      "epoch": 3.0579551667577913,
      "grad_norm": 0.5977045893669128,
      "learning_rate": 2.357444149351664e-05,
      "loss": 1.3092,
      "step": 19575
    },
    {
      "epoch": 3.061860501444974,
      "grad_norm": 0.9724144339561462,
      "learning_rate": 2.347680049992189e-05,
      "loss": 1.3308,
      "step": 19600
    },
    {
      "epoch": 3.0657658361321567,
      "grad_norm": 0.7432237863540649,
      "learning_rate": 2.3379159506327137e-05,
      "loss": 1.2774,
      "step": 19625
    },
    {
      "epoch": 3.069671170819339,
      "grad_norm": 0.8366708159446716,
      "learning_rate": 2.3281518512732387e-05,
      "loss": 1.2165,
      "step": 19650
    },
    {
      "epoch": 3.073576505506522,
      "grad_norm": 1.022196650505066,
      "learning_rate": 2.3183877519137637e-05,
      "loss": 1.2819,
      "step": 19675
    },
    {
      "epoch": 3.0774818401937045,
      "grad_norm": 0.9706599116325378,
      "learning_rate": 2.3086236525542884e-05,
      "loss": 1.3151,
      "step": 19700
    },
    {
      "epoch": 3.0813871748808874,
      "grad_norm": 0.7247435450553894,
      "learning_rate": 2.2988595531948134e-05,
      "loss": 1.2788,
      "step": 19725
    },
    {
      "epoch": 3.08529250956807,
      "grad_norm": 0.824932873249054,
      "learning_rate": 2.2890954538353385e-05,
      "loss": 1.3416,
      "step": 19750
    },
    {
      "epoch": 3.089197844255253,
      "grad_norm": 1.0219223499298096,
      "learning_rate": 2.279331354475863e-05,
      "loss": 1.2618,
      "step": 19775
    },
    {
      "epoch": 3.0931031789424352,
      "grad_norm": 0.7436484694480896,
      "learning_rate": 2.269567255116388e-05,
      "loss": 1.3122,
      "step": 19800
    },
    {
      "epoch": 3.097008513629618,
      "grad_norm": 0.8345494866371155,
      "learning_rate": 2.259803155756913e-05,
      "loss": 1.2854,
      "step": 19825
    },
    {
      "epoch": 3.1009138483168006,
      "grad_norm": 0.7797983884811401,
      "learning_rate": 2.250039056397438e-05,
      "loss": 1.2652,
      "step": 19850
    },
    {
      "epoch": 3.1048191830039835,
      "grad_norm": 0.7560648322105408,
      "learning_rate": 2.240274957037963e-05,
      "loss": 1.2766,
      "step": 19875
    },
    {
      "epoch": 3.108724517691166,
      "grad_norm": 0.754463255405426,
      "learning_rate": 2.230510857678488e-05,
      "loss": 1.3147,
      "step": 19900
    },
    {
      "epoch": 3.112629852378349,
      "grad_norm": 0.8397393822669983,
      "learning_rate": 2.220746758319013e-05,
      "loss": 1.3055,
      "step": 19925
    },
    {
      "epoch": 3.1165351870655313,
      "grad_norm": 0.6752567887306213,
      "learning_rate": 2.2109826589595376e-05,
      "loss": 1.3558,
      "step": 19950
    },
    {
      "epoch": 3.1204405217527142,
      "grad_norm": 0.9955958724021912,
      "learning_rate": 2.2012185596000627e-05,
      "loss": 1.3227,
      "step": 19975
    },
    {
      "epoch": 3.1243458564398967,
      "grad_norm": 0.7538465857505798,
      "learning_rate": 2.1914544602405877e-05,
      "loss": 1.3256,
      "step": 20000
    },
    {
      "epoch": 3.1243458564398967,
      "eval_loss": 1.354318380355835,
      "eval_runtime": 1660.7945,
      "eval_samples_per_second": 6.167,
      "eval_steps_per_second": 6.167,
      "step": 20000
    },
    {
      "epoch": 3.1282511911270796,
      "grad_norm": 0.6614251136779785,
      "learning_rate": 2.1816903608811124e-05,
      "loss": 1.2821,
      "step": 20025
    },
    {
      "epoch": 3.1321565258142625,
      "grad_norm": 0.7710075974464417,
      "learning_rate": 2.1719262615216374e-05,
      "loss": 1.2392,
      "step": 20050
    },
    {
      "epoch": 3.136061860501445,
      "grad_norm": 0.7502425312995911,
      "learning_rate": 2.1621621621621624e-05,
      "loss": 1.2928,
      "step": 20075
    },
    {
      "epoch": 3.1399671951886274,
      "grad_norm": 0.7025060057640076,
      "learning_rate": 2.152398062802687e-05,
      "loss": 1.3102,
      "step": 20100
    },
    {
      "epoch": 3.1438725298758103,
      "grad_norm": 0.8912141919136047,
      "learning_rate": 2.142633963443212e-05,
      "loss": 1.2934,
      "step": 20125
    },
    {
      "epoch": 3.1477778645629932,
      "grad_norm": 0.6865562796592712,
      "learning_rate": 2.1328698640837368e-05,
      "loss": 1.3151,
      "step": 20150
    },
    {
      "epoch": 3.1516831992501757,
      "grad_norm": 0.5945425629615784,
      "learning_rate": 2.1231057647242618e-05,
      "loss": 1.2961,
      "step": 20175
    },
    {
      "epoch": 3.1555885339373586,
      "grad_norm": 0.7947463989257812,
      "learning_rate": 2.113341665364787e-05,
      "loss": 1.3597,
      "step": 20200
    },
    {
      "epoch": 3.159493868624541,
      "grad_norm": 0.7270830869674683,
      "learning_rate": 2.1035775660053115e-05,
      "loss": 1.2728,
      "step": 20225
    },
    {
      "epoch": 3.163399203311724,
      "grad_norm": 0.7684758305549622,
      "learning_rate": 2.0938134666458366e-05,
      "loss": 1.3204,
      "step": 20250
    },
    {
      "epoch": 3.1673045379989064,
      "grad_norm": 1.1576731204986572,
      "learning_rate": 2.0840493672863616e-05,
      "loss": 1.2941,
      "step": 20275
    },
    {
      "epoch": 3.1712098726860893,
      "grad_norm": 0.9134004712104797,
      "learning_rate": 2.0742852679268866e-05,
      "loss": 1.2915,
      "step": 20300
    },
    {
      "epoch": 3.175115207373272,
      "grad_norm": 0.7146313190460205,
      "learning_rate": 2.0645211685674116e-05,
      "loss": 1.2879,
      "step": 20325
    },
    {
      "epoch": 3.1790205420604547,
      "grad_norm": 0.799666702747345,
      "learning_rate": 2.0547570692079363e-05,
      "loss": 1.2691,
      "step": 20350
    },
    {
      "epoch": 3.182925876747637,
      "grad_norm": 0.9202192425727844,
      "learning_rate": 2.0449929698484613e-05,
      "loss": 1.2902,
      "step": 20375
    },
    {
      "epoch": 3.18683121143482,
      "grad_norm": 1.000792145729065,
      "learning_rate": 2.0352288704889864e-05,
      "loss": 1.2752,
      "step": 20400
    },
    {
      "epoch": 3.1907365461220025,
      "grad_norm": 0.9596400260925293,
      "learning_rate": 2.025464771129511e-05,
      "loss": 1.2857,
      "step": 20425
    },
    {
      "epoch": 3.1946418808091854,
      "grad_norm": 0.8892242908477783,
      "learning_rate": 2.015700671770036e-05,
      "loss": 1.314,
      "step": 20450
    },
    {
      "epoch": 3.198547215496368,
      "grad_norm": 1.0340445041656494,
      "learning_rate": 2.0059365724105608e-05,
      "loss": 1.312,
      "step": 20475
    },
    {
      "epoch": 3.202452550183551,
      "grad_norm": 0.752708375453949,
      "learning_rate": 1.9961724730510858e-05,
      "loss": 1.2954,
      "step": 20500
    },
    {
      "epoch": 3.2063578848707333,
      "grad_norm": 0.9539978504180908,
      "learning_rate": 1.9864083736916108e-05,
      "loss": 1.291,
      "step": 20525
    },
    {
      "epoch": 3.210263219557916,
      "grad_norm": 0.9266553521156311,
      "learning_rate": 1.9766442743321355e-05,
      "loss": 1.319,
      "step": 20550
    },
    {
      "epoch": 3.2141685542450986,
      "grad_norm": 0.7319308519363403,
      "learning_rate": 1.9668801749726605e-05,
      "loss": 1.2625,
      "step": 20575
    },
    {
      "epoch": 3.2180738889322815,
      "grad_norm": 0.6558763980865479,
      "learning_rate": 1.9571160756131855e-05,
      "loss": 1.2792,
      "step": 20600
    },
    {
      "epoch": 3.221979223619464,
      "grad_norm": 0.8929443359375,
      "learning_rate": 1.9473519762537106e-05,
      "loss": 1.2944,
      "step": 20625
    },
    {
      "epoch": 3.225884558306647,
      "grad_norm": 0.9373739957809448,
      "learning_rate": 1.9375878768942356e-05,
      "loss": 1.3497,
      "step": 20650
    },
    {
      "epoch": 3.2297898929938293,
      "grad_norm": 1.057969570159912,
      "learning_rate": 1.9278237775347603e-05,
      "loss": 1.351,
      "step": 20675
    },
    {
      "epoch": 3.2336952276810123,
      "grad_norm": 0.7232056260108948,
      "learning_rate": 1.9180596781752853e-05,
      "loss": 1.3407,
      "step": 20700
    },
    {
      "epoch": 3.237600562368195,
      "grad_norm": 0.8264232277870178,
      "learning_rate": 1.9082955788158103e-05,
      "loss": 1.2774,
      "step": 20725
    },
    {
      "epoch": 3.2415058970553776,
      "grad_norm": 0.876156747341156,
      "learning_rate": 1.898531479456335e-05,
      "loss": 1.2848,
      "step": 20750
    },
    {
      "epoch": 3.2454112317425605,
      "grad_norm": 0.8418545722961426,
      "learning_rate": 1.88876738009686e-05,
      "loss": 1.3091,
      "step": 20775
    },
    {
      "epoch": 3.249316566429743,
      "grad_norm": 0.7475924491882324,
      "learning_rate": 1.8790032807373847e-05,
      "loss": 1.2844,
      "step": 20800
    },
    {
      "epoch": 3.253221901116926,
      "grad_norm": 0.8890367150306702,
      "learning_rate": 1.8692391813779097e-05,
      "loss": 1.292,
      "step": 20825
    },
    {
      "epoch": 3.2571272358041083,
      "grad_norm": 1.0586001873016357,
      "learning_rate": 1.8594750820184348e-05,
      "loss": 1.303,
      "step": 20850
    },
    {
      "epoch": 3.2610325704912912,
      "grad_norm": 0.6586139798164368,
      "learning_rate": 1.8497109826589594e-05,
      "loss": 1.327,
      "step": 20875
    },
    {
      "epoch": 3.2649379051784737,
      "grad_norm": 0.9561905860900879,
      "learning_rate": 1.8399468832994845e-05,
      "loss": 1.296,
      "step": 20900
    },
    {
      "epoch": 3.2688432398656566,
      "grad_norm": 0.8905490636825562,
      "learning_rate": 1.8301827839400095e-05,
      "loss": 1.3025,
      "step": 20925
    },
    {
      "epoch": 3.272748574552839,
      "grad_norm": 0.8053985238075256,
      "learning_rate": 1.8204186845805342e-05,
      "loss": 1.2868,
      "step": 20950
    },
    {
      "epoch": 3.276653909240022,
      "grad_norm": 0.8701311945915222,
      "learning_rate": 1.8106545852210592e-05,
      "loss": 1.3536,
      "step": 20975
    },
    {
      "epoch": 3.2805592439272044,
      "grad_norm": 0.8316996693611145,
      "learning_rate": 1.8008904858615842e-05,
      "loss": 1.3318,
      "step": 21000
    },
    {
      "epoch": 3.2805592439272044,
      "eval_loss": 1.354501724243164,
      "eval_runtime": 2143.0819,
      "eval_samples_per_second": 4.779,
      "eval_steps_per_second": 4.779,
      "step": 21000
    },
    {
      "epoch": 3.2844645786143873,
      "grad_norm": 0.5708069801330566,
      "learning_rate": 1.7911263865021092e-05,
      "loss": 1.2646,
      "step": 21025
    },
    {
      "epoch": 3.28836991330157,
      "grad_norm": 0.8954827785491943,
      "learning_rate": 1.7813622871426343e-05,
      "loss": 1.3047,
      "step": 21050
    },
    {
      "epoch": 3.2922752479887527,
      "grad_norm": 0.5991426706314087,
      "learning_rate": 1.771598187783159e-05,
      "loss": 1.2956,
      "step": 21075
    },
    {
      "epoch": 3.296180582675935,
      "grad_norm": 0.8146704435348511,
      "learning_rate": 1.761834088423684e-05,
      "loss": 1.3095,
      "step": 21100
    },
    {
      "epoch": 3.300085917363118,
      "grad_norm": 0.8283705711364746,
      "learning_rate": 1.752069989064209e-05,
      "loss": 1.3334,
      "step": 21125
    },
    {
      "epoch": 3.3039912520503005,
      "grad_norm": 0.8457741737365723,
      "learning_rate": 1.7423058897047337e-05,
      "loss": 1.3679,
      "step": 21150
    },
    {
      "epoch": 3.3078965867374834,
      "grad_norm": 0.7466288208961487,
      "learning_rate": 1.7325417903452587e-05,
      "loss": 1.2916,
      "step": 21175
    },
    {
      "epoch": 3.3118019214246663,
      "grad_norm": 1.0591851472854614,
      "learning_rate": 1.7227776909857834e-05,
      "loss": 1.3084,
      "step": 21200
    },
    {
      "epoch": 3.315707256111849,
      "grad_norm": 0.7678786516189575,
      "learning_rate": 1.7130135916263084e-05,
      "loss": 1.2284,
      "step": 21225
    },
    {
      "epoch": 3.3196125907990313,
      "grad_norm": 1.026847004890442,
      "learning_rate": 1.7032494922668334e-05,
      "loss": 1.3076,
      "step": 21250
    },
    {
      "epoch": 3.323517925486214,
      "grad_norm": 0.709598183631897,
      "learning_rate": 1.693485392907358e-05,
      "loss": 1.3324,
      "step": 21275
    },
    {
      "epoch": 3.327423260173397,
      "grad_norm": 0.980945348739624,
      "learning_rate": 1.683721293547883e-05,
      "loss": 1.3001,
      "step": 21300
    },
    {
      "epoch": 3.3313285948605795,
      "grad_norm": 0.6714683175086975,
      "learning_rate": 1.6739571941884082e-05,
      "loss": 1.3308,
      "step": 21325
    },
    {
      "epoch": 3.3352339295477624,
      "grad_norm": 0.7671632766723633,
      "learning_rate": 1.6641930948289332e-05,
      "loss": 1.3368,
      "step": 21350
    },
    {
      "epoch": 3.339139264234945,
      "grad_norm": 0.8901289701461792,
      "learning_rate": 1.6544289954694582e-05,
      "loss": 1.3233,
      "step": 21375
    },
    {
      "epoch": 3.343044598922128,
      "grad_norm": 1.1153684854507446,
      "learning_rate": 1.644664896109983e-05,
      "loss": 1.3328,
      "step": 21400
    },
    {
      "epoch": 3.3469499336093103,
      "grad_norm": 0.7532497048377991,
      "learning_rate": 1.634900796750508e-05,
      "loss": 1.3206,
      "step": 21425
    },
    {
      "epoch": 3.350855268296493,
      "grad_norm": 0.6928556561470032,
      "learning_rate": 1.625136697391033e-05,
      "loss": 1.3294,
      "step": 21450
    },
    {
      "epoch": 3.3547606029836756,
      "grad_norm": 0.6636329889297485,
      "learning_rate": 1.6153725980315576e-05,
      "loss": 1.3018,
      "step": 21475
    },
    {
      "epoch": 3.3586659376708585,
      "grad_norm": 0.9833728671073914,
      "learning_rate": 1.6056084986720827e-05,
      "loss": 1.3069,
      "step": 21500
    },
    {
      "epoch": 3.362571272358041,
      "grad_norm": 0.8316293954849243,
      "learning_rate": 1.5958443993126073e-05,
      "loss": 1.2978,
      "step": 21525
    },
    {
      "epoch": 3.366476607045224,
      "grad_norm": 1.0484850406646729,
      "learning_rate": 1.5860802999531324e-05,
      "loss": 1.2971,
      "step": 21550
    },
    {
      "epoch": 3.3703819417324064,
      "grad_norm": 1.0197194814682007,
      "learning_rate": 1.5763162005936574e-05,
      "loss": 1.3463,
      "step": 21575
    },
    {
      "epoch": 3.3742872764195893,
      "grad_norm": 0.826474130153656,
      "learning_rate": 1.566552101234182e-05,
      "loss": 1.2528,
      "step": 21600
    },
    {
      "epoch": 3.3781926111067717,
      "grad_norm": 0.7397425770759583,
      "learning_rate": 1.556788001874707e-05,
      "loss": 1.2832,
      "step": 21625
    },
    {
      "epoch": 3.3820979457939546,
      "grad_norm": 0.7666304707527161,
      "learning_rate": 1.5470239025152318e-05,
      "loss": 1.2964,
      "step": 21650
    },
    {
      "epoch": 3.386003280481137,
      "grad_norm": 0.6672960519790649,
      "learning_rate": 1.5372598031557568e-05,
      "loss": 1.2862,
      "step": 21675
    },
    {
      "epoch": 3.38990861516832,
      "grad_norm": 0.7747824192047119,
      "learning_rate": 1.5274957037962818e-05,
      "loss": 1.3115,
      "step": 21700
    },
    {
      "epoch": 3.3938139498555024,
      "grad_norm": 0.8678906559944153,
      "learning_rate": 1.5177316044368067e-05,
      "loss": 1.3482,
      "step": 21725
    },
    {
      "epoch": 3.3977192845426853,
      "grad_norm": 1.0547798871994019,
      "learning_rate": 1.5079675050773317e-05,
      "loss": 1.3195,
      "step": 21750
    },
    {
      "epoch": 3.401624619229868,
      "grad_norm": 0.6211031675338745,
      "learning_rate": 1.4982034057178567e-05,
      "loss": 1.3629,
      "step": 21775
    },
    {
      "epoch": 3.4055299539170507,
      "grad_norm": 0.7366201281547546,
      "learning_rate": 1.4884393063583816e-05,
      "loss": 1.3149,
      "step": 21800
    },
    {
      "epoch": 3.409435288604233,
      "grad_norm": 0.8747114539146423,
      "learning_rate": 1.4786752069989066e-05,
      "loss": 1.2963,
      "step": 21825
    },
    {
      "epoch": 3.413340623291416,
      "grad_norm": 0.6434773802757263,
      "learning_rate": 1.4689111076394313e-05,
      "loss": 1.2799,
      "step": 21850
    },
    {
      "epoch": 3.417245957978599,
      "grad_norm": 0.8037090301513672,
      "learning_rate": 1.4591470082799563e-05,
      "loss": 1.345,
      "step": 21875
    },
    {
      "epoch": 3.4211512926657814,
      "grad_norm": 0.6632211208343506,
      "learning_rate": 1.4493829089204813e-05,
      "loss": 1.2839,
      "step": 21900
    },
    {
      "epoch": 3.425056627352964,
      "grad_norm": 1.207157015800476,
      "learning_rate": 1.439618809561006e-05,
      "loss": 1.2684,
      "step": 21925
    },
    {
      "epoch": 3.428961962040147,
      "grad_norm": 0.8931275010108948,
      "learning_rate": 1.429854710201531e-05,
      "loss": 1.2898,
      "step": 21950
    },
    {
      "epoch": 3.4328672967273297,
      "grad_norm": 0.7558072209358215,
      "learning_rate": 1.420090610842056e-05,
      "loss": 1.3269,
      "step": 21975
    },
    {
      "epoch": 3.436772631414512,
      "grad_norm": 0.68391352891922,
      "learning_rate": 1.410326511482581e-05,
      "loss": 1.3299,
      "step": 22000
    },
    {
      "epoch": 3.436772631414512,
      "eval_loss": 1.353966236114502,
      "eval_runtime": 1633.9054,
      "eval_samples_per_second": 6.268,
      "eval_steps_per_second": 6.268,
      "step": 22000
    },
    {
      "epoch": 3.440677966101695,
      "grad_norm": 0.8845788240432739,
      "learning_rate": 1.400562412123106e-05,
      "loss": 1.3102,
      "step": 22025
    },
    {
      "epoch": 3.4445833007888775,
      "grad_norm": 0.8646826148033142,
      "learning_rate": 1.3907983127636306e-05,
      "loss": 1.2831,
      "step": 22050
    },
    {
      "epoch": 3.4484886354760604,
      "grad_norm": 0.9202032685279846,
      "learning_rate": 1.3814247773785347e-05,
      "loss": 1.2941,
      "step": 22075
    },
    {
      "epoch": 3.452393970163243,
      "grad_norm": 0.8789118528366089,
      "learning_rate": 1.3716606780190597e-05,
      "loss": 1.2892,
      "step": 22100
    },
    {
      "epoch": 3.456299304850426,
      "grad_norm": 0.7771650552749634,
      "learning_rate": 1.3618965786595844e-05,
      "loss": 1.3323,
      "step": 22125
    },
    {
      "epoch": 3.4602046395376083,
      "grad_norm": 1.0603415966033936,
      "learning_rate": 1.3521324793001094e-05,
      "loss": 1.3588,
      "step": 22150
    },
    {
      "epoch": 3.464109974224791,
      "grad_norm": 0.8594583868980408,
      "learning_rate": 1.3423683799406345e-05,
      "loss": 1.3281,
      "step": 22175
    },
    {
      "epoch": 3.4680153089119736,
      "grad_norm": 0.6498304605484009,
      "learning_rate": 1.3326042805811592e-05,
      "loss": 1.3122,
      "step": 22200
    },
    {
      "epoch": 3.4719206435991565,
      "grad_norm": 0.7584251761436462,
      "learning_rate": 1.3228401812216842e-05,
      "loss": 1.3271,
      "step": 22225
    },
    {
      "epoch": 3.475825978286339,
      "grad_norm": 0.9355670809745789,
      "learning_rate": 1.313076081862209e-05,
      "loss": 1.3153,
      "step": 22250
    },
    {
      "epoch": 3.479731312973522,
      "grad_norm": 0.6093696355819702,
      "learning_rate": 1.303311982502734e-05,
      "loss": 1.3236,
      "step": 22275
    },
    {
      "epoch": 3.4836366476607044,
      "grad_norm": 1.0401698350906372,
      "learning_rate": 1.293547883143259e-05,
      "loss": 1.3236,
      "step": 22300
    },
    {
      "epoch": 3.4875419823478873,
      "grad_norm": 0.690137505531311,
      "learning_rate": 1.2837837837837838e-05,
      "loss": 1.2798,
      "step": 22325
    },
    {
      "epoch": 3.4914473170350697,
      "grad_norm": 0.7687968015670776,
      "learning_rate": 1.2740196844243088e-05,
      "loss": 1.3027,
      "step": 22350
    },
    {
      "epoch": 3.4953526517222526,
      "grad_norm": 0.9118028879165649,
      "learning_rate": 1.2642555850648335e-05,
      "loss": 1.3568,
      "step": 22375
    },
    {
      "epoch": 3.499257986409435,
      "grad_norm": 0.667023241519928,
      "learning_rate": 1.2544914857053585e-05,
      "loss": 1.33,
      "step": 22400
    },
    {
      "epoch": 3.503163321096618,
      "grad_norm": 0.6527143120765686,
      "learning_rate": 1.2447273863458835e-05,
      "loss": 1.3397,
      "step": 22425
    },
    {
      "epoch": 3.507068655783801,
      "grad_norm": 0.6761289834976196,
      "learning_rate": 1.2349632869864085e-05,
      "loss": 1.2987,
      "step": 22450
    },
    {
      "epoch": 3.5109739904709834,
      "grad_norm": 0.6645992398262024,
      "learning_rate": 1.2251991876269334e-05,
      "loss": 1.3241,
      "step": 22475
    },
    {
      "epoch": 3.514879325158166,
      "grad_norm": 0.8202558159828186,
      "learning_rate": 1.2154350882674583e-05,
      "loss": 1.3222,
      "step": 22500
    },
    {
      "epoch": 3.5187846598453487,
      "grad_norm": 0.6154232025146484,
      "learning_rate": 1.2056709889079831e-05,
      "loss": 1.3232,
      "step": 22525
    },
    {
      "epoch": 3.5226899945325316,
      "grad_norm": 0.8117192387580872,
      "learning_rate": 1.1959068895485081e-05,
      "loss": 1.3245,
      "step": 22550
    },
    {
      "epoch": 3.526595329219714,
      "grad_norm": 0.7439884543418884,
      "learning_rate": 1.186142790189033e-05,
      "loss": 1.2683,
      "step": 22575
    },
    {
      "epoch": 3.530500663906897,
      "grad_norm": 0.6828821301460266,
      "learning_rate": 1.176378690829558e-05,
      "loss": 1.2969,
      "step": 22600
    },
    {
      "epoch": 3.5344059985940794,
      "grad_norm": 0.7111977934837341,
      "learning_rate": 1.1666145914700829e-05,
      "loss": 1.2764,
      "step": 22625
    },
    {
      "epoch": 3.5383113332812623,
      "grad_norm": 0.985354483127594,
      "learning_rate": 1.1568504921106079e-05,
      "loss": 1.296,
      "step": 22650
    },
    {
      "epoch": 3.542216667968445,
      "grad_norm": 0.6404893398284912,
      "learning_rate": 1.1470863927511327e-05,
      "loss": 1.3037,
      "step": 22675
    },
    {
      "epoch": 3.5461220026556277,
      "grad_norm": 0.6717045307159424,
      "learning_rate": 1.1373222933916576e-05,
      "loss": 1.2495,
      "step": 22700
    },
    {
      "epoch": 3.55002733734281,
      "grad_norm": 0.7275011539459229,
      "learning_rate": 1.1275581940321824e-05,
      "loss": 1.2487,
      "step": 22725
    },
    {
      "epoch": 3.553932672029993,
      "grad_norm": 1.0045357942581177,
      "learning_rate": 1.1177940946727073e-05,
      "loss": 1.2768,
      "step": 22750
    },
    {
      "epoch": 3.5578380067171755,
      "grad_norm": 1.1246964931488037,
      "learning_rate": 1.1080299953132323e-05,
      "loss": 1.3059,
      "step": 22775
    },
    {
      "epoch": 3.5617433414043584,
      "grad_norm": 0.992222249507904,
      "learning_rate": 1.0982658959537573e-05,
      "loss": 1.3189,
      "step": 22800
    },
    {
      "epoch": 3.565648676091541,
      "grad_norm": 0.8031905889511108,
      "learning_rate": 1.0885017965942822e-05,
      "loss": 1.2906,
      "step": 22825
    },
    {
      "epoch": 3.569554010778724,
      "grad_norm": 0.6919228434562683,
      "learning_rate": 1.078737697234807e-05,
      "loss": 1.2856,
      "step": 22850
    },
    {
      "epoch": 3.5734593454659063,
      "grad_norm": 0.8709911108016968,
      "learning_rate": 1.068973597875332e-05,
      "loss": 1.2717,
      "step": 22875
    },
    {
      "epoch": 3.577364680153089,
      "grad_norm": 0.8519253730773926,
      "learning_rate": 1.059209498515857e-05,
      "loss": 1.2642,
      "step": 22900
    },
    {
      "epoch": 3.581270014840272,
      "grad_norm": 1.0337802171707153,
      "learning_rate": 1.0494453991563818e-05,
      "loss": 1.2833,
      "step": 22925
    },
    {
      "epoch": 3.5851753495274545,
      "grad_norm": 0.8271001577377319,
      "learning_rate": 1.0396812997969068e-05,
      "loss": 1.3166,
      "step": 22950
    },
    {
      "epoch": 3.589080684214637,
      "grad_norm": 0.9974682927131653,
      "learning_rate": 1.0299172004374318e-05,
      "loss": 1.3156,
      "step": 22975
    },
    {
      "epoch": 3.59298601890182,
      "grad_norm": 0.9179110527038574,
      "learning_rate": 1.0201531010779567e-05,
      "loss": 1.3306,
      "step": 23000
    },
    {
      "epoch": 3.59298601890182,
      "eval_loss": 1.3538893461227417,
      "eval_runtime": 1634.0004,
      "eval_samples_per_second": 6.268,
      "eval_steps_per_second": 6.268,
      "step": 23000
    },
    {
      "epoch": 3.596891353589003,
      "grad_norm": 0.7244482040405273,
      "learning_rate": 1.0103890017184815e-05,
      "loss": 1.3253,
      "step": 23025
    },
    {
      "epoch": 3.6007966882761853,
      "grad_norm": 0.884554386138916,
      "learning_rate": 1.0006249023590064e-05,
      "loss": 1.3531,
      "step": 23050
    },
    {
      "epoch": 3.6047020229633677,
      "grad_norm": 0.94629967212677,
      "learning_rate": 9.908608029995314e-06,
      "loss": 1.3072,
      "step": 23075
    },
    {
      "epoch": 3.6086073576505506,
      "grad_norm": 0.9334456920623779,
      "learning_rate": 9.810967036400563e-06,
      "loss": 1.2801,
      "step": 23100
    },
    {
      "epoch": 3.6125126923377335,
      "grad_norm": 0.9434067010879517,
      "learning_rate": 9.713326042805811e-06,
      "loss": 1.2683,
      "step": 23125
    },
    {
      "epoch": 3.616418027024916,
      "grad_norm": 0.6486048698425293,
      "learning_rate": 9.615685049211062e-06,
      "loss": 1.3363,
      "step": 23150
    },
    {
      "epoch": 3.6203233617120985,
      "grad_norm": 0.924140989780426,
      "learning_rate": 9.51804405561631e-06,
      "loss": 1.2839,
      "step": 23175
    },
    {
      "epoch": 3.6242286963992814,
      "grad_norm": 0.9663827419281006,
      "learning_rate": 9.42040306202156e-06,
      "loss": 1.2812,
      "step": 23200
    },
    {
      "epoch": 3.6281340310864643,
      "grad_norm": 0.7914227843284607,
      "learning_rate": 9.322762068426809e-06,
      "loss": 1.2849,
      "step": 23225
    },
    {
      "epoch": 3.6320393657736467,
      "grad_norm": 0.8237428665161133,
      "learning_rate": 9.225121074832057e-06,
      "loss": 1.2941,
      "step": 23250
    },
    {
      "epoch": 3.6359447004608296,
      "grad_norm": 0.8661096692085266,
      "learning_rate": 9.127480081237306e-06,
      "loss": 1.3677,
      "step": 23275
    },
    {
      "epoch": 3.639850035148012,
      "grad_norm": 0.7241946458816528,
      "learning_rate": 9.029839087642556e-06,
      "loss": 1.3514,
      "step": 23300
    },
    {
      "epoch": 3.643755369835195,
      "grad_norm": 0.6755736470222473,
      "learning_rate": 8.932198094047806e-06,
      "loss": 1.298,
      "step": 23325
    },
    {
      "epoch": 3.6476607045223775,
      "grad_norm": 0.7912322878837585,
      "learning_rate": 8.834557100453055e-06,
      "loss": 1.2988,
      "step": 23350
    },
    {
      "epoch": 3.6515660392095604,
      "grad_norm": 0.8400288820266724,
      "learning_rate": 8.736916106858303e-06,
      "loss": 1.2973,
      "step": 23375
    },
    {
      "epoch": 3.655471373896743,
      "grad_norm": 0.6856719255447388,
      "learning_rate": 8.639275113263554e-06,
      "loss": 1.3151,
      "step": 23400
    },
    {
      "epoch": 3.6593767085839257,
      "grad_norm": 0.888497531414032,
      "learning_rate": 8.541634119668802e-06,
      "loss": 1.2999,
      "step": 23425
    },
    {
      "epoch": 3.663282043271108,
      "grad_norm": 0.8906947374343872,
      "learning_rate": 8.44399312607405e-06,
      "loss": 1.3296,
      "step": 23450
    },
    {
      "epoch": 3.667187377958291,
      "grad_norm": 0.7905377745628357,
      "learning_rate": 8.3463521324793e-06,
      "loss": 1.3121,
      "step": 23475
    },
    {
      "epoch": 3.671092712645474,
      "grad_norm": 1.457275390625,
      "learning_rate": 8.24871113888455e-06,
      "loss": 1.3061,
      "step": 23500
    },
    {
      "epoch": 3.6749980473326564,
      "grad_norm": 0.8587862849235535,
      "learning_rate": 8.1510701452898e-06,
      "loss": 1.3471,
      "step": 23525
    },
    {
      "epoch": 3.678903382019839,
      "grad_norm": 0.958238959312439,
      "learning_rate": 8.053429151695048e-06,
      "loss": 1.3189,
      "step": 23550
    },
    {
      "epoch": 3.682808716707022,
      "grad_norm": 0.8911495804786682,
      "learning_rate": 7.955788158100297e-06,
      "loss": 1.2918,
      "step": 23575
    },
    {
      "epoch": 3.6867140513942047,
      "grad_norm": 0.9311278462409973,
      "learning_rate": 7.858147164505545e-06,
      "loss": 1.3111,
      "step": 23600
    },
    {
      "epoch": 3.690619386081387,
      "grad_norm": 0.8787327408790588,
      "learning_rate": 7.760506170910796e-06,
      "loss": 1.3289,
      "step": 23625
    },
    {
      "epoch": 3.6945247207685696,
      "grad_norm": 0.8873226046562195,
      "learning_rate": 7.662865177316044e-06,
      "loss": 1.2961,
      "step": 23650
    },
    {
      "epoch": 3.6984300554557525,
      "grad_norm": 0.982568085193634,
      "learning_rate": 7.565224183721294e-06,
      "loss": 1.3552,
      "step": 23675
    },
    {
      "epoch": 3.7023353901429354,
      "grad_norm": 0.8087933659553528,
      "learning_rate": 7.467583190126542e-06,
      "loss": 1.3009,
      "step": 23700
    },
    {
      "epoch": 3.706240724830118,
      "grad_norm": 0.7043917775154114,
      "learning_rate": 7.369942196531792e-06,
      "loss": 1.2666,
      "step": 23725
    },
    {
      "epoch": 3.7101460595173004,
      "grad_norm": 0.8148566484451294,
      "learning_rate": 7.272301202937042e-06,
      "loss": 1.3462,
      "step": 23750
    },
    {
      "epoch": 3.7140513942044833,
      "grad_norm": 0.7744919657707214,
      "learning_rate": 7.17466020934229e-06,
      "loss": 1.3481,
      "step": 23775
    },
    {
      "epoch": 3.717956728891666,
      "grad_norm": 1.0159209966659546,
      "learning_rate": 7.077019215747539e-06,
      "loss": 1.3404,
      "step": 23800
    },
    {
      "epoch": 3.7218620635788486,
      "grad_norm": 0.9315864443778992,
      "learning_rate": 6.97937822215279e-06,
      "loss": 1.3574,
      "step": 23825
    },
    {
      "epoch": 3.7257673982660315,
      "grad_norm": 0.7974504232406616,
      "learning_rate": 6.8817372285580385e-06,
      "loss": 1.283,
      "step": 23850
    },
    {
      "epoch": 3.729672732953214,
      "grad_norm": 0.8365243077278137,
      "learning_rate": 6.784096234963287e-06,
      "loss": 1.3154,
      "step": 23875
    },
    {
      "epoch": 3.733578067640397,
      "grad_norm": 0.8456975817680359,
      "learning_rate": 6.686455241368536e-06,
      "loss": 1.3279,
      "step": 23900
    },
    {
      "epoch": 3.7374834023275794,
      "grad_norm": 0.933812141418457,
      "learning_rate": 6.588814247773787e-06,
      "loss": 1.3278,
      "step": 23925
    },
    {
      "epoch": 3.7413887370147623,
      "grad_norm": 0.851453423500061,
      "learning_rate": 6.491173254179035e-06,
      "loss": 1.3226,
      "step": 23950
    },
    {
      "epoch": 3.7452940717019447,
      "grad_norm": 0.7724521160125732,
      "learning_rate": 6.393532260584284e-06,
      "loss": 1.3399,
      "step": 23975
    },
    {
      "epoch": 3.7491994063891276,
      "grad_norm": 0.7940539121627808,
      "learning_rate": 6.295891266989533e-06,
      "loss": 1.2928,
      "step": 24000
    },
    {
      "epoch": 3.7491994063891276,
      "eval_loss": 1.3532685041427612,
      "eval_runtime": 1633.7839,
      "eval_samples_per_second": 6.269,
      "eval_steps_per_second": 6.269,
      "step": 24000
    },
    {
      "epoch": 3.75310474107631,
      "grad_norm": 0.865887463092804,
      "learning_rate": 6.1982502733947825e-06,
      "loss": 1.3845,
      "step": 24025
    },
    {
      "epoch": 3.757010075763493,
      "grad_norm": 0.7567430734634399,
      "learning_rate": 6.100609279800031e-06,
      "loss": 1.2695,
      "step": 24050
    },
    {
      "epoch": 3.760915410450676,
      "grad_norm": 0.6129659414291382,
      "learning_rate": 6.0029682862052804e-06,
      "loss": 1.2866,
      "step": 24075
    },
    {
      "epoch": 3.7648207451378584,
      "grad_norm": 0.7744671106338501,
      "learning_rate": 5.90923293235432e-06,
      "loss": 1.3146,
      "step": 24100
    },
    {
      "epoch": 3.768726079825041,
      "grad_norm": 1.0080405473709106,
      "learning_rate": 5.811591938759569e-06,
      "loss": 1.3184,
      "step": 24125
    },
    {
      "epoch": 3.7726314145122237,
      "grad_norm": 0.7515034079551697,
      "learning_rate": 5.713950945164818e-06,
      "loss": 1.2946,
      "step": 24150
    },
    {
      "epoch": 3.7765367491994066,
      "grad_norm": 0.848573625087738,
      "learning_rate": 5.616309951570068e-06,
      "loss": 1.2812,
      "step": 24175
    },
    {
      "epoch": 3.780442083886589,
      "grad_norm": 1.240938663482666,
      "learning_rate": 5.518668957975317e-06,
      "loss": 1.3313,
      "step": 24200
    },
    {
      "epoch": 3.7843474185737715,
      "grad_norm": 0.7863733768463135,
      "learning_rate": 5.421027964380566e-06,
      "loss": 1.228,
      "step": 24225
    },
    {
      "epoch": 3.7882527532609545,
      "grad_norm": 0.8518193960189819,
      "learning_rate": 5.323386970785815e-06,
      "loss": 1.3121,
      "step": 24250
    },
    {
      "epoch": 3.7921580879481374,
      "grad_norm": 0.687843382358551,
      "learning_rate": 5.225745977191064e-06,
      "loss": 1.299,
      "step": 24275
    },
    {
      "epoch": 3.79606342263532,
      "grad_norm": 0.7945259809494019,
      "learning_rate": 5.128104983596314e-06,
      "loss": 1.354,
      "step": 24300
    },
    {
      "epoch": 3.7999687573225023,
      "grad_norm": 0.9766938090324402,
      "learning_rate": 5.030463990001562e-06,
      "loss": 1.2885,
      "step": 24325
    },
    {
      "epoch": 3.803874092009685,
      "grad_norm": 0.7229238748550415,
      "learning_rate": 4.932822996406812e-06,
      "loss": 1.2718,
      "step": 24350
    },
    {
      "epoch": 3.807779426696868,
      "grad_norm": 0.7120583057403564,
      "learning_rate": 4.835182002812061e-06,
      "loss": 1.3174,
      "step": 24375
    },
    {
      "epoch": 3.8116847613840505,
      "grad_norm": 0.8719556331634521,
      "learning_rate": 4.73754100921731e-06,
      "loss": 1.346,
      "step": 24400
    },
    {
      "epoch": 3.8155900960712335,
      "grad_norm": 0.7795589566230774,
      "learning_rate": 4.639900015622559e-06,
      "loss": 1.3034,
      "step": 24425
    },
    {
      "epoch": 3.819495430758416,
      "grad_norm": 0.7085461616516113,
      "learning_rate": 4.5422590220278084e-06,
      "loss": 1.2672,
      "step": 24450
    },
    {
      "epoch": 3.823400765445599,
      "grad_norm": 0.7745245099067688,
      "learning_rate": 4.444618028433058e-06,
      "loss": 1.3363,
      "step": 24475
    },
    {
      "epoch": 3.8273061001327813,
      "grad_norm": 0.7380982041358948,
      "learning_rate": 4.346977034838306e-06,
      "loss": 1.2811,
      "step": 24500
    },
    {
      "epoch": 3.831211434819964,
      "grad_norm": 0.6517394781112671,
      "learning_rate": 4.249336041243556e-06,
      "loss": 1.31,
      "step": 24525
    },
    {
      "epoch": 3.8351167695071466,
      "grad_norm": 0.7630465030670166,
      "learning_rate": 4.151695047648805e-06,
      "loss": 1.3114,
      "step": 24550
    },
    {
      "epoch": 3.8390221041943295,
      "grad_norm": 0.873406708240509,
      "learning_rate": 4.0540540540540545e-06,
      "loss": 1.3167,
      "step": 24575
    },
    {
      "epoch": 3.842927438881512,
      "grad_norm": 0.9426177740097046,
      "learning_rate": 3.956413060459303e-06,
      "loss": 1.286,
      "step": 24600
    },
    {
      "epoch": 3.846832773568695,
      "grad_norm": 1.2482223510742188,
      "learning_rate": 3.8587720668645525e-06,
      "loss": 1.3056,
      "step": 24625
    },
    {
      "epoch": 3.8507381082558774,
      "grad_norm": 0.7739953994750977,
      "learning_rate": 3.761131073269802e-06,
      "loss": 1.2762,
      "step": 24650
    },
    {
      "epoch": 3.8546434429430603,
      "grad_norm": 0.8132297396659851,
      "learning_rate": 3.6634900796750512e-06,
      "loss": 1.3234,
      "step": 24675
    },
    {
      "epoch": 3.8585487776302427,
      "grad_norm": 0.7315826416015625,
      "learning_rate": 3.5658490860803e-06,
      "loss": 1.2812,
      "step": 24700
    },
    {
      "epoch": 3.8624541123174256,
      "grad_norm": 0.7437311410903931,
      "learning_rate": 3.468208092485549e-06,
      "loss": 1.3356,
      "step": 24725
    },
    {
      "epoch": 3.8663594470046085,
      "grad_norm": 0.8066688179969788,
      "learning_rate": 3.3705670988907986e-06,
      "loss": 1.2935,
      "step": 24750
    },
    {
      "epoch": 3.870264781691791,
      "grad_norm": 0.874963641166687,
      "learning_rate": 3.2729261052960475e-06,
      "loss": 1.2728,
      "step": 24775
    },
    {
      "epoch": 3.8741701163789735,
      "grad_norm": 0.7993471026420593,
      "learning_rate": 3.175285111701297e-06,
      "loss": 1.3002,
      "step": 24800
    },
    {
      "epoch": 3.8780754510661564,
      "grad_norm": 0.8296200037002563,
      "learning_rate": 3.0776441181065463e-06,
      "loss": 1.3007,
      "step": 24825
    },
    {
      "epoch": 3.8819807857533393,
      "grad_norm": 0.7902215719223022,
      "learning_rate": 2.9800031245117953e-06,
      "loss": 1.313,
      "step": 24850
    },
    {
      "epoch": 3.8858861204405217,
      "grad_norm": 0.9890444278717041,
      "learning_rate": 2.8823621309170446e-06,
      "loss": 1.3481,
      "step": 24875
    },
    {
      "epoch": 3.889791455127704,
      "grad_norm": 0.7674009203910828,
      "learning_rate": 2.7847211373222936e-06,
      "loss": 1.3337,
      "step": 24900
    },
    {
      "epoch": 3.893696789814887,
      "grad_norm": 0.7799805402755737,
      "learning_rate": 2.687080143727543e-06,
      "loss": 1.2962,
      "step": 24925
    },
    {
      "epoch": 3.89760212450207,
      "grad_norm": 0.8896424770355225,
      "learning_rate": 2.5894391501327915e-06,
      "loss": 1.2801,
      "step": 24950
    },
    {
      "epoch": 3.9015074591892525,
      "grad_norm": 0.8244658708572388,
      "learning_rate": 2.491798156538041e-06,
      "loss": 1.3292,
      "step": 24975
    },
    {
      "epoch": 3.9054127938764354,
      "grad_norm": 0.9579216241836548,
      "learning_rate": 2.39415716294329e-06,
      "loss": 1.3302,
      "step": 25000
    },
    {
      "epoch": 3.9054127938764354,
      "eval_loss": 1.3531228303909302,
      "eval_runtime": 1633.8498,
      "eval_samples_per_second": 6.269,
      "eval_steps_per_second": 6.269,
      "step": 25000
    },
    {
      "epoch": 3.909318128563618,
      "grad_norm": 0.8639940619468689,
      "learning_rate": 2.2965161693485393e-06,
      "loss": 1.2888,
      "step": 25025
    },
    {
      "epoch": 3.9132234632508007,
      "grad_norm": 0.7790184020996094,
      "learning_rate": 2.1988751757537887e-06,
      "loss": 1.3456,
      "step": 25050
    },
    {
      "epoch": 3.917128797937983,
      "grad_norm": 0.8623098731040955,
      "learning_rate": 2.1012341821590376e-06,
      "loss": 1.3144,
      "step": 25075
    },
    {
      "epoch": 3.921034132625166,
      "grad_norm": 0.9008269906044006,
      "learning_rate": 2.003593188564287e-06,
      "loss": 1.3521,
      "step": 25100
    },
    {
      "epoch": 3.9249394673123486,
      "grad_norm": 0.863013744354248,
      "learning_rate": 1.905952194969536e-06,
      "loss": 1.297,
      "step": 25125
    },
    {
      "epoch": 3.9288448019995315,
      "grad_norm": 1.1117000579833984,
      "learning_rate": 1.8083112013747854e-06,
      "loss": 1.3175,
      "step": 25150
    },
    {
      "epoch": 3.932750136686714,
      "grad_norm": 1.0124530792236328,
      "learning_rate": 1.7106702077800346e-06,
      "loss": 1.2892,
      "step": 25175
    },
    {
      "epoch": 3.936655471373897,
      "grad_norm": 0.6927037835121155,
      "learning_rate": 1.6130292141852837e-06,
      "loss": 1.3145,
      "step": 25200
    },
    {
      "epoch": 3.9405608060610793,
      "grad_norm": 0.7014454007148743,
      "learning_rate": 1.515388220590533e-06,
      "loss": 1.3742,
      "step": 25225
    },
    {
      "epoch": 3.944466140748262,
      "grad_norm": 0.9487886428833008,
      "learning_rate": 1.4177472269957819e-06,
      "loss": 1.3274,
      "step": 25250
    },
    {
      "epoch": 3.9483714754354446,
      "grad_norm": 0.5989198684692383,
      "learning_rate": 1.320106233401031e-06,
      "loss": 1.2458,
      "step": 25275
    },
    {
      "epoch": 3.9522768101226275,
      "grad_norm": 0.870384931564331,
      "learning_rate": 1.2224652398062802e-06,
      "loss": 1.3187,
      "step": 25300
    },
    {
      "epoch": 3.9561821448098105,
      "grad_norm": 0.8792304992675781,
      "learning_rate": 1.1248242462115294e-06,
      "loss": 1.3214,
      "step": 25325
    },
    {
      "epoch": 3.960087479496993,
      "grad_norm": 0.860820472240448,
      "learning_rate": 1.0271832526167786e-06,
      "loss": 1.2592,
      "step": 25350
    },
    {
      "epoch": 3.9639928141841754,
      "grad_norm": 0.7257557511329651,
      "learning_rate": 9.295422590220279e-07,
      "loss": 1.3015,
      "step": 25375
    },
    {
      "epoch": 3.9678981488713583,
      "grad_norm": 1.0443295240402222,
      "learning_rate": 8.31901265427277e-07,
      "loss": 1.3242,
      "step": 25400
    },
    {
      "epoch": 3.971803483558541,
      "grad_norm": 0.9566537737846375,
      "learning_rate": 7.342602718325262e-07,
      "loss": 1.3133,
      "step": 25425
    },
    {
      "epoch": 3.9757088182457236,
      "grad_norm": 0.8026045560836792,
      "learning_rate": 6.366192782377754e-07,
      "loss": 1.3549,
      "step": 25450
    },
    {
      "epoch": 3.979614152932906,
      "grad_norm": 0.8443578481674194,
      "learning_rate": 5.389782846430246e-07,
      "loss": 1.2738,
      "step": 25475
    },
    {
      "epoch": 3.983519487620089,
      "grad_norm": 0.961696982383728,
      "learning_rate": 4.4133729104827376e-07,
      "loss": 1.3172,
      "step": 25500
    },
    {
      "epoch": 3.987424822307272,
      "grad_norm": 0.6573724746704102,
      "learning_rate": 3.4369629745352293e-07,
      "loss": 1.3072,
      "step": 25525
    },
    {
      "epoch": 3.9913301569944544,
      "grad_norm": 0.6980927586555481,
      "learning_rate": 2.4605530385877206e-07,
      "loss": 1.2833,
      "step": 25550
    },
    {
      "epoch": 3.9952354916816373,
      "grad_norm": 0.6989649534225464,
      "learning_rate": 1.4841431026402126e-07,
      "loss": 1.3138,
      "step": 25575
    },
    {
      "epoch": 3.9991408263688197,
      "grad_norm": 0.6623865365982056,
      "learning_rate": 5.0773316669270426e-08,
      "loss": 1.372,
      "step": 25600
    }
  ],
  "logging_steps": 25,
  "max_steps": 25604,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6289479049512387e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
