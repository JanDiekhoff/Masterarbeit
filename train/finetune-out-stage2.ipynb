{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8367bff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:23.908491Z",
     "iopub.status.busy": "2024-08-23T22:15:23.908102Z",
     "iopub.status.idle": "2024-08-23T22:15:23.912601Z",
     "shell.execute_reply": "2024-08-23T22:15:23.911666Z"
    },
    "papermill": {
     "duration": 0.010862,
     "end_time": "2024-08-23T22:15:23.914588",
     "exception": false,
     "start_time": "2024-08-23T22:15:23.903726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from huggingface_hub import login\n",
    "#login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e93e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:23.921051Z",
     "iopub.status.busy": "2024-08-23T22:15:23.920731Z",
     "iopub.status.idle": "2024-08-23T22:15:25.013922Z",
     "shell.execute_reply": "2024-08-23T22:15:25.013426Z"
    },
    "papermill": {
     "duration": 1.098716,
     "end_time": "2024-08-23T22:15:25.016036",
     "exception": false,
     "start_time": "2024-08-23T22:15:23.917320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfca2117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:25.025093Z",
     "iopub.status.busy": "2024-08-23T22:15:25.024722Z",
     "iopub.status.idle": "2024-08-23T22:15:25.850603Z",
     "shell.execute_reply": "2024-08-23T22:15:25.849677Z"
    },
    "papermill": {
     "duration": 0.832754,
     "end_time": "2024-08-23T22:15:25.852826",
     "exception": false,
     "start_time": "2024-08-23T22:15:25.020072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r = 64,\n",
    "    lora_alpha = 16,\n",
    "    init_lora_weights = False,\n",
    "    lora_dropout = 0.1,\n",
    "    bias = 'none',\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a003c22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:25.862480Z",
     "iopub.status.busy": "2024-08-23T22:15:25.861976Z",
     "iopub.status.idle": "2024-08-23T22:15:26.098579Z",
     "shell.execute_reply": "2024-08-23T22:15:26.098004Z"
    },
    "papermill": {
     "duration": 0.242987,
     "end_time": "2024-08-23T22:15:26.099814",
     "exception": false,
     "start_time": "2024-08-23T22:15:25.856827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "#model_name = \"microsoft/phi-2\"\n",
    "\n",
    "def init_tokenizer(model_name):\n",
    "    print(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.bos_token = \"<func>\"\n",
    "    tokenizer.eos_token = \"</func>\"\n",
    "    print(tokenizer)\n",
    "    #if model_name == \"microsoft/phi-2\": \n",
    "    tokenizer.pad_token = \"</s>\"\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff0dda3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:26.106709Z",
     "iopub.status.busy": "2024-08-23T22:15:26.106375Z",
     "iopub.status.idle": "2024-08-23T22:15:26.109257Z",
     "shell.execute_reply": "2024-08-23T22:15:26.108865Z"
    },
    "papermill": {
     "duration": 0.007985,
     "end_time": "2024-08-23T22:15:26.110511",
     "exception": false,
     "start_time": "2024-08-23T22:15:26.102526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_model(model_name, tokenizer, bnb_config, lora_config):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        revision=\"main\",\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#model = init_model(model_name, tokenizer, bnb_config, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4951a808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:26.116415Z",
     "iopub.status.busy": "2024-08-23T22:15:26.116184Z",
     "iopub.status.idle": "2024-08-23T22:15:26.118460Z",
     "shell.execute_reply": "2024-08-23T22:15:26.118064Z"
    },
    "papermill": {
     "duration": 0.006674,
     "end_time": "2024-08-23T22:15:26.119389",
     "exception": false,
     "start_time": "2024-08-23T22:15:26.112715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_collator(tokenizer):\n",
    "    return DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "629db7eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:26.125063Z",
     "iopub.status.busy": "2024-08-23T22:15:26.124694Z",
     "iopub.status.idle": "2024-08-23T22:15:26.127728Z",
     "shell.execute_reply": "2024-08-23T22:15:26.127335Z"
    },
    "papermill": {
     "duration": 0.00705,
     "end_time": "2024-08-23T22:15:26.128625",
     "exception": false,
     "start_time": "2024-08-23T22:15:26.121575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "  \"\"\"\n",
    "  Prints the number of trainable parameters in the model.\n",
    "  \"\"\"\n",
    "  trainable_params = 0\n",
    "  all_param = 0\n",
    "  for _, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "      trainable_params += param.numel()\n",
    "  print(\n",
    "    f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305153a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:26.134826Z",
     "iopub.status.busy": "2024-08-23T22:15:26.134609Z",
     "iopub.status.idle": "2024-08-23T22:15:26.137684Z",
     "shell.execute_reply": "2024-08-23T22:15:26.137210Z"
    },
    "papermill": {
     "duration": 0.007615,
     "end_time": "2024-08-23T22:15:26.138567",
     "exception": false,
     "start_time": "2024-08-23T22:15:26.130952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_args():\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/\",\n",
    "        label_names=['input_ids'],\n",
    "        weight_decay=0.01,\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        dataloader_num_workers=4,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_strategy=\"steps\",\n",
    "        learning_rate=1e-4,\n",
    "        gradient_checkpointing=True,\n",
    "        gradient_checkpointing_kwargs={'use_reentrant':False},\n",
    "        fp16=True,\n",
    "        no_cuda=False,\n",
    "        #tf32=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=250,\n",
    "        save_strategy=\"epoch\",\n",
    "        #save_steps = 800,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=1500\n",
    "    )\n",
    "    return training_args\n",
    "\n",
    "# TODO custom data loader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cab5165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:26.142451Z",
     "iopub.status.busy": "2024-08-23T22:15:26.142061Z",
     "iopub.status.idle": "2024-08-23T22:15:26.407391Z",
     "shell.execute_reply": "2024-08-23T22:15:26.406855Z"
    },
    "papermill": {
     "duration": 0.269422,
     "end_time": "2024-08-23T22:15:26.409447",
     "exception": false,
     "start_time": "2024-08-23T22:15:26.140025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "def init_trainer(model, args, train, valid, tokenizer, data_collator):\n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=valid,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668bcc9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:26.418975Z",
     "iopub.status.busy": "2024-08-23T22:15:26.418519Z",
     "iopub.status.idle": "2024-08-23T22:15:26.429618Z",
     "shell.execute_reply": "2024-08-23T22:15:26.429196Z"
    },
    "papermill": {
     "duration": 0.017981,
     "end_time": "2024-08-23T22:15:26.431499",
     "exception": false,
     "start_time": "2024-08-23T22:15:26.413518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "def add_special_tokens(example):\n",
    "    example['body'] = f\"{tokenizer.bos_token} {example['body']} {tokenizer.eos_token}\"\n",
    "    return example\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "    examples['body'], \n",
    "    return_tensors=\"np\", \n",
    "    padding=\"max_length\",\n",
    ")\n",
    "\n",
    "\n",
    "# Function to sample fixed number of rows from each group\n",
    "def sample_fixed_per_group(df, n_samples, random_state=None):\n",
    "    return df.groupby(\"language\").apply(lambda x: x.sample(n=n_samples, random_state=random_state)).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def stratified_sample(df, frac, random_state=None):\n",
    "    grouped = df.groupby('language')\n",
    "    sampled_df = grouped.apply(lambda x: x.sample(frac=frac, random_state=random_state)).reset_index(drop=True)\n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "def load_dataset(seed, data_split_type):\n",
    "    df = pd.read_parquet(\"./data/filtered_funcs.parquet\")\n",
    "    if data_split_type == \"fixed\":\n",
    "        samples_per_group = round(len(df)/1000)\n",
    "        df = sample_fixed_per_group(df, n_samples=samples_per_group,random_state=seed)\n",
    "    elif data_split_type == \"stratified\":\n",
    "        df = stratified_sample(df, frac=0.01, random_state=seed)\n",
    "    \n",
    "    #df = pd.read_parquet(f\"data/1percent_fixed_{seed}.parquet\")\n",
    "\n",
    "    train, valid = train_test_split(df, train_size=0.8, test_size=0.2, random_state=42)\n",
    "    \n",
    "    ds = DatasetDict({\n",
    "        'train': Dataset.from_pandas(train),\n",
    "        'valid': Dataset.from_pandas(valid)}\n",
    "    )\n",
    "    \n",
    "    ds = ds.map(add_special_tokens)\n",
    "    tokenized_ds = ds.map(tokenize_function, batched=True)\n",
    "    print(tokenized_ds)\n",
    "    \n",
    "    del df\n",
    "    del train\n",
    "    del valid\n",
    "    del ds\n",
    "    gc.collect()\n",
    "    \n",
    "    return tokenized_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb88212f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:26.440035Z",
     "iopub.status.busy": "2024-08-23T22:15:26.439840Z",
     "iopub.status.idle": "2024-08-23T22:15:26.442269Z",
     "shell.execute_reply": "2024-08-23T22:15:26.441869Z"
    },
    "papermill": {
     "duration": 0.0088,
     "end_time": "2024-08-23T22:15:26.444053",
     "exception": false,
     "start_time": "2024-08-23T22:15:26.435253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87f3e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T22:15:26.452824Z",
     "iopub.status.busy": "2024-08-23T22:15:26.452547Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-08-23T22:15:26.447851",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama-1.1B-Chat-v1.0', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<func>', 'eos_token': '</func>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9011200 || all params: 624617472 || trainable%: 1.4426749817206521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793179/1962877364.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = grouped.apply(lambda x: x.sample(frac=frac, random_state=random_state)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02eeee87cdd468c8a1793d183f3d38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3519de599914c2890b709631f7e8498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348011862e2249a892b816b43ef74626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c758560bac674ac48bfdac3076d790b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 51212\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 12803\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-24 00:16:00,061] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6401' max='6401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6401/6401 9:13:21, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.393600</td>\n",
       "      <td>1.404054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.402800</td>\n",
       "      <td>1.388490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.389700</td>\n",
       "      <td>1.380924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.356400</td>\n",
       "      <td>1.377169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793179/1962877364.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = grouped.apply(lambda x: x.sample(frac=frac, random_state=random_state)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aff3bc41f694ca18f31049201b570ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a28ed886b8f4daf9b623b0cae671aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7e7c58ba5b4fbdb3dd5423e6b3e72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786dbfaf50bc40adb5cc4c50ce73da50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 51212\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 12803\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6401' max='6401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6401/6401 9:13:39, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.382500</td>\n",
       "      <td>1.371243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.365600</td>\n",
       "      <td>1.364858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.366700</td>\n",
       "      <td>1.361206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.368800</td>\n",
       "      <td>1.358397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793179/1962877364.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = grouped.apply(lambda x: x.sample(frac=frac, random_state=random_state)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6796172c46d0450a92ff9c505cbb4c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e3ac6f625a4cd590f6ffff4e6afb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45770c7f81e4417ba7ca05e0fb2dc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8901406827ae4ce6bb3e9efe3e07d0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 51212\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 12803\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6401' max='6401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6401/6401 9:19:23, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.368000</td>\n",
       "      <td>1.362067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.376200</td>\n",
       "      <td>1.357525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.346300</td>\n",
       "      <td>1.354237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.368500</td>\n",
       "      <td>1.351982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793179/1962877364.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = grouped.apply(lambda x: x.sample(frac=frac, random_state=random_state)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64f04b984834b4e9973fb851fc24a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7975d784db9046829ef67af666bec76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8af0ebef9a407e873ad2bd7d6fe021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8fac12fd904cfdbefa1a1acd44dda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 51212\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 12803\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6401' max='6401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6401/6401 9:46:52, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.338100</td>\n",
       "      <td>1.352139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.361400</td>\n",
       "      <td>1.349274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.342600</td>\n",
       "      <td>1.346777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.357200</td>\n",
       "      <td>1.344632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3793179/1962877364.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = grouped.apply(lambda x: x.sample(frac=frac, random_state=random_state)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b11227b31464f81935c7d5e91f34678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bd6a4b02fc4d09932227c8231c6adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7eb2c2ddd24e54ac866687c797e7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634ac5c1c6354c78be35037c8cf7ebf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 51212\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['language', 'body', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 12803\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3369' max='6401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3369/6401 4:49:10 < 4:20:24, 0.19 it/s, Epoch 0.53/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.351100</td>\n",
       "      <td>1.351206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.334600</td>\n",
       "      <td>1.348564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "tokenizer = init_tokenizer(model_name)\n",
    "data_collator = init_collator(tokenizer)\n",
    "\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model = get_peft_model(model, peft_config=lora_config)\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "data_split_type = \"stratified\"\n",
    "training_args = init_args()\n",
    "\n",
    "num_epochs = 100\n",
    "for i in range(num_epochs):\n",
    "    tokenized_ds = load_dataset(i, data_split_type)\n",
    "    \n",
    "    trainer = init_trainer(\n",
    "        model,\n",
    "        training_args,\n",
    "        tokenized_ds[\"train\"],\n",
    "        tokenized_ds[\"valid\"],\n",
    "        tokenizer, \n",
    "        data_collator\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"./results/{data_split_type}/checkpoint-{i}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "finetune-llama.ipynb",
   "output_path": "finetune-llama-out.ipynb",
   "parameters": {},
   "start_time": "2024-08-23T22:15:22.887769",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}