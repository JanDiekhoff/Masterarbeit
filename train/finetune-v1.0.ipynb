{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d57c6275",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [12]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367bff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:08.827339Z",
     "iopub.status.busy": "2024-08-21T22:13:08.827041Z",
     "iopub.status.idle": "2024-08-21T22:13:08.830796Z",
     "shell.execute_reply": "2024-08-21T22:13:08.830166Z"
    },
    "papermill": {
     "duration": 0.008116,
     "end_time": "2024-08-21T22:13:08.831844",
     "exception": false,
     "start_time": "2024-08-21T22:13:08.823728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from huggingface_hub import login\n",
    "#login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e93e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:08.835582Z",
     "iopub.status.busy": "2024-08-21T22:13:08.835391Z",
     "iopub.status.idle": "2024-08-21T22:13:09.910911Z",
     "shell.execute_reply": "2024-08-21T22:13:09.909983Z"
    },
    "papermill": {
     "duration": 1.079818,
     "end_time": "2024-08-21T22:13:09.913126",
     "exception": false,
     "start_time": "2024-08-21T22:13:08.833308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca2117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:09.922131Z",
     "iopub.status.busy": "2024-08-21T22:13:09.921701Z",
     "iopub.status.idle": "2024-08-21T22:13:10.750690Z",
     "shell.execute_reply": "2024-08-21T22:13:10.749748Z"
    },
    "papermill": {
     "duration": 0.83477,
     "end_time": "2024-08-21T22:13:10.751766",
     "exception": false,
     "start_time": "2024-08-21T22:13:09.916996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r = 64,\n",
    "    lora_alpha = 16,\n",
    "    init_lora_weights = False,\n",
    "    lora_dropout = 0.1,\n",
    "    bias = 'none',\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003c22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:10.755653Z",
     "iopub.status.busy": "2024-08-21T22:13:10.755425Z",
     "iopub.status.idle": "2024-08-21T22:13:11.202401Z",
     "shell.execute_reply": "2024-08-21T22:13:11.201434Z"
    },
    "papermill": {
     "duration": 0.450789,
     "end_time": "2024-08-21T22:13:11.204028",
     "exception": false,
     "start_time": "2024-08-21T22:13:10.753239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "def init_tokenizer(model_name):\n",
    "    print(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.bos_token = \"<func>\"\n",
    "    tokenizer.eos_token = \"</func>\"\n",
    "    print(tokenizer)\n",
    "    tokenizer.pad_token = \"</s>\"\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0dda3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:11.212158Z",
     "iopub.status.busy": "2024-08-21T22:13:11.211924Z",
     "iopub.status.idle": "2024-08-21T22:13:12.801872Z",
     "shell.execute_reply": "2024-08-21T22:13:12.801234Z"
    },
    "papermill": {
     "duration": 1.596226,
     "end_time": "2024-08-21T22:13:12.803546",
     "exception": false,
     "start_time": "2024-08-21T22:13:11.207320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_model(model_name, tokenizer, bnb_config, lora_config):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        revision=\"main\",\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#model = init_model(model_name, tokenizer, bnb_config, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951a808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:12.807451Z",
     "iopub.status.busy": "2024-08-21T22:13:12.807306Z",
     "iopub.status.idle": "2024-08-21T22:13:12.810296Z",
     "shell.execute_reply": "2024-08-21T22:13:12.809790Z"
    },
    "papermill": {
     "duration": 0.00599,
     "end_time": "2024-08-21T22:13:12.811222",
     "exception": false,
     "start_time": "2024-08-21T22:13:12.805232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_collator(tokenizer):\n",
    "    return DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629db7eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:12.814974Z",
     "iopub.status.busy": "2024-08-21T22:13:12.814695Z",
     "iopub.status.idle": "2024-08-21T22:13:12.817856Z",
     "shell.execute_reply": "2024-08-21T22:13:12.817456Z"
    },
    "papermill": {
     "duration": 0.006153,
     "end_time": "2024-08-21T22:13:12.818704",
     "exception": false,
     "start_time": "2024-08-21T22:13:12.812551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "  \"\"\"\n",
    "  Prints the number of trainable parameters in the model.\n",
    "  \"\"\"\n",
    "  trainable_params = 0\n",
    "  all_param = 0\n",
    "  for _, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "      trainable_params += param.numel()\n",
    "  print(\n",
    "    f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305153a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:12.822257Z",
     "iopub.status.busy": "2024-08-21T22:13:12.822028Z",
     "iopub.status.idle": "2024-08-21T22:13:12.825402Z",
     "shell.execute_reply": "2024-08-21T22:13:12.825007Z"
    },
    "papermill": {
     "duration": 0.006081,
     "end_time": "2024-08-21T22:13:12.826201",
     "exception": false,
     "start_time": "2024-08-21T22:13:12.820120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_args():\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/chunked/stratified\",\n",
    "        label_names=['input_ids'],\n",
    "        weight_decay=0.01,\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        dataloader_num_workers=4,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_strategy=\"steps\",\n",
    "        learning_rate=1e-4,\n",
    "        gradient_checkpointing=True,\n",
    "        gradient_checkpointing_kwargs={'use_reentrant':False},\n",
    "        fp16=True,\n",
    "        no_cuda=False,\n",
    "        #tf32=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=250,\n",
    "        save_strategy=\"epoch\",\n",
    "        #save_steps = 800,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=1500\n",
    "    )\n",
    "    return training_args\n",
    "\n",
    "# TODO custom data loader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab5165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:12.830262Z",
     "iopub.status.busy": "2024-08-21T22:13:12.829690Z",
     "iopub.status.idle": "2024-08-21T22:13:13.108089Z",
     "shell.execute_reply": "2024-08-21T22:13:13.107191Z"
    },
    "papermill": {
     "duration": 0.281589,
     "end_time": "2024-08-21T22:13:13.109134",
     "exception": false,
     "start_time": "2024-08-21T22:13:12.827545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "def init_trainer(model, args, train, valid, tokenizer, data_collator):\n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=valid,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668bcc9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:13.113305Z",
     "iopub.status.busy": "2024-08-21T22:13:13.113009Z",
     "iopub.status.idle": "2024-08-21T22:13:13.123834Z",
     "shell.execute_reply": "2024-08-21T22:13:13.123202Z"
    },
    "papermill": {
     "duration": 0.014403,
     "end_time": "2024-08-21T22:13:13.125117",
     "exception": false,
     "start_time": "2024-08-21T22:13:13.110714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "def add_special_tokens(example):\n",
    "    example['body'] = f\"{tokenizer.bos_token} {example['body']} {tokenizer.eos_token}\"\n",
    "    return example\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "    examples['body'], \n",
    "    return_tensors=\"np\", \n",
    "    padding=\"max_length\",\n",
    ")\n",
    "\n",
    "\n",
    "def sample_fixed_per_group(df, n_samples, random_state=None):\n",
    "    return df.groupby(\"language\").apply(lambda x: x.sample(n=n_samples, random_state=random_state)).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def stratified_sample(df, frac, random_state=None):\n",
    "    grouped = df.groupby('language')\n",
    "    sampled_df = grouped.apply(lambda x: x.sample(frac=frac, random_state=random_state)).reset_index(drop=True)\n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "def load_dataset(seed, data_split_type):\n",
    "    df = pd.read_parquet(\"./data/filtered_funcs.parquet\")\n",
    "    if data_split_type == \"fixed\":\n",
    "        samples_per_group = round(len(df)/1000)\n",
    "        df = sample_fixed_per_group(df, n_samples=samples_per_group,random_state=seed)\n",
    "    elif data_split_type == \"stratified\":\n",
    "        df = stratified_sample(df, frac=0.01, random_state=seed)\n",
    "    \n",
    "    #df = pd.read_parquet(f\"data/1percent_fixed_{seed}.parquet\")\n",
    "\n",
    "    train, valid = train_test_split(df, train_size=0.8, test_size=0.2, random_state=42)\n",
    "    \n",
    "    ds = DatasetDict({\n",
    "        'train': Dataset.from_pandas(train),\n",
    "        'valid': Dataset.from_pandas(valid)}\n",
    "    )\n",
    "    \n",
    "    ds = ds.map(add_special_tokens)\n",
    "    tokenized_ds = ds.map(tokenize_function, batched=True)\n",
    "    print(tokenized_ds)\n",
    "    \n",
    "    del df\n",
    "    del train\n",
    "    del valid\n",
    "    del ds\n",
    "    gc.collect()\n",
    "    \n",
    "    return tokenized_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88212f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:13.128982Z",
     "iopub.status.busy": "2024-08-21T22:13:13.128794Z",
     "iopub.status.idle": "2024-08-21T22:13:13.131841Z",
     "shell.execute_reply": "2024-08-21T22:13:13.131229Z"
    },
    "papermill": {
     "duration": 0.006274,
     "end_time": "2024-08-21T22:13:13.132829",
     "exception": false,
     "start_time": "2024-08-21T22:13:13.126555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f3e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T22:13:13.136811Z",
     "iopub.status.busy": "2024-08-21T22:13:13.136527Z",
     "iopub.status.idle": "2024-08-21T22:13:13.376037Z",
     "shell.execute_reply": "2024-08-21T22:13:13.375029Z"
    },
    "papermill": {
     "duration": 0.242704,
     "end_time": "2024-08-21T22:13:13.376956",
     "exception": true,
     "start_time": "2024-08-21T22:13:13.134252",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "tokenizer = init_tokenizer(model_name)\n",
    "data_collator = init_collator(tokenizer)\n",
    "\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model = get_peft_model(model, peft_config=lora_config)\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "data_split_type = \"stratified\"\n",
    "training_args = init_args()\n",
    " \n",
    "tokenized_ds = load_dataset(0, data_split_type)\n",
    "trainer = init_trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    tokenized_ds[\"train\"],\n",
    "    tokenized_ds[\"valid\"],\n",
    "    tokenizer, \n",
    "    data_collator\n",
    ")\n",
    "\n",
    "num_epochs = 100\n",
    "for i in range(10,num_epochs):\n",
    "    print(i)\n",
    "    if i:\n",
    "        tokenized_ds = load_dataset(i, data_split_type)\n",
    "        \n",
    "        trainer.train_dataset = tokenized_ds[\"train\"]\n",
    "        trainer.eval_dataset = tokenized_ds[\"valid\"]\n",
    "        \n",
    "    print(trainer.train_dataset[0])\n",
    "        \n",
    "        #trainer.args.num_train_epochs = i+1\n",
    "\n",
    "    trainer.train(resume_from_checkpoint=True)\n",
    "    trainer.save_model(f\"./results/chunked/{data_split_type}/checkpoint-{i}-chunked\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.567572,
   "end_time": "2024-08-21T22:13:14.498311",
   "environment_variables": {},
   "exception": true,
   "input_path": "finetune-llama.ipynb",
   "output_path": "finetune-llama-out.ipynb",
   "parameters": {},
   "start_time": "2024-08-21T22:13:07.930739",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
